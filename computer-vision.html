<html>

<head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <link rel="stylesheet" href="css/computer-vision.css" />
    <link rel="stylesheet" href="css/page.css" />
</head>

<body class="c78 c110">
    <p class="c102 title" id="h.yex36bfjrdd9"><span class="c84 c21">Computer Vision</span></p>
    <p class="c45 subtitle" id="h.repsoi6h2qv9"><span class="c38 c21">Joshua Gregory</span></p>
    <p class="c45 subtitle" id="h.qglqlxj0eutt"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 194.50px; height: 185.33px;"><img
                alt="" src="assets/computer-vision/image186.png"
                style="width: 194.50px; height: 185.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c88"><span class="c30 c5"><a class="c0" href="#h.u3rdxkn44rsj">Notes intro</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.u3rdxkn44rsj">10</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.c60tptcb72mf">Introduction</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.c60tptcb72mf">10</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.s6a9yo2qvoba">Lecture 1: Eye and Human
                Vision</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.s6a9yo2qvoba">12</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.3vlet6ck734k">The human eye</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.3vlet6ck734k">12</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.xq9s4h48dvia">Optics</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.xq9s4h48dvia">13</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ynp85x94awn0">Spectral responses</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ynp85x94awn0">14</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.7k0qsdpckrju">Mach bands</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7k0qsdpckrju">15</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.o1edcy8wcjx1">Neural processing</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.o1edcy8wcjx1">16</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.qr7i0cfd613j">Lecture 2: Image Formation</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.qr7i0cfd613j">16</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.koa7ohlu7fh6">Decomposition</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.koa7ohlu7fh6">16</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.fda4lu9df2ko">Resolution</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.fda4lu9df2ko">17</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.wxtfywxz52iv">Fourier Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wxtfywxz52iv">17</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.raugx0r1u30">What the Fourier Transform actually
                does</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.raugx0r1u30">18</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.1xupejvn9gpk">A pulse and its Fourier
                transform</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.1xupejvn9gpk">19</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.gsw108thax1c">Reconstructing signal from its Fourier
                Transform</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.gsw108thax1c">20</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ek4l8sln6f22">Magnitude and phase of the Fourier transform of
                a pulse</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ek4l8sln6f22">21</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.g5kvnta1x5y9">Lecture 3: Image Sampling</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.g5kvnta1x5y9">21</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.utsmcrfhamoq">Aliasing in Sampled Imagery</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.utsmcrfhamoq">21</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.lzs9auur59vg">Aliasing</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.lzs9auur59vg">22</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.7i2xexvzifkh">Sampling Signals</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7i2xexvzifkh">22</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.y3c92p8cee9m">Wheels Motion</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.y3c92p8cee9m">22</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.2csxltjk3xt9">Sampling Theory</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2csxltjk3xt9">23</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.17if0t24uylf">Transform Pair from Sampled
                Pulse</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.17if0t24uylf">23</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.y2ajgvsy24o7">2D Fourier Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.y2ajgvsy24o7">24</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ru1t3s7nh578">Reconstruction (non examinable)</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ru1t3s7nh578">26</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.2seqon9ny58p">Shift Invariance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2seqon9ny58p">26</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.s7ggx4p0trm4">Rotation Invariance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.s7ggx4p0trm4">27</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.nqpliez1yxlm">Filtering</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.nqpliez1yxlm">27</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.5ft9mcodohws">Other Transforms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.5ft9mcodohws">28</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.pagfk6ypugwl">Applications of 2D Fourier
                Transform</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.pagfk6ypugwl">29</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.6telsegzeux8">Lecture 4: Point Operators</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.6telsegzeux8">29</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.6drwr87kekh7">Image Histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.6drwr87kekh7">29</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.7jcpjrz8waba">Brightening and Image</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7jcpjrz8waba">29</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.mpamkzzb0c88">Intensity Mappings</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.mpamkzzb0c88">30</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.k3kucmg2oad">Exponential/Logarithmic Point Operators (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.k3kucmg2oad">30</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.uxk7c5mfkpjp">Intensity normalisation and histogram
                equalisation</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.uxk7c5mfkpjp">31</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.6qf1dortzp99">Histogram Equalisation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.6qf1dortzp99">31</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.1ckjb6vuzlx6">Applying intensity normalisation and histogram
                equalisation</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.1ckjb6vuzlx6">32</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.8ngqvh6dthc3">Thresholding and eye image</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.8ngqvh6dthc3">32</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.sh1v1yo2asf4">Thresholding: Manual vs
                Automatic</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.sh1v1yo2asf4">33</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.r60lp14xtz3o">Lecture 5: Group Operators</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.r60lp14xtz3o">33</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.rgogy2m4wjgl">Template Convolution</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.rgogy2m4wjgl">34</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.bv76o1e6lbap">3x3 template and weighting
                coefficients</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.bv76o1e6lbap">35</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.vr8heioavsbo">3x3 averaging operator</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.vr8heioavsbo">36</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.s6srnnxi407x">Illustrating the effect of window
                size</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.s6srnnxi407x">37</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.5qwoy67hrjcb">Template convolution via the Fourier
                transform</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.5qwoy67hrjcb">37</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.2x9jp0fp4wv9">2D Gaussian function</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2x9jp0fp4wv9">37</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.eljctdpui0i2">2D Gaussian template</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.eljctdpui0i2">39</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.9ughi4p1i2yy">Applying Gaussian averaging</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.9ughi4p1i2yy">39</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.3uljj9ropf2a">Finding the median from a 3x3
                template</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.3uljj9ropf2a">39</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.l2x6zsge0fob">Newer stuff (non-examinable)</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.l2x6zsge0fob">40</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.363myf528l6r">Applying non local means</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.363myf528l6r">41</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.rd1wzi7hb98m">Even newer stuff: Image Ray
                Transform</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.rd1wzi7hb98m">41</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.v7lnzpjmxsn4">Applying Image Ray Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.v7lnzpjmxsn4">41</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.pnrxn2wjz81g">Comparing operators</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.pnrxn2wjz81g">43</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.a23nf1qm73o1">Lecture 6: Edge Detection</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.a23nf1qm73o1">43</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.poti69atue89">Edge detection</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.poti69atue89">43</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.nv01ocsxcyi6">First order edge detection</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.nv01ocsxcyi6">43</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.t1jujyvca2jd">Edge detection maths</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.t1jujyvca2jd">45</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.vwjili3ejkm1">Templates for improved first order
                difference</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.vwjili3ejkm1">45</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.w6etzb93kgix">Edge Detection in Vector Format</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w6etzb93kgix">45</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.48w5z9pnhlny">Templates for Prewitt operator</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.48w5z9pnhlny">46</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.oxpmszan1wnu">Applying the Prewitt Operator</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.oxpmszan1wnu">46</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.cpee65aduznx">Templates for Sobel operator</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.cpee65aduznx">47</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.fwie2y64dpq4">Applying Sobel operator</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.fwie2y64dpq4">47</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ri2bfihw9zsn">Generalising Sobel</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ri2bfihw9zsn">47</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ypmu5mxcf6t2">Generalised Sobel (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ypmu5mxcf6t2">48</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.z8xfmpffewkt">Lecture 7: Further Edge
                Detection</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.z8xfmpffewkt">48</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.kiathytlgbbw">Canny edge detection operator</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kiathytlgbbw">48</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.maqnl8o22vhp">Interpolation in non-maximum
                suppression</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.maqnl8o22vhp">49</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.l2unabxihzo">Hysteresis thresholding transfer
                function</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.l2unabxihzo">50</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.54cft2uhljs">Action of non-maximum suppression and hysteresis
                thresholding</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.54cft2uhljs">51</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.5dhvqr2ue8x8">Hysteresis thresholding vs uniform
                thresholding</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.5dhvqr2ue8x8">51</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.70f9y4syypeu">Canny vs Sobel</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.70f9y4syypeu">51</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.nucyakitr4jz">First and second order edge
                detection</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.nucyakitr4jz">53</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ome8giktir7a">Edge detection via the Laplacian
                operator</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ome8giktir7a">53</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.7iddkrpcix6">Mathbelts on&hellip;</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7iddkrpcix6">54</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.n8v1bc8n6lfh">Shape of Laplacian of Gaussian
                operator</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.n8v1bc8n6lfh">54</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.hcmf1p4g73j">Zero crossing detection</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.hcmf1p4g73j">55</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.l0gsjfn55919">Marr-Hildreth edge detection</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.l0gsjfn55919">55</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.q8uvwjtr10v6">Comparison of edge detection
                operators</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.q8uvwjtr10v6">55</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.bkbo49qovp4r">Newer stuff - interest detections
                (non-examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.bkbo49qovp4r">56</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.8cfmcn38vzev">Newer stuff - saliency</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.8cfmcn38vzev">56</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.b6h9b1xpm1ul">Lecture 8: Finding Shapes</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.b6h9b1xpm1ul">57</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.wphzqhcwf5de">Feature extraction by
                thresholding</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.wphzqhcwf5de">57</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ahgye3gca4ro">Template Matching</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ahgye3gca4ro">57</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.o4ukfk6oe1tb">Template matching in:</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.o4ukfk6oe1tb">58</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.qh5yqve8ye7n">In Noisy images</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.qh5yqve8ye7n">58</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.udkrzg2x7gb6">In Occluded Images</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.udkrzg2x7gb6">58</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.7yvs59xxj7hb">Encore, Monsieur Fourier! (???) (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.7yvs59xxj7hb">59</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.f87o22lh4yvs">Applying Template Matching (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.f87o22lh4yvs">59</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ncb9i4axsgzs">Applying SIFT in ear biometrics (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ncb9i4axsgzs">60</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.c1kb1fyhod63">Hough Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.c1kb1fyhod63">60</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.m46f2icu9qwu">Applying the Hough transform for
                lines</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.m46f2icu9qwu">61</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.lzblxpi6dqj2">Hough Transform for Lines &hellip;
                problems</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.lzblxpi6dqj2">61</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.4enyckjmhksu">Images and accumulator space of polar Hough
                Transform</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.4enyckjmhksu">62</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.b9t8kfmirpub">Applying Hough Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.b9t8kfmirpub">62</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.g2j618ptvci9">Lecture 9: Finding More
                Shapes</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.g2j618ptvci9">63</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.bm7answwtaav">Hough Transform for Circles</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.bm7answwtaav">63</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.oqzuof2nrndu">Circle Voting and Accumulator
                Space</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.oqzuof2nrndu">64</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.os4nb27d08et">Speeding it up</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.os4nb27d08et">64</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.wjb4a4xt6om0">Applying the HT for circles</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wjb4a4xt6om0">64</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.c9gn47ra3dzt">Integrodifferential operator? (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.c9gn47ra3dzt">64</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.2ak0f5l2grdx">Arbitrary Shapes</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2ak0f5l2grdx">65</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.6p906787a3bo">R-table Construction</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.6p906787a3bo">65</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.rku7h3jplkvd">Active Contours (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.rku7h3jplkvd">66</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.t17lsdlxi2q8">Geometric active contours (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.t17lsdlxi2q8">67</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.qr3f44iyekit">Parts-based shape modelling (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.qr3f44iyekit">67</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.brc5hs2ecfcz">Symmetry yrtemmyS (non
                examinable)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.brc5hs2ecfcz">68</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.f9va09x4y1py">Lecture 10 Applications/Deep
                Learning</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.f9va09x4y1py">68</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.h4hlcxfog5uy">Where is computer vision used?</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.h4hlcxfog5uy">68</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.gvvqmhsfeyuw">Deep Learning</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gvvqmhsfeyuw">68</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.g3p56ktzy0ck">Conclusions</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.g3p56ktzy0ck">68</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.iy72sddzw1cg">Lecture 1: Building machines that
                see</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.iy72sddzw1cg">71</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.m5aa6q92x3t4">Key terms in designing Computer Vision
                systems</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.m5aa6q92x3t4">71</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.bwuje9hi3xve">Robustness</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.bwuje9hi3xve">71</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.fa922gsx4ewr">Repeatability</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.fa922gsx4ewr">71</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.83adh2kb97u3">Invariance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.83adh2kb97u3">71</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.smoa788qskgm">Constraints</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.smoa788qskgm">71</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.vtqxj8cpjfjm">Constraints in Industrial
                Vision</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.vtqxj8cpjfjm">72</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.7hfw5nibiydz">Software Constraints</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7hfw5nibiydz">72</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.uw57z06xh156">Colour-Spaces (non examinable?)</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.uw57z06xh156">72</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.3hhakmzi727p">RGB Colour-space</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.3hhakmzi727p">72</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.kqgdou8gsidi">HSV Colour-space</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kqgdou8gsidi">72</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.t0lem6ewl5o">Physical Constraints</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.t0lem6ewl5o">73</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.l31tj9bgeegs">Vision in the wild</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.l31tj9bgeegs">73</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.y9a1jfizwew1">Lecture 2: Machine learning for pattern
                recognition</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.y9a1jfizwew1">73</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.2yyn6u5csbzq">Feature Spaces</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2yyn6u5csbzq">73</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.eko2x51ny74k">Key terminology</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.eko2x51ny74k">74</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ugkc9jexg0iq">Density and Similarity</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ugkc9jexg0iq">74</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.w4prz560taxo">Distance in featurespace</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w4prz560taxo">74</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.8gko3o3iszzp">Euclidean distance (L2 distance)</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.8gko3o3iszzp">75</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.mayrtvj44hxn">Manhattan/Taxicab distance (L1
                distance)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.mayrtvj44hxn">76</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.euhn1fjb81y4">Cosine Similarity</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.euhn1fjb81y4">76</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.eawvrmhllhox">Choosing good </a></span><span class="c8"><a
                class="c0" href="#h.eawvrmhllhox">featurevector</a></span><span class="c8"><a class="c0"
                href="#h.eawvrmhllhox">&nbsp;representations for machine learning</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.eawvrmhllhox">77</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.h205onq4o86x">Supervised Machine Learning:
                Classification</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.h205onq4o86x">77</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.7ifbjkds5n7f">Linear Classifiers</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7ifbjkds5n7f">77</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.m48s0h7011bg">Non-linear binary classifiers</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.m48s0h7011bg">78</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.5qn8mwpnnfh0">Multiclass classifiers: KNN</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.5qn8mwpnnfh0">80</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.21fwhzwbg0v6">KNN Problems (non examinable?)</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.21fwhzwbg0v6">80</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.qq2zm5zd204x">Unsupervised Machine Learning:
                Clustering</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.qq2zm5zd204x">81</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.taca32ts1z7c">K-Means Clustering</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.taca32ts1z7c">81</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.6ieazp851c7p">Lecture 3: Covariance and Principal
                Components</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.6ieazp851c7p">82</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.xd66dx7ruk3c">Random Variables and Expected
                Values</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.xd66dx7ruk3c">82</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.3285v0s2vh76">Variance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.3285v0s2vh76">82</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.wndutylwftvo">Covariance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wndutylwftvo">82</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ts9wke7kwzrj">Covariance Matrix</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ts9wke7kwzrj">83</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.c8jpumw8hlro">Mean Centring</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.c8jpumw8hlro">83</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.by7ogxotx6p8">Covariance matrix again</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.by7ogxotx6p8">84</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.aqf9tsbo5r2r">Principal axes of variation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.aqf9tsbo5r2r">85</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.gzxnincvri8b">Basis</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gzxnincvri8b">85</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.clq2n8kzpmrz">The first principal axis</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.clq2n8kzpmrz">85</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.tsih352efgk">The second principal axis</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.tsih352efgk">85</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ajo1tmv3ovgx">The third principal axis</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ajo1tmv3ovgx">85</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.eyso2ifrb6ag">Eigenvectors and Eigenvalues</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.eyso2ifrb6ag">86</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ycxwwa7v367v">Important Equation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ycxwwa7v367v">86</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.7243he8btq3j">Properties</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7243he8btq3j">86</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.rtu5z6v9alav">Finding Values</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.rtu5z6v9alav">87</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ao76kyhu56nv">Eigendecomposition</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ao76kyhu56nv">87</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.m5y0717acyg1">Summary</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.m5y0717acyg1">87</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.9xipgpz465iz">Ordering</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.9xipgpz465iz">87</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.oybzg79020yb">Principal Component Analysis</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.oybzg79020yb">87</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.vdbp53b2ulxj">Linear Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.vdbp53b2ulxj">87</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.qgppvkwnwvsr">Linear Transforms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.qgppvkwnwvsr">88</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.bf42na9f5806">PCA</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.bf42na9f5806">88</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.tv78nbjwhe3t">PCA Algorithm</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.tv78nbjwhe3t">89</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.pgjbjnsl3ht2">Eigenfaces</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.pgjbjnsl3ht2">89</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.b4t5dgr4hgqw">Making Invariant</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.b4t5dgr4hgqw">89</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.4cfvm0yi5j3i">Problems</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.4cfvm0yi5j3i">90</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.xgz2qy88ff0i">Potential Solution&hellip; Apply
                PCA</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.xgz2qy88ff0i">90</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.eqyupxg60g7w">Lecture 4: Types of image feature and
                segmentation</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.eqyupxg60g7w">91</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.w0yhkccpw81g">Image Feature Morphology</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w0yhkccpw81g">91</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.1vbc0xw8x9xz">Global Features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.1vbc0xw8x9xz">91</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.b4x5o1ibh85z">Grid or Block-based Features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.b4x5o1ibh85z">91</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.vc54aveoejqd">Region-based Features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.vc54aveoejqd">92</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.7zb3wepl6bvu">Local Features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7zb3wepl6bvu">92</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.d1b2ik55rt54">Global Features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.d1b2ik55rt54">92</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.oeiysmjdwhvh">Image Histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.oeiysmjdwhvh">92</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.xd305kbo099q">Joint-colour histogram</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.xd305kbo099q">93</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ypi7l1q2v3ep">Image Segmentation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ypi7l1q2v3ep">94</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.z2crchf8lzi7">What is segmentation?</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.z2crchf8lzi7">94</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.aq04qk7gtqno">Global Binary Thresholding</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.aq04qk7gtqno">94</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.r8jii5w2jsl0">Otsu&rsquo;s thresholding method</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.r8jii5w2jsl0">94</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.b1i5vo8596sf">Adaptive / local thresholding</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.b1i5vo8596sf">95</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.1se2cwtf55o3">Mean adaptive thresholding</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.1se2cwtf55o3">95</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.jzgxig4pxzl6">Segmentation with K-Means</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.jzgxig4pxzl6">95</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.cdamjurmh46r">Advanced segmentation techniques</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.cdamjurmh46r">96</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.qjtv8cw0rkr9">Connected Components</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.qjtv8cw0rkr9">96</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.2quijahlnq4t">Pixel Connectivity</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2quijahlnq4t">96</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ly56umo30dfb">Connected Component</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ly56umo30dfb">96</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.1vptw2gx0ctk">Connected Component Labelling</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.1vptw2gx0ctk">96</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.p25mkdd477mz">The two-pass algorithm</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.p25mkdd477mz">97</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.36kzsod8q2go">Lecture 5: Shape description and
                modelling</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.36kzsod8q2go">98</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.170xuhz620u5">Extracting features from shapes represented by
                connected components</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.170xuhz620u5">98</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.sdil8cl9yrga">Borders</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.sdil8cl9yrga">98</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.os565i2g2oc1">Inner Border</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.os565i2g2oc1">98</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.y0v7fiyt9qt1">Outer Border</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.y0v7fiyt9qt1">98</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.4hiwo6kmmfjo">Two ways to describe shape</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.4hiwo6kmmfjo">99</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.rnuyumkn9a3j">Region Description: Simple Scalar Shape
                Features</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.rnuyumkn9a3j">100</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.w87tf1nedhwj">Area and Perimeter</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w87tf1nedhwj">100</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.upn2q7f6warm">Compactness</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.upn2q7f6warm">100</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.kyaowyx54gxy">Centre of Mass</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kyaowyx54gxy">100</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.6uzukm6c0zt">Irregularity / Dispersion</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.6uzukm6c0zt">101</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.o43xkdlyavsz">Moments</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.o43xkdlyavsz">102</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.f2ekr7sflkrn">Standard Moments</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.f2ekr7sflkrn">102</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.b85r2j8dofai">Central Moments</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.b85r2j8dofai">102</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.18gql5oqgvgo">Normalised Central Moments</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.18gql5oqgvgo">103</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.yzzsbu2n9p7k">Boundary Description</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.yzzsbu2n9p7k">103</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.w8he9ccgnnsg">Chain Codes</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w8he9ccgnnsg">103</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.evssub9r3lz3">Chain Code Invariance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.evssub9r3lz3">103</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.hmduyiaiflow">Chain Code Advantages and
                Limitations</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.hmduyiaiflow">104</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.82ge272fzh4n">Fourier Descriptors</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.82ge272fzh4n">104</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.bnd5a67osaq">Region Adjacency Graphs</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.bnd5a67osaq">105</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.9bt76860dlus">Active Shape Models and Constrained Local
                Models</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.9bt76860dlus">105</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.hawd7v91o2fl">Lecture 6: Local interest
                points</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.hawd7v91o2fl">105</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.igxj4uizlu6v">What makes a good interest
                point?</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.igxj4uizlu6v">105</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.rqc5a1xpinmw">How to find interest points</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.rqc5a1xpinmw">106</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.xj82bw5edhf3">The Harris and Stephens corner
                detector</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.xj82bw5edhf3">107</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.56s1ffw478lw">Basic Idea</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.56s1ffw478lw">107</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ri611ke4amb1">Harris &amp; Stephens:
                Mathematics</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ri611ke4amb1">107</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.n3yj36hzpyw3">Structure Tensor</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.n3yj36hzpyw3">108</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ga25farzxogb">Eigenvalues of the Structure
                Tensor</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ga25farzxogb">109</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ttaafybqugor">Harris &amp; Stephens Response
                Function</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ttaafybqugor">109</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.v8j250vcxfdu">Harris &amp; Stephens Detector</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.v8j250vcxfdu">110</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.1h601c8x29j3">Scale in Computer Vision</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.1h601c8x29j3">111</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.83v5p4nxrfdp">The problem of scale</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.83v5p4nxrfdp">111</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.262gckmizhdc">Scale space theory</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.262gckmizhdc">111</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.mlec6uwrpjtk">The Gaussian Scale Space</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.mlec6uwrpjtk">112</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.3wxc3i44ofge">Nyquist-Shannon Sampling theorem</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.3wxc3i44ofge">112</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.pupmen7hxoec">Gaussian Pyramid</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.pupmen7hxoec">113</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.zdifhduyxv6y">Multi-scale Harris &amp;
                Stephens</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.zdifhduyxv6y">113</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.qh88fr9bfd5j">Blob Detection Finally</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.qh88fr9bfd5j">113</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.5cbud18u9rd5">Laplacian of Gaussian</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.5cbud18u9rd5">113</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.kdpbqcwpepu9">Scale space LoG</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kdpbqcwpepu9">114</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.jy4a9e7f5j5n">Scale space DoG</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.jy4a9e7f5j5n">115</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.rhv7ytpf40bl">DoG Pyramid</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.rhv7ytpf40bl">115</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.94rmmib8ayrb">Lecture 7: Local features and
                matching</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.94rmmib8ayrb">116</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.kv93s9lqardj">Local features and matching
                basics</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.kv93s9lqardj">116</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.a94ltbrr545s">Local Features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.a94ltbrr545s">116</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.uo3mtcmihwam">Why extract local features?</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.uo3mtcmihwam">116</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.o8qtj511mxa5">Example: Building a panorama</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.o8qtj511mxa5">116</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.vzbl4jemkzdb">Problem 1:</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.vzbl4jemkzdb">116</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.v5tbtuywcbar">Problem 2:</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.v5tbtuywcbar">117</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.667ot0q29brs">Two distinct types of matching
                problem</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.667ot0q29brs">117</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.z5cfwxbd2q3g">Narrow-baseline stereo</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.z5cfwxbd2q3g">117</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.c217tv97nlt2">Wide-baseline stereo</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.c217tv97nlt2">117</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.rl1wzlffpqks">Two distinct types of matching
                problem</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.rl1wzlffpqks">118</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.knnlmmm0f1eo">Robust local description</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.knnlmmm0f1eo">118</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.2l0pv3el8ip">Descriptor Requirements</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2l0pv3el8ip">118</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ffrg7zp5sqbc">Matching by correlation (template
                matching)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.ffrg7zp5sqbc">118</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.54go8u4x2ip6">(Narrow baseline) template
                matching</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.54go8u4x2ip6">118</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.kjybdojf3feh">Problems with wider baselines</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kjybdojf3feh">120</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.h3k19glbgll">Local Intensity Histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.h3k19glbgll">120</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.u6hohw8t1lca">Use local histograms instead of pixel
                patches</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.u6hohw8t1lca">120</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.bcuajgzcm5u0">Local histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.bcuajgzcm5u0">120</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.9qw6wvot1pj3">Overcoming localisation
                sensitivity</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.9qw6wvot1pj3">121</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.8j0g0w9614gy">Overcoming lack of illumination
                invariance</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.8j0g0w9614gy">121</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.t9mzxc5epxg8">Local Gradient Histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.t9mzxc5epxg8">121</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.2mogkv9ngvm2">Gradient Magnitudes and
                Directions</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.2mogkv9ngvm2">121</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.xdmc0mhafssu">Gradient Histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.xdmc0mhafssu">121</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.z7ppojyidx8v">Building gradient histograms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.z7ppojyidx8v">121</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.f14skbp3f7gx">Rotation Invariance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.f14skbp3f7gx">121</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.yeanesignxvv">The SIFT feature</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.yeanesignxvv">122</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.115gzxwf7ocl">Adding spatial awareness</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.115gzxwf7ocl">122</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.n5lhgh3yxan">SIFT Construction: sampling</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.n5lhgh3yxan">123</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.lloepz129yci">SIFT Construction: weighting</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.lloepz129yci">123</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.r99fc4uiwwqc">SIFT Construction: binning</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.r99fc4uiwwqc">123</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.4s9gpi5a0k9a">Matching SIFT features</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.4s9gpi5a0k9a">124</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.hpkjqhtinuoc">Euclidean Matching</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.hpkjqhtinuoc">124</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.nys8rasilcyk">Improving matching performance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.nys8rasilcyk">124</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.nmuw6dn8i020">Lecture 8: Consistent
                matching</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.nmuw6dn8i020">124</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.v61p14xdbuf9">Feature distinctiveness</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.v61p14xdbuf9">124</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.4dcuukn8u0ji">Constrained matching</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.4dcuukn8u0ji">125</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.p47y378x78t8">Geometric Mappings</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.p47y378x78t8">125</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.szoindpt596n">What are geometric transforms?</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.szoindpt596n">125</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.3y9nu1gliosj">Point Transforms</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.3y9nu1gliosj">125</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.2t35nvh8ktf8">The Affine Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2t35nvh8ktf8">125</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.tcu2nyev1sa0">Translation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.tcu2nyev1sa0">126</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.i86slkyzyvz2">Translation and Rotation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.i86slkyzyvz2">126</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.yqsn0mmodxwj">Scaling</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.yqsn0mmodxwj">126</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.la982dbsyv5t">Aspect Ratio</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.la982dbsyv5t">126</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.x85a8deg6f5i">Shear</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.x85a8deg6f5i">126</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.q6zvatlwypym">Degrees of Freedom</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.q6zvatlwypym">126</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.wpl9ssdfi9tt">Affine Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wpl9ssdfi9tt">129</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.sdeg1gdhr5bt">Similarity Transform</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.sdeg1gdhr5bt">130</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.h5lnl02h5m20">More degrees of freedom</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.h5lnl02h5m20">130</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.gybzp8rgcdx1">Homogeneous coordinates</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gybzp8rgcdx1">131</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.gzlo5cezv4by">The Planar Homography (Projective
                Transformation)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.gzlo5cezv4by">131</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.6h01l96qh3w3">Recovering a geometric mapping</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.6h01l96qh3w3">131</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.lobh3qgx7jej">Simultaneous equations</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.lobh3qgx7jej">131</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.qpgxw9ebmfwz">Least-squares</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.qpgxw9ebmfwz">132</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.dqzefd8s3rxm">Robust Estimation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.dqzefd8s3rxm">132</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.fqmx1z6ovw62">Problem: Noisy data</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.fqmx1z6ovw62">133</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ltogbcgd5mwc">Robust estimation techniques</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ltogbcgd5mwc">133</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.7b3n2rimkra">RANSAC: RANdom SAmple Consensus</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7b3n2rimkra">133</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.tszxj8k70th5">Further applications of robust local
                matching</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.tszxj8k70th5">134</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.rhjj7c3myh5c">Object recognition &amp; AR</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.rhjj7c3myh5c">134</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.7w7wc7i6ts61">3D reconstruction</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.7w7wc7i6ts61">134</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.7tgbqj1tuhbw">Problems with direct local feature
                matching</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.7tgbqj1tuhbw">134</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.gegp1v49xorn">Local feature matching is slow!</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gegp1v49xorn">134</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.cqy63c4g5pf4">Efficient Nearest Neighbour
                Search</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.cqy63c4g5pf4">134</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.br4w9beok9x8">K-D Trees</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.br4w9beok9x8">134</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.p6exul1isbpl">K-D Tree problems</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.p6exul1isbpl">135</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.2ns91rh6ogtq">Hashing</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2ns91rh6ogtq">137</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.i91ftrl89i72">Sketching</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.i91ftrl89i72">138</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.qm6is335tqam">Lecture 9: Image search and Bags of Visual
                Words</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.qm6is335tqam">138</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.kj7684lbh0xy">Text Information Retrieval</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kj7684lbh0xy">138</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.cszw2vs2nfxt">The bag data structure</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.cszw2vs2nfxt">138</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.iu4ukqoy6sn9">Bag of Words</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.iu4ukqoy6sn9">138</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.r7cubjp1kxys">Text processing (feature
                extraction)</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.r7cubjp1kxys">139</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.wp6dpvupt7ju">The Vector-Space Model</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wp6dpvupt7ju">139</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.qk348d10icl9">Bag of Words Vectors</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.qk348d10icl9">140</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.yt2hh2nqw8tt">The Vector-space Model</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.yt2hh2nqw8tt">140</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.z0nxr5bjz7ci">Searching the VSM</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.z0nxr5bjz7ci">141</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.whw51oxsv0ws">Recap: Cosine Similarity</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.whw51oxsv0ws">141</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.sh7m1mrqgvyu">Inverted Indexes</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.sh7m1mrqgvyu">141</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.epwoag43sy7">Computing the Cosine Similarity</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.epwoag43sy7">142</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.kgx6lglo3hg7">Weighting the vectors</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.kgx6lglo3hg7">142</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.gus1kmt2ss5q">Possible weighting schemes</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gus1kmt2ss5q">143</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.608thq1r83uq">Vector Quantisation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.608thq1r83uq">143</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.gmvt9otz6d0n">Learning a Vector Quantiser</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gmvt9otz6d0n">143</a></span></p>
    <p class="c54"><span class="c8"><a class="c0" href="#h.wiiev4ur5of1">Vector Quantisation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wiiev4ur5of1">143</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.h3cjrb9y5hgl">Visual Words</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.h3cjrb9y5hgl">144</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.lik4ufp2b31f">SIFT Visual Words</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.lik4ufp2b31f">144</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.wkq0cik291i6">Bags of Visual Words</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wkq0cik291i6">144</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.33vrpzdqzggk">Histograms of Bags of Visual
                Words</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.33vrpzdqzggk">145</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ovbs7g23s6zx">Visualising Visual Words</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ovbs7g23s6zx">146</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.keznjdmb2abu">The effect of codebook size</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.keznjdmb2abu">146</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.duva7wq7k6dw">Content-based Image Retrieval</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.duva7wq7k6dw">147</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.n20olp2clwfm">BoVW Retrieval</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.n20olp2clwfm">147</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.pmopc9y2tzfh">Optimal codebook size</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.pmopc9y2tzfh">147</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.rs0jr7b7mj19">Problems with big codebooks</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.rs0jr7b7mj19">147</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.6ijc0wdpooeh">Overall process for building a BoVW retrieval
                system</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.6ijc0wdpooeh">148</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.mjg0o93plsl8">Lecture 10: Image classification and
                auto-annotation</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.mjg0o93plsl8">148</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.y1uhj0bmn5jb">Multilabel classification</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.y1uhj0bmn5jb">148</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.r8atlnlaan9q">Object Detection / Localisation</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.r8atlnlaan9q">149</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.tdi28o987z9o">Slide summary: Challenges in Computer
                Vision</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.tdi28o987z9o">149</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ex37or3w10lx">Aside: Optimal codebook size</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ex37or3w10lx">150</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.wk5tvccx3g0q">Another slide summary: Stuff</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wk5tvccx3g0q">150</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.w6csm04hotkg">Dense Local Image Patches</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w6csm04hotkg">150</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.oz6l7u8i71ld">Dense SIFT</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.oz6l7u8i71ld">150</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.9xq7vq6q119k">Pyramid Dense SIFT</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.9xq7vq6q119k">151</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.ours0s7049jz">Spatial Pyramids</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ours0s7049jz">152</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.hb3qtat72ije">Developing and benchmarking a BoVW scene
                classifier</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.hb3qtat72ije">152</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.wktt7j1dxvv6">Evaluation Dataset</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.wktt7j1dxvv6">152</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.35gjms3btr3w">Building the BoVW</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.35gjms3btr3w">153</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.b74inykqb89i">Training classifiers</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.b74inykqb89i">153</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.tvkxxtnp7vpb">Classifying the test set</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.tvkxxtnp7vpb">153</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.hrs4l9b67zv5">Evaluating Performance</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.hrs4l9b67zv5">153</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.spxwuwtkjljg">Lecture 11: Towards 3D
                vision</a></span><span class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c30 c5"><a class="c0" href="#h.spxwuwtkjljg">153</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.2ekoomb6f6lt">Summary Summary</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.2ekoomb6f6lt">154</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.2po3i53z2ykf">Programming for computer vision &amp; other
                musings related to the coursework</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.2po3i53z2ykf">155</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.hmme0vxnjqiy">Writing code for computer
                vision</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.hmme0vxnjqiy">155</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.g34n15jupn2i">Most vision algorithms are
                continuous</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.g34n15jupn2i">155</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.kvspk4mrmqdt">Always work with floating point
                pixels</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.kvspk4mrmqdt">155</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.uvbvdbpaxwhm">Guidelines for writing vision
                code</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.uvbvdbpaxwhm">155</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.gfw67atdbn5x">Convolution</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gfw67atdbn5x">155</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.adllfqjatp2e">Aside: phase and magnitude</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.adllfqjatp2e">156</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.gfdnriorr11">Aside: Displaying FFTs</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.gfdnriorr11">156</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.58qqzn933xwu">Template Convolution</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.58qqzn933xwu">157</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.xkxgxpeu1a6y">What if you don&rsquo;t flip the
                kernel?</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.xkxgxpeu1a6y">158</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.w3ln0jlh0zum">Ideal Low-Pass filter</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.w3ln0jlh0zum">158</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.qqkydnh85njg">Ideal Low-Pass filter -
                problems</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            class="c8"><a class="c0" href="#h.qqkydnh85njg">159</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.ky501pcxpt4o">Gaussian filters - why</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.ky501pcxpt4o">160</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.v0z03j8ax760">Building Gaussian Filters</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.v0z03j8ax760">160</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.4au8qchl9ui">High-pass filters</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.4au8qchl9ui">161</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.71m9hzfnx1cz">Note - Don&rsquo;t do this!</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.71m9hzfnx1cz">161</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.6v4vm6kgouwl">High-pass filters have a mixture of negative
                and positive coefficients</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.6v4vm6kgouwl">162</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.jqamhqjsy0dg">Building hybrid images</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.jqamhqjsy0dg">162</a></span></p>
    <p class="c4"><span class="c8"><a class="c0" href="#h.en4ii6yp5vbp">&hellip;is really simple</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.en4ii6yp5vbp">162</a></span></p>
    <p class="c37"><span class="c30 c5"><a class="c0" href="#h.32vczl3k1335">TL;DR</a></span><span
            class="c30 c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c30 c5"><a class="c0"
                href="#h.32vczl3k1335">163</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.8j5rgmn7e95p">Part 1: Mark</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.8j5rgmn7e95p">164</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.k06zf8tvxd71">Part 2: Jon</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.k06zf8tvxd71">164</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.qpxqxvun8m4x">Lec 1</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.qpxqxvun8m4x">164</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.8p9k7os3yqle">Lec 2</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.8p9k7os3yqle">164</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.1b8lw1n9rer3">Lec 3</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.1b8lw1n9rer3">165</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.u4z9m0jn9o9i">Lec 4</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.u4z9m0jn9o9i">167</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.wy4sy56pq33z">Lec 5</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.wy4sy56pq33z">169</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.hoz14wvvq984">Lec 6</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.hoz14wvvq984">172</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.85lvrv7skst6">Lec 7</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.85lvrv7skst6">174</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.uy6r4e69lw72">Lec 8</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.uy6r4e69lw72">176</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.ywv90kepaecj">Lec 9</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.ywv90kepaecj">178</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.w4m6ow72tili">Lec 10</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.w4m6ow72tili">180</a></span></p>
    <p class="c34"><span class="c8"><a class="c0" href="#h.q25m2fdp23vb">TL;DR By Mark Towers</a></span><span
            class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c0"
                href="#h.q25m2fdp23vb">182</a></span></p>
    <p class="c4"><span class="c41"><a class="c0" href="#h.gr71k62go3oc">Mark (edited by Joshua Gregory)</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.gr71k62go3oc">182</a></span></p>
    <p class="c50 c106"><span class="c41"><a class="c0" href="#h.x8zi2cpk1e2d">Jon</a></span><span
            class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41"><a class="c0"
                href="#h.x8zi2cpk1e2d">187</a></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h1 class="c46" id="h.u3rdxkn44rsj"><span class="c31 c21">Notes intro</span></h1>
    <ul class="c10 lst-kix_b838rf08zn4-0 start">
        <li class="c7 li-bullet-0"><span class="c36 c13 c21">Basically this is a summary of the slides, plus some extra
                explanation.</span></li>
        <li class="c7 li-bullet-0"><span class="c13">Text which is coloured dark yellow: &ldquo;</span><span
                class="c29">like this</span><span class="c13">&rdquo;, is content from the slides I have decided to
                include as I think it is probably a bit important/interesting, even though there was no hand with bow
                for it: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 21.00px; height: 24.50px;"><img
                    alt="" src="assets/computer-vision/image348.png"
                    style="width: 21.00px; height: 24.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h1 class="c46" id="h.c60tptcb72mf"><span class="c31 c21">Introduction</span></h1>
    <p class="c9"><span class="c1">Images consist of picture elements known as &ldquo;pixels&rdquo;.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><img src="assets/computer-vision/image1.png"></p>
    <ul class="c10 lst-kix_rolfv8pp4863-0 start">
        <li class="c7 li-bullet-0"><span class="c1">(x,y) - location</span></li>
        <li class="c7 li-bullet-0"><span class="c1">z - depth</span></li>
        <li class="c7 li-bullet-0"><img src="assets/computer-vision/image2.png"><span class="c1">&nbsp;- colour</span></li>
        <li class="c7 li-bullet-0"><span class="c1">T - time</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">2D Images are matrices of numbers.</span></p>
    <ul class="c10 lst-kix_6z3lqm1vlxc1-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Grey level image</span></li>
        <li class="c7 li-bullet-0"><span class="c1">3D view</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Corresponding Matrix</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c2">Point Operations:</span></p>
    <ul class="c10 lst-kix_ryepwylg1jhf-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Recalculate point values</span></li>
    </ul>
    <ul class="c10 lst-kix_ryepwylg1jhf-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Modify Brightness</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Find Intensity</span></li>
    </ul>
    <p class="c9"><span class="c2">Group Operations:</span></p>
    <ul class="c10 lst-kix_as8rwdfmzacz-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Process neighbourhoods</span></li>
    </ul>
    <ul class="c10 lst-kix_as8rwdfmzacz-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Image filtering</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Edge detection</span></li>
    </ul>
    <p class="c9"><span class="c2">Feature Extraction</span></p>
    <ul class="c10 lst-kix_5pnqr78yj732-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Finds shapes</span></li>
    </ul>
    <ul class="c10 lst-kix_5pnqr78yj732-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Roads in remotely-sensed image</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Artery in ultrasound image</span></li>
    </ul>
    <p class="c3"><span class="c2"></span></p>
    <p class="c9"><span class="c2">Applications of Computer Vision</span></p>
    <ul class="c10 lst-kix_56ejth6g9ku9-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Image coding (MPEG/JPEG)</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Product inspection</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Robotics</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Modern cameras/phones</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Medical imaging</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Demography</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Biometrics</span></li>
    </ul>
    <p class="c3"><span class="c2"></span></p>
    <p class="c102 title" id="h.3i00vpestc24"><span>Part 1: Mark</span></p>
    <h1 class="c46" id="h.s6a9yo2qvoba"><span class="c31 c21">Lecture 1: Eye and Human Vision</span></h1>
    <p class="c45 subtitle" id="h.5b13qaoutb6p"><span>Is human vision a good model for computer vision?</span></p>
    <h2 class="c19" id="h.3vlet6ck734k"><span class="c23 c21">The human eye</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 355.14px; height: 314.50px;"><img
                alt="" src="assets/computer-vision/image315.png"
                style="width: 355.14px; height: 314.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Diagram of the human eye. Light comes in through the lens and is focused onto the
            retina. These light impulses are then sent through the optic nerve.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c103">Cones are photopic (Coloured vision) and Rods are scotopic (Black and white) (Nixon
            made a mistake on his notes) </span><span class="c1">- Thanks Tim :)</span></p>
    <h2 class="c19" id="h.xq9s4h48dvia"><span class="c23 c21">Optics</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 506.63px; height: 369.50px;"><img
                alt="" src="assets/computer-vision/image347.png"
                style="width: 506.63px; height: 369.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Image is flipped, just like a camera. Our brain works this out and we perceive it the
            right way up.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.ynp85x94awn0"><span class="c23 c21">Spectral responses</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 450.67px;"><img
                alt="" src="assets/computer-vision/image71.png"
                style="width: 602.00px; height: 450.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">The eye is most sensitive to green light, least to blue, but the point is that
            colours are at different response levels.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.7k0qsdpckrju"><span class="c23 c21">Mach bands</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 464.35px; height: 428.50px;"><img
                alt="" src="assets/computer-vision/image166.png"
                style="width: 464.35px; height: 428.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Mach bands are an optical illusion whereby the contrast between edges of slightly
            differing shades of grey is exaggerated when they are touching.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 196.00px; height: 131.00px;"><img
                alt="" src="assets/computer-vision/image112.gif"
                style="width: 196.00px; height: 131.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c43 c6 c21">[Source: Wikipedia]</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">This and many other optical illusions (edges, static, benham&rsquo;s disk... you can
            look at in the slides) demonstrate that our eyes can actually be not so good as a vision system.</span></p>
    <h2 class="c19" id="h.o1edcy8wcjx1"><span class="c23 c21">Neural processing</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 503.50px; height: 318.06px;"><img
                alt="" src="assets/computer-vision/image340.png"
                style="width: 503.50px; height: 318.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h1 class="c46" id="h.qr7i0cfd613j"><span class="c31 c21">Lecture 2: Image Formation</span></h1>
    <p class="c45 subtitle" id="h.46joqt4tnmlo"><span class="c38 c21">What is inside an image?</span></p>
    <h2 class="c19" id="h.koa7ohlu7fh6"><span class="c23 c21">Decomposition</span></h2>
    <p class="c9"><span class="c1">You can decompose an image into its bits.</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 245.33px;"><img
                alt="" src="assets/computer-vision/image273.png"
                style="width: 602.00px; height: 245.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_cqbxjxhrdocj-0 start">
        <li class="c7 li-bullet-0"><span class="c1">For a greyscale image, each pixel in the image is usually
                represented by 8 bits; a byte.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The number value ranges from 0-255, which represents all the
                greyscale colours from white to black.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">When you decompose an image, you are only looking at the one bit in
                each pixel, and this is either a 0 or 1, so either black or white.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">So for bit 0, only the first bit of each pixel is being shown in the
                image. As you can see this bit represents the least amount of information and is very noisy. </span>
        </li>
        <li class="c7 li-bullet-0"><span class="c1">As you look at the images increasing in the bit position, you can
                see more information is represented.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The main point here is that the image gets clearer as you go up to
                the most significant bit (bit 7).</span></li>
    </ul>
    <h2 class="c19" id="h.fda4lu9df2ko"><span class="c23 c21">Resolution</span></h2>
    <p class="c9"><span class="c1">Images are also (obviously) less detailed at lower resolutions.</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 225.33px;"><img
                alt="" src="assets/computer-vision/image201.png"
                style="width: 602.00px; height: 225.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.wxtfywxz52iv"><span class="c23 c21">Fourier Transform</span></h2>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">Any periodic function is the result of adding up sine and cosine waves of different
            frequencies.</span></p>
    <p class="c9"><span>[This is a good visual intuitive: </span><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DspUNpyF58BY&amp;sa=D&amp;source=editors&amp;ust=1623775880327000&amp;usg=AOvVaw1fP6c7ZjsQEBqOC4OIh1Jt">https://www.youtube.com/watch?v=spUNpyF58BY</a></span><span>]</span>
    </p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 418.00px; height: 92.00px;"><img
                alt="" src="assets/computer-vision/image133.png"
                style="width: 418.00px; height: 92.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_rdt49r9s1s5f-0 start">
        <li class="c7 li-bullet-0"><img src="assets/computer-vision/image3.png"><span class="c1">&nbsp;is the Fourier transform</span>
        </li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 22.00px; height: 27.00px;"><img
                    alt="" src="assets/computer-vision/image154.png"
                    style="width: 22.00px; height: 27.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span><span class="c1">denotes the Fourier transform process:</span></li>
        <li class="c7 li-bullet-0"><img src="assets/computer-vision/image2.png"><span>&nbsp;is the angular frequency, </span><img
                src="assets/computer-vision/image4.png"><span>measure in radians/s (where frequency </span><img
                src="assets/computer-vision/image5.png"><span>&nbsp;is the reciprocal of time </span><img
                src="assets/computer-vision/image6.png"><span>, </span><img src="assets/computer-vision/image7.png"><span class="c1">)</span></li>
        <li class="c7 li-bullet-0"><img src="assets/computer-vision/image8.png"><span>&nbsp;is the complex variable </span><img
                src="assets/computer-vision/image9.png"><span>&nbsp;(usually </span><img src="assets/computer-vision/image10.png"><span
                class="c1">)</span></li>
        <li class="c7 li-bullet-0"><img src="assets/computer-vision/image11.png"><span class="c1">&nbsp;is a continuous signal (varying
                continuously with time)</span></li>
        <li class="c7 li-bullet-0"><img src="assets/computer-vision/image12.png"><span>&nbsp;gives the frequency components in
            </span><img src="assets/computer-vision/image11.png"></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.raugx0r1u30"><span class="c23 c21">What the Fourier Transform actually does</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 422.67px;"><img
                alt="" src="assets/computer-vision/image349.png"
                style="width: 602.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c20">(To do: explain how a function that deals with (sound) waves can be used on images
            with pixels. If anyone reading can explain that&rsquo;d be great)</span></p>
    <p class="c3"><span class="c20"></span></p>
    <p class="c9"><span class="c20">A: The fourier transform is just a technique for mapping signals that vary in one
            dimension to the frequency domain of that dimension. In the case of audio this means transforming air
            pressure from the time domain to the (temporal) frequency domain. If we consider the intensity of an image
            to be our signal, which varies in space (let&#39;s say along the x axis), then the FT will transform the
            signal into spatial frequency in the x dimension.</span></p>
    <p class="c3"><span class="c20"></span></p>
    <p class="c9"><span class="c20">Now, we can generalise the fourier transform to take signals that are defined in
            more than one mutually orthogonal dimensions, e.g. an image represented by pixel intensity defined in x and
            y. Now the FT transforms the image into the (spatial) frequency domain, defined in two dimensions (spatial
            frequency in x, and spatial frequency in the y direction). Hope that helps? - James</span></p>
    <p class="c3"><span class="c20"></span></p>
    <ul class="c10 lst-kix_1u2jujfaplul-0 start">
        <li class="c7 li-bullet-0"><span>Pulse </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 370.00px; height: 91.00px;"><img
                    alt="" src="assets/computer-vision/image240.png"
                    style="width: 370.00px; height: 91.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Use Fourier </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 246.00px; height: 91.00px;"><img
                    alt="" src="assets/computer-vision/image275.png"
                    style="width: 246.00px; height: 91.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Evaluate integral </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 315.00px; height: 81.00px;"><img
                    alt="" src="assets/computer-vision/image113.png"
                    style="width: 315.00px; height: 81.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>And get result </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 385.00px; height: 133.00px;"><img
                    alt="" src="assets/computer-vision/image83.png"
                    style="width: 385.00px; height: 133.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.1xupejvn9gpk"><span class="c23 c21">A pulse and its Fourier transform</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 252.00px;"><img
                alt="" src="assets/computer-vision/image268.png"
                style="width: 602.00px; height: 252.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.gsw108thax1c"><span class="c23 c21">Reconstructing signal from its Fourier Transform</span>
    </h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 579.00px; height: 610.00px;"><img
                alt="" src="assets/computer-vision/image295.png"
                style="width: 579.00px; height: 610.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.ek4l8sln6f22"><span class="c23 c21">Magnitude and phase of the Fourier transform of a
            pulse</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 300.00px;"><img
                alt="" src="assets/computer-vision/image265.png"
                style="width: 602.00px; height: 300.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c58">Re() is the real function and Im() is the imaginary function so for expression
        </span><img src="assets/computer-vision/image13.png"><span class="c58">&nbsp;then </span><img src="assets/computer-vision/image14.png"><span
            class="c58">and </span><img src="assets/computer-vision/image15.png"><span class="c36 c58 c21">. In the complex plane, you
            can imagine the imaginary numbers as another number line with the real number as the other number. So to
            calculate the magnitude, it is Pythagoras&rsquo; theorem of the two numbers while the angle is the angle of
            the two numbers. For more information, look up complex numbers. (Thanks Mark ;) )</span></p>
    <p class="c9"><span class="c36 c58 c21">The magnitude is the scalar amount of the frequency and the phase is its
            offset (from a regular sin wave) (-Alex)</span></p>
    <p class="c3"><span class="c36 c58 c21"></span></p>
    <h1 class="c46" id="h.g5kvnta1x5y9"><span class="c31 c21">Lecture 3: Image Sampling</span></h1>
    <p class="c45 subtitle" id="h.1jje3so0tom1"><span class="c38 c21">How is an image sampled and what does it
            imply?</span></p>
    <h2 class="c19" id="h.utsmcrfhamoq"><span class="c23 c21">Aliasing in Sampled Imagery</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 260.00px;"><img
                alt="" src="assets/computer-vision/image266.png"
                style="width: 602.00px; height: 260.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_87w0gth4wrmr-0 start">
        <li class="c7 li-bullet-0"><span class="c1">As you can see the left image looks clearer as it is at a higher
                resolution, and therefore literally has more information than lower resolutions. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">The low resolution image on the right is aliased, and appears a bit
                blurry to the left image.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">This is probably a result of a low sampling rate.</span></li>
    </ul>
    <h3 class="c22" id="h.lzs9auur59vg"><span>Aliasing</span></h3>
    <p class="c9"><span class="c32 c78">Aliasing is an effect that causes different signals to become indistinguishable
            when sampled. It also often refers to the distortion or artifact that results when a signal reconstructed
            from samples is different from the original continuous signal.</span><span
            class="c32 c6 c78 c5">&nbsp;</span><span class="c32 c6 c78">[-Wiki]</span></p>
    <h2 class="c19" id="h.7i2xexvzifkh"><span class="c23 c21">Sampling Signals</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 280.00px;"><img
                alt="" src="assets/computer-vision/image77.png"
                style="width: 602.00px; height: 280.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_8f593ufpmfwu-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The original signal is a continuous function. We want to sample
                this, and have to do it digitally. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">If we sample at a good (high) rate, then we can capture a good
                representation of the signal. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">If we sample at a bad (low) rate, then this captured signal become
                aliased, and is not a good representation.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">As you can see, the signal wave is completely the wrong
                representation from the original image.</span></li>
    </ul>
    <h2 class="c19" id="h.y3c92p8cee9m"><span class="c23 c21">Wheels Motion</span></h2>
    <ul class="c10 lst-kix_ceehpqm2yjd8-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Have you ever seen a wheel (or propeller) turn sooooooooooo fast in
                a video (or even real life) that it looks like it&rsquo;s not turning at all!? </span></li>
        <li class="c7 li-bullet-0"><span class="c1">Or even turning the wrong way!?!!??!??</span></li>
        <li class="c7 li-bullet-0"><span class="c1">This is due to the sampling rate the wheel is captured at.</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 208.00px;"><img
                alt="" src="assets/computer-vision/image335.png"
                style="width: 602.00px; height: 208.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_juntneqypmdo-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The wheel is spinning faster or slower to (a multiple) of the
                sampling rate.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">This can cause the illusion of standing or reverse turning.</span>
        </li>
        <li class="c7 li-bullet-0"><span class="c1">Look up some videos or something to see this in action.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The point is the sampling rate matters in vision.</span></li>
    </ul>
    <h2 class="c19" id="h.2csxltjk3xt9"><span class="c23 c21">Sampling Theory</span></h2>
    <ul class="c10 lst-kix_5825ctxjl5zs-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Nyquist&rsquo;s sampling theorem is 1D.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">E.g. speech 6kHz, sample at 12 kHz.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Video bandwidth (CCIR) is 5 MHz.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Sampling at 10 MHz gave 576x576 images.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Guideline: &ldquo;two pixels for every pixel of
                interest&rdquo;.</span></li>
    </ul>
    <h2 class="c19" id="h.17if0t24uylf"><span class="c23 c21">Transform Pair from Sampled Pulse</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 246.67px;"><img
                alt="" src="assets/computer-vision/image270.png"
                style="width: 602.00px; height: 246.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 422.67px;"><img
                alt="" src="assets/computer-vision/image158.png"
                style="width: 602.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">Some stuff to do with the Fourier Transform&hellip;</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c20">(If anyone could explain what these graphs are demonstrating that&rsquo;d be
            epic)</span></p>
    <p class="c3"><span class="c20"></span></p>
    <p class="c9"><span class="c49">A: It&rsquo;s showing the effect of adding reconstructing the sampled signal from
            its frequency components. However, the images for (b) and (c) are the wrong way around. Essentially
            it&rsquo;s trying to demonstrate that as you add more frequency components from the transform of the sampled
            signal, the reconstruction becomes a better approximation of the sampled signal, until eventually (f) all
            the frequency </span><span class="c49">components</span><span class="c20">&nbsp;are present and the
            reconstruction is perfect [(a) and (f) are identical]. - James</span></p>
    <p class="c3"><span class="c20"></span></p>
    <h2 class="c19" id="h.y2ajgvsy24o7"><span class="c23 c21">2D Fourier Transform</span></h2>
    <ul class="c10 lst-kix_ihzqatq11p4e-0 start">
        <li class="c7 li-bullet-0"><span>The Fourier Transform has a </span><span class="c5">forward </span><span>and
            </span><span class="c5">inverse </span><span class="c1">function.</span></li>
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">forward </span><span>transform: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 379.00px; height: 86.00px;"><img
                    alt="" src="assets/computer-vision/image73.png"
                    style="width: 379.00px; height: 86.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_ihzqatq11p4e-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Where there are </span></li>
    </ul>
    <ul class="c10 lst-kix_ihzqatq11p4e-2 start">
        <li class="c9 c12 li-bullet-0"><span>Two dimensions of space, </span><span class="c6">x </span><span>and
            </span><span class="c43 c6 c21">y</span></li>
        <li class="c9 c12 li-bullet-0"><span>Two dimensions of frequency, </span><span class="c6">u </span><span>and
            </span><span class="c43 c6 c21">v</span></li>
        <li class="c9 c12 li-bullet-0"><span>Image </span><span class="c6">NxN</span><span>&nbsp;pixels </span><span
                class="c5">P</span><span class="c42 c6">x,y</span></li>
    </ul>
    <p class="c3"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_ihzqatq11p4e-0">
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">inverse </span><span>transform: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 324.00px; height: 85.00px;"><img
                    alt="" src="assets/computer-vision/image236.png"
                    style="width: 324.00px; height: 85.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 283.00px; height: 211.00px;"><img
                    alt="" src="assets/computer-vision/image78.png"
                    style="width: 283.00px; height: 211.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_ihzqatq11p4e-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Lol</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.ru1t3s7nh578"><span class="c11">Reconstruction (non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 501.33px;"><img
                alt="" src="assets/computer-vision/image64.png"
                style="width: 602.00px; height: 501.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.2seqon9ny58p"><span class="c23 c21">Shift Invariance</span></h2>
    <ul class="c10 lst-kix_otcucdv1wpm8-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Images can be shifted.</span></li>
        <li class="c7 li-bullet-0"><span>What happens to the magnitude and phase of the fourier transform from shifted
                images.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 361.33px;"><img
                alt="" src="assets/computer-vision/image325.png"
                style="width: 602.00px; height: 361.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_fd2rht1g70d-0 start">
        <li class="c7 li-bullet-0"><span class="c1">This shows that the magnitude is not affected by shifting.</span>
        </li>
        <li class="c7 li-bullet-0"><span class="c1">But the phase is affected by shifting.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">What about for rotation?</span></li>
    </ul>
    <h2 class="c19" id="h.s7ggx4p0trm4"><span class="c23 c21">Rotation Invariance</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 192.00px;"><img
                alt="" src="assets/computer-vision/image245.png"
                style="width: 602.00px; height: 192.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_tdfbmy92mcwu-0 start">
        <li class="c7 li-bullet-0"><span class="c1">As you can see, the transform is just rotated too.</span></li>
    </ul>
    <h2 class="c19" id="h.nqpliez1yxlm"><span class="c23 c21">Filtering</span></h2>
    <ul class="c10 lst-kix_9n49k7sw2fqg-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Fourier gives access to frequency components.</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 194.00px; height: 194.00px;"><img
                    alt="" src="assets/computer-vision/image172.png"
                    style="width: 194.00px; height: 194.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_9n49k7sw2fqg-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Original Image</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_9n49k7sw2fqg-0">
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 196.00px;"><img
                    alt="" src="assets/computer-vision/image115.png"
                    style="width: 602.00px; height: 196.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_9n49k7sw2fqg-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Transforms</span></li>
    </ul>
    <h2 class="c19" id="h.5ft9mcodohws"><span class="c23 c21">Other Transforms</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 305.33px;"><img
                alt="" src="assets/computer-vision/image103.png"
                style="width: 602.00px; height: 305.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.pagfk6ypugwl"><span class="c23 c21">Applications of 2D Fourier Transform</span></h2>
    <ul class="c10 lst-kix_s63j48gbcv3-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Understanding and analysis</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Speeding up algorithms</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Representation (invariance)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Coding</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Recognition / understanding (e.g. texture)</span></li>
    </ul>
    <h1 class="c46" id="h.6telsegzeux8"><span class="c31 c21">Lecture 4: Point Operators</span></h1>
    <p class="c45 subtitle" id="h.nktozvcdrv4g"><span class="c38 c21">How many different operators are there which
            operate on image points?</span></p>
    <h2 class="c19" id="h.6drwr87kekh7"><span class="c23 c21">Image Histograms</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 189.33px;"><img
                alt="" src="assets/computer-vision/image79.png"
                style="width: 602.00px; height: 189.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_wyqhmbmylq61-0 start">
        <li class="c7 li-bullet-0"><span class="c1">A histogram is a graph of frequency. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">In this context it is showing how many pixels have a certain
                brightness level. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">This data is a global feature.</span></li>
    </ul>
    <h2 class="c19" id="h.7jcpjrz8waba"><span class="c23 c21">Brightening an Image</span></h2>
    <ul class="c10 lst-kix_mna34ghx2tk9-0 start">
        <li class="c7 li-bullet-0"><span class="c1">An Image can be brightened by using this formula:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 212.00px; height: 48.00px;"><img
                    alt="" src="assets/computer-vision/image76.png"
                    style="width: 212.00px; height: 48.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c1">Where:</span></li>
    </ul>
    <ul class="c10 lst-kix_mna34ghx2tk9-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">N</span><span class="c1">&nbsp;-
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new image</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">O </span><span class="c1">-
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old image</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c6">k </span><span class="c1">-
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;gain</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c6">l </span><span class="c1">-
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c6">x,y </span><span class="c1">-
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;coordinates</span></li>
    </ul>
    <h2 class="c19" id="h.mpamkzzb0c88"><span class="c23 c21">Intensity Mappings</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 469.33px;"><img
                alt="" src="assets/computer-vision/image96.png"
                style="width: 602.00px; height: 469.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.k3kucmg2oad"><span class="c11">Exponential/Logarithmic Point Operators (non examinable)</span>
    </h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 234.67px;"><img
                alt="" src="assets/computer-vision/image278.png"
                style="width: 602.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span class="c1">Intensity Normalisation</span></p>
    <ul class="c10 lst-kix_b4n81g4a1h1i-0 start">
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 529.50px; height: 71.25px;"><img
                    alt="" src="assets/computer-vision/image165.png"
                    style="width: 529.50px; height: 71.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_b4n81g4a1h1i-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">N </span><span class="c1">- new image</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">O</span><span class="c1">&nbsp;- old image</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c6">x,y </span><span class="c1">- coordinates</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">N</span><span class="c1">max - maximum input</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">N</span><span class="c1">min - minimum input</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">O</span><span class="c1">max - maximum output</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">O</span><span class="c1">min - minimum output</span></li>
    </ul>
    <ul class="c10 lst-kix_b4n81g4a1h1i-0">
        <li class="c7 li-bullet-0"><span class="c1">Avoids need for parameter choice</span></li>
    </ul>
    <h2 class="c19" id="h.uxk7c5mfkpjp"><span class="c23 c21">Intensity normalisation and histogram equalisation</span>
    </h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 456.00px;"><img
                alt="" src="assets/computer-vision/image146.png"
                style="width: 602.00px; height: 456.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.6qf1dortzp99"><span class="c23 c21">Histogram Equalisation</span></h2>
    <ul class="c10 lst-kix_z261et5jw61s-0 start">
        <li class="c7 li-bullet-0"><span class="c6">N</span><span class="c6 c66">2</span><span>&nbsp;points in the
                image; the sum of points per level is equal &nbsp;</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 216.00px; height: 82.00px;"><img
                    alt="" src="assets/computer-vision/image285.png"
                    style="width: 216.00px; height: 82.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Cumulative histogram up to level </span><span
                class="c6">p</span><span>&nbsp;should be transformed to cover up to the level </span><span class="c6">q
            </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 205.00px; height: 79.00px;"><img
                    alt="" src="assets/computer-vision/image280.png"
                    style="width: 205.00px; height: 79.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Number of points per level in the output picture </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 263.00px; height: 80.00px;"><img
                    alt="" src="assets/computer-vision/image93.png"
                    style="width: 263.00px; height: 80.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Cumulative histogram of the output picture</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 319.00px; height: 74.00px;"><img
                    alt="" src="assets/computer-vision/image134.png"
                    style="width: 319.00px; height: 74.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Mapping for the output pixels at level </span><span
                class="c6">q</span><span>&nbsp;</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 314.00px; height: 83.00px;"><img
                    alt="" src="assets/computer-vision/image148.png"
                    style="width: 314.00px; height: 83.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.1ckjb6vuzlx6"><span class="c11">Applying intensity normalisation and histogram
            equalisation</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 225.33px;"><img
                alt="" src="assets/computer-vision/image164.png"
                style="width: 602.00px; height: 225.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.8ngqvh6dthc3"><span class="c23 c21">Thresholding and eye image</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 256.00px;"><img
                alt="" src="assets/computer-vision/image66.png"
                style="width: 602.00px; height: 256.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.sh1v1yo2asf4"><span class="c11">Thresholding: Manual vs Automatic</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 188.00px;"><img
                alt="" src="assets/computer-vision/image203.png"
                style="width: 602.00px; height: 188.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 221.33px;"><img
                alt="" src="assets/computer-vision/image98.png"
                style="width: 602.00px; height: 221.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c2">Other thresholding includes Entropic thresholding and Optimal Thresholding</span></p>
    <h1 class="c46" id="h.r60lp14xtz3o"><span class="c31 c21">Lecture 5: Group Operators</span></h1>
    <p class="c45 subtitle" id="h.o23equmj5p91"><span class="c38 c21">How do we combine points to make a new point in a
            new image?</span></p>
    <h2 class="c19" id="h.rgogy2m4wjgl"><span class="c23 c21">Template Convolution</span></h2>
    <p class="c9"><span class="c36 c81 c21">I&rsquo;m sure everyone knows about this by now&hellip;</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 376.00px;"><img
                alt="" src="assets/computer-vision/image234.png"
                style="width: 602.00px; height: 376.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">This is when you take an original image and then apply a convolution template over
            every pixel to create a resultant pixel value.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 357.33px;"><img
                alt="" src="assets/computer-vision/image86.png"
                style="width: 602.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c20">(to do: more explanation&hellip;)</span></p>
    <p class="c3"><span class="c20"></span></p>
    <ul class="c10 lst-kix_ublsj8cxkmaz-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Convolution is a system response</span></li>
    </ul>
    <ul class="c10 lst-kix_ublsj8cxkmaz-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 440.50px; height: 87.08px;"><img
                    alt="" src="assets/computer-vision/image159.png"
                    style="width: 440.50px; height: 87.08px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_ublsj8cxkmaz-0">
        <li class="c7 li-bullet-0"><span>Template convolution includes coordinate inversion in </span><span
                class="c6">x</span><span>&nbsp;and in </span><span class="c6">y</span></li>
    </ul>
    <ul class="c10 lst-kix_ublsj8cxkmaz-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 509.11px; height: 67.50px;"><img
                    alt="" src="assets/computer-vision/image68.png"
                    style="width: 509.11px; height: 67.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_ublsj8cxkmaz-0">
        <li class="c7 li-bullet-0"><span class="c1">Inversion is not needed if the template is symmetric</span></li>
    </ul>
    <h2 class="c19" id="h.bv76o1e6lbap"><span class="c23 c21">3x3 template and weighting coefficients</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 451.00px; height: 283.00px;"><img
                alt="" src="assets/computer-vision/image67.png"
                style="width: 451.00px; height: 283.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span>Where </span><span class="c6">w</span><span class="c42 c6">i,j</span><span>&nbsp;are the weights
            and </span><span class="c6">x(i), y(j)</span><span class="c1">&nbsp;denote the position of the point that
            matches the weighting coefficient position</span></p>
    <h2 class="c19" id="h.vr8heioavsbo"><span class="c23 c21">3x3 averaging operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 277.33px;"><img
                alt="" src="assets/computer-vision/image269.png"
                style="width: 602.00px; height: 277.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.s6srnnxi407x"><span class="c23 c21">Illustrating the effect of window size</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 213.33px;"><img
                alt="" src="assets/computer-vision/image255.png"
                style="width: 602.00px; height: 213.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Larger windows lead to more blur.</span></p>
    <h2 class="c19" id="h.5qwoy67hrjcb"><span class="c23 c21">Template convolution via the Fourier transform</span></h2>
    <p class="c9"><span class="c1">Allows for fast computation for template sizes &gt;= 7x7</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 311.00px; height: 60.00px;"><img
                alt="" src="assets/computer-vision/image111.png"
                style="width: 311.00px; height: 60.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_vm2jom7zb6zf-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Template convolution: *</span></li>
        <li class="c7 li-bullet-0"><span>Fourier transform of the picture: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 38.98px; height: 24.50px;"><img
                    alt="" src="assets/computer-vision/image161.png"
                    style="width: 38.98px; height: 24.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Fourier transform of the template: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 39.77px; height: 23.50px;"><img
                    alt="" src="assets/computer-vision/image294.png"
                    style="width: 39.77px; height: 23.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c1">Point by point multiplication (.&times;)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">Note: it&rsquo;s point by point! The equation is wrongly written in various
            places.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 393.33px;"><img
                alt="" src="assets/computer-vision/image300.png"
                style="width: 602.00px; height: 393.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.2x9jp0fp4wv9"><span class="c23 c21">2D Gaussian function</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 304.00px; height: 124.00px;"><img
                alt="" src="assets/computer-vision/image334.png"
                style="width: 304.00px; height: 124.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_mjilgemo5a56-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Used to calculate template values</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Note compromise between variance &sigma;&sup2; and window
                size</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Common choices</span></li>
    </ul>
    <ul class="c10 lst-kix_mjilgemo5a56-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">5x5, 1.0</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">7x7, 1.2</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">9x9, 1.4</span></li>
    </ul>
    <h3 class="c22" id="h.eljctdpui0i2"><span class="c26 c21">2D Gaussian template</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 226.67px;"><img
                alt="" src="assets/computer-vision/image109.png"
                style="width: 602.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.9ughi4p1i2yy"><span class="c23 c21">Applying Gaussian averaging</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 178.67px;"><img
                alt="" src="assets/computer-vision/image178.png"
                style="width: 602.00px; height: 178.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.3uljj9ropf2a"><span class="c23 c21">Finding the median from a 3x3 template</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 220.00px;"><img
                alt="" src="assets/computer-vision/image122.png"
                style="width: 602.00px; height: 220.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_5p69x5flbx05-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Preserves edges</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Removes salt and pepper noise</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 230.67px;"><img
                alt="" src="assets/computer-vision/image152.png"
                style="width: 602.00px; height: 230.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.l2x6zsge0fob"><span class="c11">Newer stuff (non-examinable)</span></h2>
    <p class="c9"><span class="c2">Averaging which preserves regions</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 306.67px;"><img
                alt="" src="assets/computer-vision/image318.png"
                style="width: 602.00px; height: 306.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.363myf528l6r"><span class="c48 c29 c21">Applying non local means</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 465.33px;"><img
                alt="" src="assets/computer-vision/image61.png"
                style="width: 602.00px; height: 465.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.rd1wzi7hb98m"><span class="c48 c29 c21">Even newer stuff: Image Ray Transform</span></h3>
    <p class="c9"><span class="c2">Use analogy to light to find shapes, removing the remainder</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 322.67px;"><img
                alt="" src="assets/computer-vision/image168.png"
                style="width: 602.00px; height: 322.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.v7lnzpjmxsn4"><span class="c48 c29 c21">Applying Image Ray Transform</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 372.00px;"><img
                alt="" src="assets/computer-vision/image309.png"
                style="width: 602.00px; height: 372.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.pnrxn2wjz81g"><span class="c48 c29 c21">Comparing operators</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 561.33px;"><img
                alt="" src="assets/computer-vision/image311.png"
                style="width: 602.00px; height: 561.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h1 class="c46" id="h.a23nf1qm73o1"><span class="c31 c21">Lecture 6: Edge Detection</span></h1>
    <p class="c45 subtitle" id="h.fwn5bs6hs579"><span class="c38 c21">What are edges and how do we find them?</span></p>
    <h2 class="c19" id="h.poti69atue89"><span class="c23 c21">Edge detection</span></h2>
    <ul class="c10 lst-kix_11e54udr7059-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Images have edges in them.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">It&rsquo;s a very useful thing to find these edges in computer
                vision.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">There are a few different operators for edge detection of an
                image.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">It involves maths.</span></li>
    </ul>
    <h2 class="c19" id="h.nv01ocsxcyi6"><span class="c23 c21">First order edge detection</span></h2>
    <ul class="c10 lst-kix_uvf9wfe8lbe1-0 start">
        <li class="c7 li-bullet-0"><span class="c1">You can detect vertical and horizontal separately.</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 310.67px;"><img
                    alt="" src="assets/computer-vision/image281.png"
                    style="width: 602.00px; height: 310.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_x6mk9hy92191-0 start">
        <li class="c7 li-bullet-0"><span>Vertical edges, </span><span
                class="c5">Ex</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 231.00px; height: 51.00px;"><img
                    alt="" src="assets/computer-vision/image207.png"
                    style="width: 231.00px; height: 51.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Horizontal edges, </span><span class="c5">Ey</span><span>&nbsp;</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 230.00px; height: 49.00px;"><img
                    alt="" src="assets/computer-vision/image141.png"
                    style="width: 230.00px; height: 49.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Vertical and horizontal edges: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 338.00px; height: 62.00px;"><img
                    alt="" src="assets/computer-vision/image123.png"
                    style="width: 338.00px; height: 62.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_vdta214mmnio-0 start">
        <li class="c7 li-bullet-0"><span>Template: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 297.00px; height: 91.00px;"><img
                    alt="" src="assets/computer-vision/image346.png"
                    style="width: 297.00px; height: 91.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Code: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 116.00px;"><img
                    alt="" src="assets/computer-vision/image310.png"
                    style="width: 602.00px; height: 116.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.t1jujyvca2jd"><span class="c23 c21">Edge detection maths</span></h2>
    <ul class="c10 lst-kix_srrk8qmph2uh-0 start">
        <li class="c7 li-bullet-0"><span>Taylor expansion for </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 50.67px;"><img
                    alt="" src="assets/computer-vision/image329.png"
                    style="width: 602.00px; height: 50.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c1">By rearrangement </span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 383.00px; height: 76.00px;"><img
                alt="" src="assets/computer-vision/image204.png"
                style="width: 383.00px; height: 76.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_k9e2wa3n98u1-0 start">
        <li class="c7 li-bullet-0"><span class="c1">This is equivalent to</span></li>
    </ul>
    <p class="c9"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 269.00px; height: 60.00px;"><img
                alt="" src="assets/computer-vision/image60.png"
                style="width: 269.00px; height: 60.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_1olqkng2pbhc-0 start">
        <li class="c7 li-bullet-0"><span>Expand </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 168.00px;"><img
                    alt="" src="assets/computer-vision/image145.png"
                    style="width: 602.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.vwjili3ejkm1"><span class="c23 c21">Templates for improved first order difference</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 96.00px;"><img
                alt="" src="assets/computer-vision/image263.png"
                style="width: 602.00px; height: 96.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.w6etzb93kgix"><span class="c23 c21">Edge Detection in Vector Format</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 217.33px;"><img
                alt="" src="assets/computer-vision/image169.png"
                style="width: 602.00px; height: 217.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.48w5z9pnhlny"><span class="c23 c21">Templates for Prewitt operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 101.33px;"><img
                alt="" src="assets/computer-vision/image274.png"
                style="width: 602.00px; height: 101.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.oxpmszan1wnu"><span class="c26 c21">Applying the Prewitt Operator</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 353.33px;"><img
                alt="" src="assets/computer-vision/image124.png"
                style="width: 602.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.cpee65aduznx"><span class="c23 c21">Templates for Sobel operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 101.33px;"><img
                alt="" src="assets/computer-vision/image296.png"
                style="width: 602.00px; height: 101.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_e7cxl7hyyu4f-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The two kernels used for the 3 x 3 sobel operator.</span></li>
    </ul>
    <h2 class="c19" id="h.fwie2y64dpq4"><span class="c23 c21">Applying Sobel operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 174.67px;"><img
                alt="" src="assets/computer-vision/image137.png"
                style="width: 602.00px; height: 174.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.ri2bfihw9zsn"><span>Generalising Sobel</span></h2>
    <ul class="c10 lst-kix_99f9u0a3qip4-0 start">
        <li class="c7 li-bullet-0"><span>Averaging </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 491.50px; height: 142.88px;"><img
                    alt="" src="assets/computer-vision/image223.png"
                    style="width: 491.50px; height: 142.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>Differencing </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 498.50px; height: 136.82px;"><img
                    alt="" src="assets/computer-vision/image163.png"
                    style="width: 498.50px; height: 136.82px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.ypmu5mxcf6t2"><span class="c29">Generalised Sobel (non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 593.00px; height: 372.00px;"><img
                alt="" src="assets/computer-vision/image185.png"
                style="width: 593.00px; height: 372.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h1 class="c46" id="h.z8xfmpffewkt"><span class="c31 c21">Lecture 7: Further Edge Detection</span></h1>
    <p class="c45 subtitle" id="h.m25dmwmnooqp"><span class="c38 c21">What better ways are there to detect edges?</span>
    </p>
    <h2 class="c19" id="h.kiathytlgbbw"><span class="c23 c21">Canny edge detection operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 222.67px;"><img
                alt="" src="assets/computer-vision/image246.png"
                style="width: 602.00px; height: 222.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Formulated with three main objectives:</span></p>
    <ul class="c10 lst-kix_ooc5u6ju46yb-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Optimal detection with no spurious responses</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Good localisation with minimal distance between detected and true
                edge position</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Single response to eliminate multiple responses to a single
                edge.</span></li>
    </ul>
    <p class="c9"><span class="c1">Approximation</span></p>
    <ol class="c10 lst-kix_h2r0xjmqmkdz-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Use Gaussian smoothing</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Use the Sobel operator (could combine with 1?)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Use non-maximal suppression</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Threshold with hysteresis to connect edge points</span></li>
    </ol>
    <h2 class="c19" id="h.maqnl8o22vhp"><span class="c23 c21">Interpolation in non-maximum suppression</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 597.00px; height: 415.00px;"><img
                alt="" src="assets/computer-vision/image292.png"
                style="width: 597.00px; height: 415.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_o6o895gh9lm2-0 start">
        <li class="c7 li-bullet-0"><span class="c20">Sobel edge detection is first order (equivalent to differentiation)
                so gives us the change in x and the change in y, which we turn into a vector and use to find the
                gradient direction (the dotted line in the diagram above), which will intuitively be at right angles to
                the direction of the line (the non-dotted line above). </span></li>
        <li class="c7 li-bullet-0"><span class="c20">In non-maximum suppression, we set all points that aren&rsquo;t a
                maximum along the line to zero (thereby thinning and sharpening the line). </span></li>
    </ul>
    <ul class="c10 lst-kix_o6o895gh9lm2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c20">This is done by taking a line of points along the gradient
                (dotted line) and setting all the points to zero, except those at a maximum. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c20">Interpolation is used to figure out the values of points
                between pixels.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c20">Alternatively, we can round the direction to the nearest
                horizontal/vertical/diagonal line</span></li>
    </ul>
    <p class="c9"><span class="c20">(Thanks Samuel Collins)</span></p>
    <h2 class="c19" id="h.l2unabxihzo"><span class="c23 c21">Hysteresis thresholding transfer function</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 350.67px;"><img
                alt="" src="assets/computer-vision/image149.png"
                style="width: 602.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">To help better understand the function an example:</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_9rta2vczpf6y-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The level is currently at black</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Brightness is increased until it reaches and passes the &ldquo;upper
                switching threshold&rdquo;</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The level now changes to white</span></li>
        <li class="c7 li-bullet-0"><span class="c1">If the brightness is decreased and goes below the &ldquo;upper
                switching threshold&rdquo; it will not switch to black</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The brightness will have to decrease until it is below the
                &ldquo;lower switching threshold&rdquo;, then it will switch back to black.</span></li>
    </ul>
    <h2 class="c19" id="h.54cft2uhljs"><span class="c23 c21">Action of non-maximum suppression and hysteresis
            thresholding</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.84px; height: 394.50px;"><img
                alt="" src="assets/computer-vision/image249.png"
                style="width: 554.84px; height: 394.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.5dhvqr2ue8x8"><span class="c23 c21">Hysteresis thresholding vs uniform thresholding</span>
    </h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 226.67px;"><img
                alt="" src="assets/computer-vision/image170.png"
                style="width: 602.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">As you can see, hysteresis thresholding is arguably better.</span></p>
    <h2 class="c19" id="h.70f9y4syypeu"><span class="c23 c21">Canny vs Sobel</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 402.67px;"><img
                alt="" src="assets/computer-vision/image150.png"
                style="width: 602.00px; height: 402.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.nucyakitr4jz"><span class="c23 c21">First and second order edge detection</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 495.00px; height: 401.00px;"><img
                alt="" src="assets/computer-vision/image62.png"
                style="width: 495.00px; height: 401.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.ome8giktir7a"><span class="c23 c21">Edge detection via the Laplacian operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 274.67px;"><img
                alt="" src="assets/computer-vision/image135.png"
                style="width: 602.00px; height: 274.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.7iddkrpcix6"><span class="c23 c21">Mathbelts on&hellip;</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.07px; height: 366.50px;"><img
                alt="" src="assets/computer-vision/image261.png"
                style="width: 576.07px; height: 366.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">(I think this is essentially just rearranging an equation)</span></p>
    <h2 class="c19" id="h.n8v1bc8n6lfh"><span class="c23 c21">Shape of Laplacian of Gaussian operator</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.00px; height: 349.00px;"><img
                alt="" src="assets/computer-vision/image326.png"
                style="width: 551.00px; height: 349.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.hcmf1p4g73j"><span class="c23 c21">Zero crossing detection</span></h2>
    <ul class="c10 lst-kix_jb997f22g63j-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Basic - straight comparison</span></li>
        <li class="c7 li-bullet-0"><span>Advanced: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 574.50px; height: 298.70px;"><img
                    alt="" src="assets/computer-vision/image140.png"
                    style="width: 574.50px; height: 298.70px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c1">You could compare every point to try and find where a 1 switches to
                0.</span></li>
    </ul>
    <ul class="c10 lst-kix_jb997f22g63j-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">That&rsquo;s not that smart.</span></li>
    </ul>
    <ul class="c10 lst-kix_jb997f22g63j-0">
        <li class="c7 li-bullet-0"><span class="c1">So you average the 4 points in the corners</span></li>
    </ul>
    <ul class="c10 lst-kix_jb997f22g63j-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Then you get 4 summations</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">If one of those is positive and another is negative, then there
                is a zero crossing.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.l0gsjfn55919"><span>Marr-Hildreth edge detection</span></h2>
    <ul class="c10 lst-kix_per6gd28bce4-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Application of LoG (or DoG) and zero-crossing detection.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 190.67px;"><img
                alt="" src="assets/computer-vision/image199.png"
                style="width: 602.00px; height: 190.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.q8uvwjtr10v6"><span class="c23 c21">Comparison of edge detection operators</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 332.00px;"><img
                alt="" src="assets/computer-vision/image94.png"
                style="width: 602.00px; height: 332.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.bkbo49qovp4r"><span class="c11">Newer stuff - interest detections (non-examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 294.67px;"><img
                alt="" src="assets/computer-vision/image338.png"
                style="width: 602.00px; height: 294.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.8cfmcn38vzev"><span class="c11">Newer stuff - saliency</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 173.33px;"><img
                alt="" src="assets/computer-vision/image226.png"
                style="width: 602.00px; height: 173.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h1 class="c46" id="h.b6h9b1xpm1ul"><span class="c31 c21">Lecture 8: Finding Shapes</span></h1>
    <p class="c45 subtitle" id="h.4fdhxvb5s36t"><span class="c38 c21">How can we group points to find shapes?</span></p>
    <h2 class="c19" id="h.wphzqhcwf5de"><span class="c23 c21">Feature extraction by thresholding</span></h2>
    <ul class="c10 lst-kix_i3keu7q2rc6y-0 start">
        <li class="c7 li-bullet-0"><span>Let&rsquo;s try to extract features from this image using thresholding.</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 185.33px;"><img
                alt="" src="assets/computer-vision/image195.png"
                style="width: 602.00px; height: 185.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_l5addaeqjjcs-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Low threshold doesn&#39;t look that good.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Neither does the high threshold.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">In conclusion: we need to identify shape!</span></li>
    </ul>
    <h2 class="c19" id="h.ahgye3gca4ro"><span>Template Matching</span></h2>
    <ul class="c10 lst-kix_bw6a2wefp7cd-0 start">
        <li class="c7 li-bullet-0"><span class="c1">This is a technique for finding small parts of an image which match
                a template image.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Intuitively simple</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Correlation and convolution</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Implementation via Fourier</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Relationship with matched filter, viz: optimality</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 168.00px;"><img
                alt="" src="assets/computer-vision/image126.png"
                style="width: 602.00px; height: 168.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_462z6a3zp1yn-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The template is the silverstone sign.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">This can be found in the image with template matching</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The accumulator space is a thing</span></li>
    </ul>
    <h2 class="c19" id="h.o4ukfk6oe1tb"><span class="c23 c21">Template matching in:</span></h2>
    <h3 class="c22" id="h.qh5yqve8ye7n"><span>In N</span><span class="c26 c21">oisy images</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 252.00px;"><img
                alt="" src="assets/computer-vision/image277.png"
                style="width: 602.00px; height: 252.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_6w4vrtwe7ler-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Noise is an issue for template matching</span></li>
        <li class="c7 li-bullet-0"><span class="c1">You want to create a matcher which is robust to noise</span></li>
    </ul>
    <h3 class="c22" id="h.udkrzg2x7gb6"><span>In </span><span>Occluded </span><span class="c26 c21">Images</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 253.33px;"><img
                alt="" src="assets/computer-vision/image354.png"
                style="width: 602.00px; height: 253.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.7yvs59xxj7hb"><span class="c11">Encore, Monsieur Fourier! (???) (non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 635.50px; height: 281.86px;"><img
                alt="" src="assets/computer-vision/image211.png"
                style="width: 635.50px; height: 281.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.f87o22lh4yvs"><span class="c11">Applying Template Matching (non examinable)</span></h2>
    <p class="c9"><span class="c1">Here, have this pretty low res image of a reaaaaally realistic weapon identification
            system, which can detect weapons like guns and knives. (aka, this is an application of template
            matching.)</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.00px; height: 382.00px;"><img
                alt="" src="assets/computer-vision/image356.png"
                style="width: 471.00px; height: 382.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c36 c68 c21">Windows XP anyone?</span></p>
    <h2 class="c19" id="h.ncb9i4axsgzs"><span class="c11">Applying SIFT in ear biometrics (non examinable)</span></h2>
    <ul class="c10 lst-kix_qsuzvuuasrzj-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Have you ever wanted to identify people by their ears?</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Well now you can!</span></li>
        <li class="c7 li-bullet-0"><span>Do this stuff with the arrows and circles and stuff</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 226.67px;"><img
                alt="" src="assets/computer-vision/image153.png"
                style="width: 602.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.c1kb1fyhod63"><span class="c23 c21">Hough Transform</span></h2>
    <ul class="c10 lst-kix_m9vhuufvyxlf-0 start">
        <li class="c7 li-bullet-0"><span class="c1">This is another feature extraction technique</span></li>
        <li class="c7 li-bullet-0"><span class="c1">It can find imperfect instances of objects within a certain class of
                shapes by a voting procedure</span></li>
        <li class="c7 li-bullet-0"><span>The voting procedure is carried out in a parameter space, from which object
                candidates are obtained as local maxima in a so-called accumulator space.</span></li>
        <li class="c7 li-bullet-0"><span>&nbsp;</span><span class="c6">[-Wiki]</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m9vhuufvyxlf-0">
        <li class="c7 li-bullet-0"><span>P</span><span class="c1">erformance equivalent to template matching, but
                faster</span></li>
        <li class="c7 li-bullet-0"><span>A line is points </span><span class="c6">x,y</span><span>&nbsp;gradient is
            </span><span class="c6">m</span><span>&nbsp;intercept is </span><span class="c6">c</span><span
                class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_m9vhuufvyxlf-1 start">
        <li class="c9 c16 li-bullet-0"><img src="assets/computer-vision/image16.png"></li>
    </ul>
    <ul class="c10 lst-kix_m9vhuufvyxlf-0">
        <li class="c7 li-bullet-0"><span class="c1">You can rearrange to get:</span></li>
    </ul>
    <ul class="c10 lst-kix_m9vhuufvyxlf-1 start">
        <li class="c9 c16 li-bullet-0"><img src="assets/computer-vision/image17.png"></li>
    </ul>
    <ul class="c10 lst-kix_m9vhuufvyxlf-0">
        <li class="c7 li-bullet-0"><span>In maths it&rsquo;s the principle of duality</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 583.00px; height: 234.00px;"><img
                alt="" src="assets/computer-vision/image219.png"
                style="width: 583.00px; height: 234.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c13">Go and read the following article about the Hough Transform: </span><span
            class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=http://aishack.in/tutorials/hough-transform-basics/&amp;sa=D&amp;source=editors&amp;ust=1623775880377000&amp;usg=AOvVaw0xroIV61QCBcRUC5GnHgRU">http://aishack.in/tutorials/hough-transform-basics/</a></span>
    </p>
    <p class="c3"><span class="c36 c13 c21"></span></p>
    <p class="c9"><span class="c36 c13 c21">It&rsquo;s really good.</span></p>
    <h3 class="c22" id="h.m46f2icu9qwu"><span class="c26 c21">Applying the Hough transform for lines</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 220.00px;"><img
                alt="" src="assets/computer-vision/image279.png"
                style="width: 602.00px; height: 220.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.lzblxpi6dqj2"><span>Hough Transform for Lines &hellip; problems</span></h3>
    <ul class="c10 lst-kix_97pbi8lpv7ev-0 start">
        <li class="c7 li-bullet-0"><span class="c6">m, c </span><span class="c1">tend to infinity</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Change the parameterisation</span></li>
        <li class="c7 li-bullet-0"><span>Use foot of normal </span><img src="assets/computer-vision/image18.png"></li>
        <li class="c7 li-bullet-0"><span class="c1">Gives polar HT for lines</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 453.50px; height: 222.68px;"><img
                alt="" src="assets/computer-vision/image132.png"
                style="width: 453.50px; height: 222.68px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.4enyckjmhksu"><span class="c23 c21">Images and accumulator space of polar Hough
            Transform</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 353.33px;"><img
                alt="" src="assets/computer-vision/image74.png"
                style="width: 602.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.b9t8kfmirpub"><span class="c11">Applying Hough Transform</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 528.00px; height: 358.00px;"><img
                alt="" src="assets/computer-vision/image287.png"
                style="width: 528.00px; height: 358.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h1 class="c46" id="h.g2j618ptvci9"><span class="c31 c21">Lecture 9: Finding More Shapes</span></h1>
    <p class="c45 subtitle" id="h.lzk5bida71pd"><span class="c38 c21">How can we go from conic sections to general
            shapes?</span></p>
    <h2 class="c19" id="h.bm7answwtaav"><span class="c23 c21">Hough Transform for Circles</span></h2>
    <ul class="c10 lst-kix_bph4m5eck48v-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Again, it&rsquo;s duality:</span></li>
        <li class="c7 li-bullet-0"><span>Equation of a circle: </span><img src="assets/computer-vision/image19.png"></li>
    </ul>
    <p class="c3"><span class="c1"></span></p><a id="t.1c811df62ea58656a4a0df0d808d574f287644d0"></a><a id="t.0"></a>
    <table class="c65">
        <tbody>
            <tr class="c51">
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Points</span></p>
                </td>
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Parameters</span></p>
                </td>
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Radius</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">x,y</span></p>
                </td>
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span>x</span><span class="c42">0</span><span>,y</span><span class="c42">0</span></p>
                </td>
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">r</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span>x</span><span class="c42">0</span><span>,y</span><span class="c42">0</span></p>
                </td>
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">x,y</span></p>
                </td>
                <td class="c82" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">r</span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.oqzuof2nrndu"><span class="c23 c21">Circle Voting and Accumulator Space</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 341.33px;"><img
                alt="" src="assets/computer-vision/image69.png"
                style="width: 602.00px; height: 341.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Like before, but this time for circles.</span></p>
    <h2 class="c19" id="h.os4nb27d08et"><span class="c23 c21">Speeding it up</span></h2>
    <ul class="c10 lst-kix_abu1w5i74ypi-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Now it&rsquo;s a 3D accumulator, fast algorithms are
                available</span></li>
        <li class="c7 li-bullet-0"><span>E.g. by differentiation:</span><img src="assets/computer-vision/image20.png"></li>
        <li class="c7 li-bullet-0"><span class="c1">SO edge gradient direction can be used, e.g. 2D accumulator
                by:</span></li>
    </ul>
    <p class="c9 c33"><img src="assets/computer-vision/image21.png"></p>
    <h2 class="c19" id="h.wjb4a4xt6om0"><span class="c23 c21">Applying the HT for circles</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 218.67px;"><img
                alt="" src="assets/computer-vision/image192.png"
                style="width: 602.00px; height: 218.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">This can be used for detecting the shapes of an eye and iris.</span></p>
    <h2 class="c19" id="h.c9gn47ra3dzt"><span class="c11">Integrodifferential operator? (non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 512.00px; height: 383.00px;"><img
                alt="" src="assets/computer-vision/image173.png"
                style="width: 512.00px; height: 383.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=https://stackoverflow.com/questions/27058057/comparing-irises-images-with-opencv&amp;sa=D&amp;source=editors&amp;ust=1623775880387000&amp;usg=AOvVaw0OLOK0A3J0mXWCd5RQr_1M">https://stackoverflow.com/questions/27058057/comparing-irises-images-with-opencv</a></span>
    </p>
    <p class="c9"><span class="c1">Looks cool???</span></p>
    <h2 class="c19" id="h.2ak0f5l2grdx"><span class="c23 c21">Arbitrary Shapes</span></h2>
    <ul class="c10 lst-kix_kkowqa3tj931-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Use Generalised HT</span></li>
        <li class="c7 li-bullet-0"><span>Form (discrete) look-up-table (</span><span class="c44">R-table</span><span
                class="c1">)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Vote via look-up-table</span></li>
        <li class="c7 li-bullet-0"><span>Orientation? Rotate </span><span class="c44">R-table</span><span
                class="c1">&nbsp;voting</span></li>
        <li class="c7 li-bullet-0"><span>Scale? Scale </span><span class="c44">R-table</span><span
                class="c1">&nbsp;voting</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Inherent problems with discretisation (process of transferring
                continuous functions to discrete)</span></li>
    </ul>
    <h2 class="c19" id="h.6p906787a3bo"><span class="c23 c21">R-table Construction</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 260.00px;"><img
                alt="" src="assets/computer-vision/image332.png"
                style="width: 602.00px; height: 260.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c20">Pick a reference point in the image.</span></p>
    <p class="c9"><span class="c20">For each boundary point x, compute \Phi(x) - the gradient direction.</span></p>
    <p class="c9"><span class="c20">r is the distance from the reference point to the boundary point (radial distance),
            and \alpha is the angle.</span></p>
    <p class="c9"><span class="c20">The table then stores each (r, \alpha) pair with the corresponding \Phi.</span></p>
    <p class="c3"><span class="c20"></span></p>
    <p class="c9"><span class="c20">(Thanks Bradley Garrod)</span></p>
    <h2 class="c19" id="h.rku7h3jplkvd"><span class="c11">Active Contours (non examinable)</span></h2>
    <ul class="c10 lst-kix_o2ar3lqi2xsh-0 start">
        <li class="c7 li-bullet-0"><span class="c1">For unknown arbitrary shapes: extract by evolution</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Elastic band analogy</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Balloon analogy</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Discrete vs. continuous</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Volcanoes? &#x1f30b;</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 146.67px;"><img
                alt="" src="assets/computer-vision/image188.png"
                style="width: 602.00px; height: 146.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.t17lsdlxi2q8"><span class="c11">Geometric active contours (non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 320.00px;"><img
                alt="" src="assets/computer-vision/image360.png"
                style="width: 602.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c36 c21 c59">Couple&rsquo;a hippos &#x1f99b;&#x1f99b;</span></p>
    <h2 class="c19" id="h.qr3f44iyekit"><span class="c29">Parts-based shape modelling (non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 258.67px;"><img
                alt="" src="assets/computer-vision/image333.png"
                style="width: 602.00px; height: 258.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c36 c59 c21">This guy don&rsquo;t look so good</span></p>
    <h2 class="c19" id="h.brc5hs2ecfcz"><span class="c29">Symmetry yrtemmyS</span><span>&nbsp;</span><span
            class="c11">(non examinable)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 405.33px;"><img
                alt="" src="assets/computer-vision/image303.png"
                style="width: 602.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c36 c68 c21">SPooky</span></p>
    <h2 class="c19" id="h.f9va09x4y1py"><span class="c23 c21">Lecture 10 Applications/Deep Learning</span></h2>
    <p class="c45 subtitle" id="h.v0ubfup1hgrg"><span class="c38 c21">Where is feature extraction used these
            days?</span></p>
    <p class="c9"><span class="c74">This lecture is mostly extra (non examinable) stuff, so I&rsquo;m only gonna cover
            the hand with bow slides. If you want a look then jump to the slides: </span><span class="c57 c13"><a
                class="c0"
                href="https://www.google.com/url?q=http://comp3204.ecs.soton.ac.uk/mark/Lecture%252010.pdf&amp;sa=D&amp;source=editors&amp;ust=1623775880392000&amp;usg=AOvVaw0RCsB_tnBI7GN7cc0y1Zq4">http://comp3204.ecs.soton.ac.uk/mark/Lecture%2010.pdf</a></span>
    </p>
    <h2 class="c19" id="h.h4hlcxfog5uy"><span class="c23 c21">Where is computer vision used?</span></h2>
    <p class="c9"><span class="c1">What you see depends on the viewpoint you take</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 509.17px; height: 452.50px;"><img
                alt="" src="assets/computer-vision/image316.png"
                style="width: 509.17px; height: 452.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 422.67px;"><img
                alt="" src="assets/computer-vision/image65.png"
                style="width: 602.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.gvvqmhsfeyuw"><span class="c23 c21">Deep Learning</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 498.67px;"><img
                alt="" src="assets/computer-vision/image196.png"
                style="width: 602.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.g3p56ktzy0ck"><span class="c23 c21">Conclusions</span></h2>
    <ul class="c10 lst-kix_h2xh97d5yxv8-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Computer vision is changing the way we live</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Computer vision uses modern hardware and modern cameras to achieve
                what we understand by &ldquo;sight&rdquo;</span></li>
        <li class="c7 li-bullet-0"><span class="c1">No technique is a panacea (a solution for all difficulties): many
                alternatives exist</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Computer vision is larger than this course</span></li>
    </ul>
    <hr style="page-break-before:always;display:none;">
    <p class="c3"><span class="c1"></span></p>
    <p class="c102 title" id="h.vdo6hs6zlxhw"><span class="c84 c21">Part 2: Jon</span></p>
    <p class="c9"><span class="c13">Note: Jon has done some really good handout summaries which have basically done my
            job for me, they can be found here: </span><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=http://comp3204.ecs.soton.ac.uk/part2.html&amp;sa=D&amp;source=editors&amp;ust=1623775880394000&amp;usg=AOvVaw2wGsGZbXtta3jpGR5lkH0a">http://comp3204.ecs.soton.ac.uk/part2.html</a></span><span
            class="c36 c13 c21">&nbsp;</span></p>
    <p class="c9"><span class="c36 c13 c21">Highly recommend reading these probably.</span></p>
    <p class="c3"><span class="c36 c13 c21"></span></p>
    <p class="c9"><span class="c36 c13 c21">But I will still go through the slides and make notes of hand with bow
            slides :)</span></p>
    <h1 class="c46" id="h.iy72sddzw1cg"><span class="c31 c21">Lecture 1: Building machines that see</span></h1>
    <h2 class="c19" id="h.m5aa6q92x3t4"><span class="c23 c21">Key terms in designing Computer Vision systems</span></h2>
    <ol class="c10 lst-kix_g2cplqf70t6c-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1 c108">Robust</span></li>
        <li class="c7 li-bullet-0"><span class="c1 c85">Repeatable</span></li>
        <li class="c7 li-bullet-0"><span class="c1 c96">Invariant</span></li>
        <li class="c7 li-bullet-0"><span class="c1 c71">Constraints</span></li>
    </ol>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_2yfxfpvdldq-0 start">
        <li class="c7 li-bullet-0"><span>You want your system to be </span><span
                class="c108">robust</span><span>&nbsp;and </span><span class="c85">repeatable</span><span
                class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>You design your system to be </span><span class="c96">invariant</span><span
                class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>You apply </span><span class="c71">constraints</span><span class="c1">&nbsp;to
                make it work.</span></li>
    </ul>
    <h3 class="c22" id="h.bwuje9hi3xve"><span class="c26 c21">Robustness</span></h3>
    <ul class="c10 lst-kix_5n7xdlz0ash4-0 start">
        <li class="c7 li-bullet-0"><span>The vision system must be </span><span class="c5">robust </span><span
                class="c1">to changes in its environment</span></li>
    </ul>
    <ul class="c10 lst-kix_5n7xdlz0ash4-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">i.e. changes in lighting; angle or position of the camera;
                etc</span></li>
    </ul>
    <h3 class="c22" id="h.fa922gsx4ewr"><span class="c26 c21">Repeatability</span></h3>
    <ul class="c10 lst-kix_qb1la8iqrcfk-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Repeatability </span><span>is a </span><span class="c6">measure
            </span><span class="c1">of robustness</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Repeatability means that the system must work the same over and
                over, regardless of environmental changes</span></li>
    </ul>
    <h3 class="c22" id="h.83adh2kb97u3"><span class="c26 c21">Invariance</span></h3>
    <ul class="c10 lst-kix_ad1r5ov0g3hi-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Invariance </span><span class="c1">to environmental factor helps
                achieve robustness and repeatability</span></li>
    </ul>
    <ul class="c10 lst-kix_ad1r5ov0g3hi-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Hardware and software can be designed to be invariant to certain
                environmental changes</span></li>
    </ul>
    <ul class="c10 lst-kix_ad1r5ov0g3hi-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">e.g. you could design an algorithm to be invariant to
                illumination changes&hellip;</span></li>
    </ul>
    <h3 class="c22" id="h.smoa788qskgm"><span class="c26 c21">Constraints</span></h3>
    <ul class="c10 lst-kix_sel83dgpds2r-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Constraints </span><span class="c1">are what you apply to the
                hardware, software and wetware (human brains in the system) to make sure your computer vision system
                works in a repeatable, robust fashion.</span></li>
    </ul>
    <ul class="c10 lst-kix_sel83dgpds2r-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">e.g. you constrain the system by putting it in a box so there
                can&rsquo;t be any illumination changes</span></li>
    </ul>
    <h2 class="c19" id="h.vtqxj8cpjfjm"><span class="c23 c21">Constraints in Industrial Vision</span></h2>
    <h3 class="c22" id="h.7hfw5nibiydz"><span class="c26 c21">Software Constraints</span></h3>
    <ul class="c10 lst-kix_4i2ad8ufsag7-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Really simple</span><span>, but </span><span class="c5">incredibly
                fast</span><span class="c1">&nbsp;algorithms</span></li>
    </ul>
    <ul class="c10 lst-kix_4i2ad8ufsag7-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Hough Transform is popular, but note that it isn&rsquo;t all
                that robust without physical constraints</span></li>
    </ul>
    <ul class="c10 lst-kix_4i2ad8ufsag7-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Actually, the same is true of most algorithms/techniques used in
                industrial vision</span></li>
    </ul>
    <ul class="c10 lst-kix_4i2ad8ufsag7-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Intelligent use of colour&hellip;</span></li>
    </ul>
    <h3 class="c22" id="h.uw57z06xh156"><span class="c48 c29 c21">Colour-Spaces (non examinable?)</span></h3>
    <p class="c9"><span class="c36 c21 c74">Even though there is no hand with bow for these slides, they seem
            useful.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ouy6irojzd5a-0 start">
        <li class="c7 li-bullet-0"><span>There are many different ways of </span><span
                class="c6">numerically</span><span class="c1">&nbsp;representing colour</span></li>
    </ul>
    <ul class="c10 lst-kix_ouy6irojzd5a-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">A single representation of all possible colours is called a
                colour-space</span></li>
        <li class="c9 c16 li-bullet-0"><span>It&rsquo;s </span><span class="c6">generally </span><span
                class="c1">&nbsp;possible to convert to one colour-space to another by applying a mapping (in the form
                of a set of equations or an algorithm)</span></li>
    </ul>
    <h4 class="c17" id="h.3hhakmzi727p"><span class="c29 c21 c72">RGB Colour-space</span></h4>
    <ul class="c10 lst-kix_lyndhykfqhnp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Most Physical image sensors capture RGB</span></li>
    </ul>
    <ul class="c10 lst-kix_lyndhykfqhnp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">By far the most widely known space</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">RGB &ldquo;couples&rdquo; brightness (luminance) with each
                channel, meaning that the illumination invariance is difficult</span></li>
    </ul>
    <ul class="c10 lst-kix_lyndhykfqhnp-0">
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 330.00px; height: 248.00px;"><img
                    alt="" src="assets/computer-vision/image235.png"
                    style="width: 330.00px; height: 248.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h4 class="c17" id="h.kqgdou8gsidi"><span class="c72 c29 c21">HSV Colour-space</span></h4>
    <ul class="c10 lst-kix_rvq1nokgh6rw-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Hue, Saturation, Value is another colour-space</span></li>
    </ul>
    <ul class="c10 lst-kix_rvq1nokgh6rw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Hue encodes the pure colour as an angle</span></li>
    </ul>
    <ul class="c10 lst-kix_rvq1nokgh6rw-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Red == 0&deg; == 360&deg;</span></li>
    </ul>
    <ul class="c10 lst-kix_rvq1nokgh6rw-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Saturation is how vibrant the colour is</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">And the Value encodes brightness</span></li>
    </ul>
    <ul class="c10 lst-kix_rvq1nokgh6rw-0">
        <li class="c7 li-bullet-0"><span class="c1">A simple way of achieving invariance to lightning is to use just the
                H or H &amp; S components</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h4 class="c17" id="h.h5420iojfjhs"><span class="c72 c29 c21">LAB Colour-space</span></h4>
    <p class="c9"><span class="c76 c86">Lab color space is more perceptually </span><span
            class="c76 c86 c5">linear</span><span class="c76 c86">&nbsp;than other color spaces. Perceptually linear
            means that a change of the same amount in a color value should produce a change of about the same visual
            importance. It is important especially when you try to measure the perceptual difference of two colors.
            (</span><span class="c57 c13 c76"><a class="c0"
                href="https://www.google.com/url?q=https://stackoverflow.com/questions/39319729/lab-color-space-vs-rgb-or-hsv-opencv-example&amp;sa=D&amp;source=editors&amp;ust=1623775880402000&amp;usg=AOvVaw3Ifwug58wmO_cTeY7NtMuR">Source</a></span><span
            class="c60 c92 c86 c21">)</span></p>
    <ul class="c10 lst-kix_fgub5h8w74oh-0 start">
        <li class="c7 li-bullet-0"><span class="c60 c86 c21 c92">Can also be made invariant to lighting by only using
                the AB components.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.t0lem6ewl5o"><span class="c26 c21">Physical Constraints</span></h3>
    <ul class="c10 lst-kix_as20xz3xmt88-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Industrial vision is usually solved by applying simple computer
                vision algorithms, and lots of physical constraints:</span></li>
    </ul>
    <ul class="c10 lst-kix_as20xz3xmt88-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Environment: lighting, enclosure, mounting</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Acquisition hardware: expensive camera, optics, filters</span>
        </li>
    </ul>
    <h2 class="c19" id="h.l31tj9bgeegs"><span class="c23 c21">Vision in the wild</span></h2>
    <ul class="c10 lst-kix_7vwm7wlrlck7-0 start">
        <li class="c7 li-bullet-0"><span class="c1">So, what about vision systems in the wild, like ANPR (Automatic
                Number-Plate Recognition) cameras, or recognition apps for mobile phones?</span></li>
    </ul>
    <ul class="c10 lst-kix_7vwm7wlrlck7-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Apply as many hardware and wetware constraints as possible, and
                let the software take up the slack</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Colour information often less important than luminance</span>
        </li>
    </ul>
    <h1 class="c46" id="h.y9a1jfizwew1"><span class="c31 c21">Lecture 2: Machine learning for pattern recognition</span>
    </h1>
    <h2 class="c19" id="h.2yyn6u5csbzq"><span class="c23 c21">Feature Spaces</span></h2>
    <p class="c9"><span class="c1">Many computer vision applications involving machine learning take the following
            form</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 486.00px; height: 349.00px;"><img
                alt="" src="assets/computer-vision/image102.png"
                style="width: 486.00px; height: 349.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ol class="c10 lst-kix_lyv76gupl5a0-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">This is where cool image processing happens</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Feature extractors make feature vectors from images</span></li>
        <li class="c7 li-bullet-0"><span>Machine learning system uses </span><span>featurevectors</span><span
                class="c1">&nbsp;to make intelligent decisions</span></li>
    </ol>
    <h2 class="c19" id="h.eko2x51ny74k"><span class="c23 c21">Key terminology</span></h2>
    <ul class="c10 lst-kix_g1uwpi9psv0z-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Featurevector</span><span class="c1">: a mathematical vector</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_g1uwpi9psv0z-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Just a list of (usually Real) numbers</span></li>
        <li class="c9 c16 li-bullet-0"><span>Has a fixed number of </span><span class="c5">elements</span><span
                class="c1">&nbsp;in it</span></li>
    </ul>
    <ul class="c10 lst-kix_g1uwpi9psv0z-2 start">
        <li class="c9 c12 li-bullet-0"><span>The number of elements is the </span><span class="c5">dimensionality
            </span><span class="c1">of the vector</span></li>
    </ul>
    <ul class="c10 lst-kix_g1uwpi9psv0z-1">
        <li class="c9 c16 li-bullet-0"><span>Represents a </span><span class="c5">point </span><span>in a </span><span
                class="c5">featurespace </span><span>or equally a </span><span class="c5">direction</span><span
                class="c1">&nbsp;in the featurespace</span></li>
        <li class="c9 c16 li-bullet-0"><span>The </span><span class="c5">dimensionality of a featurespace </span><span
                class="c1">is the dimensionality of every vector within it</span></li>
    </ul>
    <ul class="c10 lst-kix_g1uwpi9psv0z-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Vectors of differing dimensionality can&rsquo;t exist in the
                same featurespace</span></li>
    </ul>
    <h2 class="c19" id="h.ugkc9jexg0iq"><span class="c23 c21">Density and Similarity</span></h2>
    <h3 class="c22" id="h.w4prz560taxo"><span class="c26 c21">Distance in featurespace</span></h3>
    <ul class="c10 lst-kix_5ehlbh4tx5kl-0 start">
        <li class="c7 li-bullet-0"><span>Feature extractors are often defined so that they produce vectors that are
            </span><span class="c6">close</span><span>&nbsp;together for </span><span class="c6">similar </span><span
                class="c1">inputs</span></li>
    </ul>
    <ul class="c10 lst-kix_5ehlbh4tx5kl-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Closeness of two vectors can be computed in the feature space by
                measuring the distance between the vectors.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 371.00px; height: 419.00px;"><img
                alt="" src="assets/computer-vision/image182.png"
                style="width: 371.00px; height: 419.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Cats are a close distance apart, and are further away from the cluster of dogs in
            this feature space.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.8gko3o3iszzp"><span class="c26 c21">Euclidean distance (L2 distance)</span></h3>
    <ul class="c10 lst-kix_cg10y4z3x6b4-0 start">
        <li class="c7 li-bullet-0"><span class="c1">L2 distance is the most intuitive distance&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_cg10y4z3x6b4-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">The straight-line distance between two points</span></li>
        <li class="c9 c16 li-bullet-0"><span>Computed via an extension of Pythagoras theorem to </span><span
                class="c6">n</span><span class="c1">&nbsp;dimensions:</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 417.00px; height: 75.00px;"><img
                alt="" src="assets/computer-vision/image205.png"
                style="width: 417.00px; height: 75.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Equation</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 89.00px; height: 190.00px;"><img
                alt="" src="assets/computer-vision/image70.png"
                style="width: 89.00px; height: 190.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">The straight-line; &ldquo;Euclidean distance&rdquo;</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.mayrtvj44hxn"><span class="c26 c21">Manhattan/Taxicab distance (L1 distance)</span></h3>
    <ul class="c10 lst-kix_cgaf721nxmxm-0 start">
        <li class="c7 li-bullet-0"><span class="c1">L1 distance is computed along paths parallel to the axes of the
                space:</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 353.00px; height: 99.00px;"><img
                alt="" src="assets/computer-vision/image105.png"
                style="width: 353.00px; height: 99.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Equation</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 83.00px; height: 183.00px;"><img
                alt="" src="assets/computer-vision/image181.png"
                style="width: 83.00px; height: 183.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Essentially just like you are taking a taxi cab around the grid like streets of
            manhattan</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.euhn1fjb81y4"><span class="c26 c21">Cosine Similarity</span></h3>
    <ul class="c10 lst-kix_aidvm1f8g3nc-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Cosine similarity measures the cosine of the angle between two
                vectors</span></li>
    </ul>
    <ul class="c10 lst-kix_aidvm1f8g3nc-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c15 c5">It is not a distance!</span></li>
    </ul>
    <ul class="c10 lst-kix_aidvm1f8g3nc-0">
        <li class="c7 li-bullet-0"><span class="c1">Useful if you don&rsquo;t care about the relative length of the
                vectors</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 358.00px; height: 139.00px;"><img
                alt="" src="assets/computer-vision/image110.png"
                style="width: 358.00px; height: 139.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Equation</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 158.00px; height: 242.00px;"><img
                alt="" src="assets/computer-vision/image359.png"
                style="width: 158.00px; height: 242.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">The angle between the two points from the origin</span></p>
    <h2 class="c19" id="h.eawvrmhllhox"><span>Choosing good </span><span>featurevector</span><span
            class="c23 c21">&nbsp;representations for machine learning</span></h2>
    <ul class="c10 lst-kix_4dxdfjiekwj2-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Choose features which allow to distinguish objects or classes of
                interest</span></li>
    </ul>
    <ul class="c10 lst-kix_4dxdfjiekwj2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Similar within classes</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Different between classes</span></li>
    </ul>
    <ul class="c10 lst-kix_4dxdfjiekwj2-0">
        <li class="c7 li-bullet-0"><span class="c1">Keep number of features small</span></li>
    </ul>
    <ul class="c10 lst-kix_4dxdfjiekwj2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Machine-learning can ge t more difficult as dimensionality of
                featurespace gets large</span></li>
    </ul>
    <h2 class="c19" id="h.h205onq4o86x"><span class="c23 c21">Supervised Machine Learning: Classification</span></h2>
    <ul class="c10 lst-kix_v64skadj2mcs-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Classification </span><span>is the process of assigning a
            </span><span class="c5">class label</span><span class="c1">&nbsp;to an object (typically represented by a
                vector in a feature space).</span></li>
        <li class="c7 li-bullet-0"><span>A </span><span class="c5">supervised machine-learning algorithm
            </span><span>uses a set of pre-labelled </span><span class="c6">training data </span><span class="c1">to
                learn how to assign class labels to vectors (and the corresponding objects).</span></li>
    </ul>
    <ul class="c10 lst-kix_v64skadj2mcs-1 start">
        <li class="c9 c16 li-bullet-0"><span>A </span><span class="c5">binary</span><span class="c1">&nbsp;classifier
                only has two classes</span></li>
        <li class="c9 c16 li-bullet-0"><span>A </span><span class="c5">multiclass </span><span class="c1">classifier has
                many classes</span></li>
    </ul>
    <h3 class="c22" id="h.7ifbjkds5n7f"><span class="c26 c21">Linear Classifiers</span></h3>
    <p class="c9"><span>Linear classifiers try to learn a </span><span class="c5">hyperplane</span><span>&nbsp;that
            separates two classes in featurespace with </span><span class="c5">minimum error</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 497.00px; height: 412.00px;"><img
                alt="" src="assets/computer-vision/image244.png"
                style="width: 497.00px; height: 412.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">There can be lots of hyperplanes to choose from; differing classification algorithms
            apply differing constraints when learning the classifier.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">To classify a new image, you just need to check what side of the hyperplane it is
            on.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.m48s0h7011bg"><span class="c26 c21">Non-linear binary classifiers</span></h3>
    <p class="c9"><span class="c1">Linear classifiers work best when the data is linearly separable.</span></p>
    <p class="c9"><span class="c1">Like this:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 305.00px; height: 299.00px;"><img
                alt="" src="assets/computer-vision/image213.png"
                style="width: 305.00px; height: 299.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">But what if the data is like this:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 305.00px; height: 295.00px;"><img
                alt="" src="assets/computer-vision/image228.png"
                style="width: 305.00px; height: 295.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">There is no hope for a linear classifier! &#x1f62d;</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span>Non-linear binary classifiers, such as </span><span class="c5">Kernel support Vector
            Machines</span><span class="c1">&nbsp;learn non-linear decision boundaries. (basically a curved graph
            separates the data instead of a straight one)</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 313.00px; height: 302.00px;"><img
                alt="" src="assets/computer-vision/image242.png"
                style="width: 313.00px; height: 302.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">However, you have to be careful, you might lose generality by overfitting:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 310.00px; height: 305.00px;"><img
                alt="" src="assets/computer-vision/image189.png"
                style="width: 310.00px; height: 305.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">What class would the blue question mark actually belong to?</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.5qn8mwpnnfh0"><span class="c26 c21">Multiclass classifiers: KNN</span></h3>
    <p class="c9"><span>Assign class of unknown point based on majority class of </span><span class="c6">closest K
        </span><span class="c1">neighbours in featurespace.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 597.00px; height: 419.00px;"><img
                alt="" src="assets/computer-vision/image147.png"
                style="width: 597.00px; height: 419.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h4 class="c17" id="h.21fwhzwbg0v6"><span class="c72 c29 c21">KNN Problems (non examinable?)</span></h4>
    <ul class="c10 lst-kix_1j9989kcrsmp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Computationally expensive if there are:</span></li>
    </ul>
    <ul class="c10 lst-kix_1j9989kcrsmp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Lots of training examples</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Many dimensions</span></li>
    </ul>
    <h2 class="c19" id="h.qq2zm5zd204x"><span>Unsupervised Machine Learning: Clustering</span></h2>
    <ul class="c10 lst-kix_cnq0gg3b28x6-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Clustering aims to group data without any prior knowledge of what
                the groups should look like or contain.</span></li>
        <li class="c7 li-bullet-0"><span>In terms of </span><span>featurevectors</span><span class="c1">, items with
                similar vectors should be grouped together by a clustering operation.</span></li>
        <li class="c7 li-bullet-0"><span>Some clustering operations create overlapping groups; for now we&rsquo;re only
                interested in disjoint clustering methods that assign an item to a single group.</span></li>
    </ul>
    <h3 class="c22" id="h.taca32ts1z7c"><span class="c26 c21">K-Means Clustering</span></h3>
    <p class="c9"><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D4b5d3muPQmA&amp;sa=D&amp;source=editors&amp;ust=1623775880418000&amp;usg=AOvVaw3Kg1IVDTySkSo5CKbgxEKe">StatQuest:
                K-means clustering</a></span><span class="c1">&nbsp;(good video to explain this!!!!!!!!!!!!!!!!)</span>
    </p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_p37w2owieo3v-0 start">
        <li class="c7 li-bullet-0"><span>K-Means is a classic featurespace clustering algorithm for grouping data in
            </span><span class="c6">K </span><span>groups with each group represented by a </span><span
                class="c6">centroid</span><span class="c1">:</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Pseudo code:</span></li>
    </ul>
    <ul class="c10 lst-kix_p37w2owieo3v-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c18 c21">The value of K is chosen</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c18 c21">K initial cluster centres are chosen</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c18 c21">The following process is performed iteratively until the
                centroids don&rsquo;t move between iterations:</span></li>
    </ul>
    <ul class="c10 lst-kix_p37w2owieo3v-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c18 c21">Each point is assigned to its closest centroid</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c18 c21">The centroid is recomputer as the mean of all the points
                assigned to it. If the centroid has no points assigned it is randomly re-initialised to a new
                point.</span></li>
    </ul>
    <ul class="c10 lst-kix_p37w2owieo3v-1">
        <li class="c9 c16 li-bullet-0"><span class="c18 c21">The final clusters are created by assigning all points to
                their nearest centroid.</span></li>
    </ul>
    <h1 class="c46" id="h.6ieazp851c7p"><span class="c31 c21">Lecture 3: Covariance and Principal Components</span></h1>
    <h2 class="c19" id="h.xd66dx7ruk3c"><span class="c11">Random Variables and Expected Values</span></h2>
    <ul class="c10 lst-kix_2g350u37asrg-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Random variables</span></li>
    </ul>
    <ul class="c10 lst-kix_2g350u37asrg-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Variable that takes on different values due to chance</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_2g350u37asrg-0">
        <li class="c7 li-bullet-0"><span class="c2">Expected values</span></li>
    </ul>
    <ul class="c10 lst-kix_2g350u37asrg-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c29">The expected value (denoted E[X]) is the most likely value a
                random variable will take.</span></li>
    </ul>
    <h2 class="c19" id="h.3285v0s2vh76"><span class="c23 c21">Variance</span></h2>
    <ul class="c10 lst-kix_4a1sgrxgmi9d-0 start">
        <li class="c7 li-bullet-0"><span>Variance (&sigma;</span><span class="c66">2</span><span class="c1">) is the
                mean squared difference from the mean (&mu;).</span></li>
        <li class="c7 li-bullet-0"><span class="c1">It&rsquo;s a measure of how spread-out the data is.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 546.00px; height: 184.00px;"><img
                alt="" src="assets/computer-vision/image80.png"
                style="width: 546.00px; height: 184.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span>Equation</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c67">Technically it&rsquo;s E[(X - E[X])</span><span class="c67 c66">2</span><span
            class="c67">]</span></p>
    <h2 class="c19" id="h.wndutylwftvo"><span>Covariance</span></h2>
    <ul class="c10 lst-kix_3w5rlurxctt-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Covariance (&sigma;(x,y)) measures how two variables change
                together</span></li>
        <li class="c7 li-bullet-0"><span>The variance is the covariance when the two variables are the same
                (&sigma;(x,y)=&sigma;</span><span class="c66">2</span><span class="c1">(x))</span></li>
        <li class="c7 li-bullet-0"><span class="c1">A covariance of 0 means the variables are uncorrelated</span></li>
    </ul>
    <p class="c9"><span class="c1">(Covariance is related to Correlation though&hellip;)</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 153.33px;"><img
                alt="" src="assets/computer-vision/image108.png"
                style="width: 602.00px; height: 153.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Equation</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c36 c21 c67">Technically it&rsquo;s E[ (x - E[x]) (y - E[y]) ]</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.ts9wke7kwzrj"><span class="c23 c21">Covariance Matrix</span></h2>
    <ul class="c10 lst-kix_4vl24j4g7p87-0 start">
        <li class="c7 li-bullet-0"><span class="c1">A covariance matrix encodes how all possible pairs of dimensions in
                an n-dimensional dataset vary together.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 162.67px;"><img
                alt="" src="assets/computer-vision/image125.png"
                style="width: 602.00px; height: 162.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span>The covariance matrix is a </span><span class="c5">square symmetric matrix</span><span>, as you
            can see by the symmetry in the example above.</span></p>
    <h2 class="c19" id="h.c8jpumw8hlro"><span class="c23 c21">Mean Centring</span></h2>
    <ul class="c10 lst-kix_g4mcmndftl4g-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Mean Centring is the process of computing the mean (across each
                dimension &nbsp;independently) of a set of vectors, and then subtracting the mean vector from every
                vector in the set.</span></li>
    </ul>
    <ul class="c10 lst-kix_g4mcmndftl4g-1 start">
        <li class="c9 c16 li-bullet-0"><span>All the vectors will be translated so their average positions is the
                origin.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 221.00px; height: 441.00px;"><img
                alt="" src="assets/computer-vision/image121.png"
                style="width: 221.00px; height: 441.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">From top image to bottom image; mean centered around the origin.</span></p>
    <h2 class="c19" id="h.by7ogxotx6p8"><span class="c23 c21">Covariance matrix again</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 137.33px;"><img
                alt="" src="assets/computer-vision/image138.png"
                style="width: 602.00px; height: 137.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">So then this means that</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 374.00px; height: 107.00px;"><img
                alt="" src="assets/computer-vision/image231.png"
                style="width: 374.00px; height: 107.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c20"></span></p>
    <p class="c9"><span class="c20">The covariance matrix is directly proportional to Z transposed, multiplied by Z,
            where Z is the matrix formed by the mean-centred vectors (each row of matrix Z is one mean-centred vector) -
            Hope this helps :) - Lorena</span></p>
    <p class="c3"><span class="c20"></span></p>
    <h2 class="c19" id="h.aqf9tsbo5r2r"><span class="c23 c21">Principal axes of variation</span></h2>
    <h3 class="c22" id="h.gzxnincvri8b"><span>Basis</span></h3>
    <ul class="c10 lst-kix_klo4twkpxtow-0 start">
        <li class="c7 li-bullet-0"><span>A basis is a set of </span><span class="c6">n</span><span>&nbsp;</span><span
                class="c5">linearly independent </span><span class="c59">(remember all the way back to first year
                Foundations guys!) </span><span>vectors in an </span><span class="c6">n</span><span
                class="c1">&nbsp;dimensional space</span></li>
    </ul>
    <ul class="c10 lst-kix_klo4twkpxtow-1 start">
        <li class="c9 c16 li-bullet-0"><span>The vectors are </span><span class="c5">orthogonal</span><span
                class="c1">&nbsp;(all right-angles to each other)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">They form a &ldquo;coordinate system&rdquo;</span></li>
        <li class="c9 c16 li-bullet-0"><span>There are an infinite number of possible </span><span
                class="c43 c6 c21">bases</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 261.00px; height: 200.00px;"><img
                alt="" src="assets/computer-vision/image85.png"
                style="width: 261.00px; height: 200.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.clq2n8kzpmrz"><span class="c26 c21">The first principal axis</span></h3>
    <ul class="c10 lst-kix_ylk5p7mahxhu-0 start">
        <li class="c7 li-bullet-0"><span>For a given set of </span><span class="c6">n</span><span>&nbsp;dimensional
                data, the </span><span class="c6 c5">first principal axis </span><span>(or just </span><span
                class="c6 c5">principal axis</span><span class="c1">) is the vector that describes the direction of
                greatest variance.</span></li>
        <li class="c7 li-bullet-0"><span>(Big </span><span class="c58">turquoise </span><span class="c1">arrow pointing
                up and to the right in the image below)</span></li>
    </ul>
    <h3 class="c22" id="h.tsih352efgk"><span class="c26 c21">The second principal axis</span></h3>
    <ul class="c10 lst-kix_x2jkqyfk3l6d-0 start">
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">second principal axis</span><span>&nbsp;is a vector
                in the direction of the greatest variance orthogonal (perpendicular) to the first </span><span>major
            </span><span class="c1">axis.</span></li>
        <li class="c7 li-bullet-0"><span>(Small </span><span class="c44">lilac </span><span class="c1">arrow pointing up
                to the left in the image below)</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 360.00px; height: 358.00px;"><img
                alt="" src="assets/computer-vision/image97.png"
                style="width: 360.00px; height: 358.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.ajo1tmv3ovgx"><span class="c26 c21">The third principal axis</span></h3>
    <ul class="c10 lst-kix_c7fwucstaunh-0 start">
        <li class="c7 li-bullet-0"><span class="c1">In a space with 3 or more dimensions, the third principal axis is
                the direction of greatest variance orthogonal to both the first and second principal axes.</span></li>
    </ul>
    <ul class="c10 lst-kix_c7fwucstaunh-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">The fourth&hellip; and so on&hellip;</span></li>
        <li class="c9 c16 li-bullet-0"><span>The set of </span><span class="c6">n</span><span>&nbsp;</span><span
                class="c5">principal axes</span><span>&nbsp;of an </span><span
                class="c6">n</span><span>&nbsp;dimensional space are a </span><span class="c5">basis</span><span
                class="c1">.</span></li>
    </ul>
    <h2 class="c19" id="h.eyso2ifrb6ag"><span class="c23 c21">Eigenvectors and Eigenvalues</span></h2>
    <h3 class="c22" id="h.ycxwwa7v367v"><span>Important Equation</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 278.00px; height: 91.00px;"><img
                alt="" src="assets/computer-vision/image298.png"
                style="width: 278.00px; height: 91.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_q2asxpg89xrs-0 start">
        <li class="c7 li-bullet-0"><span>A = </span><span class="c6">n x n </span><span class="c1">square matrix</span>
        </li>
        <li class="c7 li-bullet-0"><span>&upsilon; = </span><span class="c6">n</span><span>&nbsp;dimensional vector,
                known as the </span><span class="c15 c5">eigenvector</span></li>
        <li class="c7 li-bullet-0"><span>&lambda; = scalar values, known as an </span><span class="c5">eigenvalue</span>
        </li>
    </ul>
    <h3 class="c22" id="h.7243he8btq3j"><span>Properties</span></h3>
    <ul class="c10 lst-kix_ka06qvb1n25b-0 start">
        <li class="c7 li-bullet-0"><span>There are at most </span><span class="c6">n</span><span
                class="c1">&nbsp;eigenvector-eigenvalue pairs.</span></li>
        <li class="c7 li-bullet-0"><span>If </span><span class="c5">A</span><span>&nbsp;is </span><span
                class="c5">symmetric</span><span>, then the set of eigenvectors is </span><span
                class="c5">orthogonal</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_6de7ypgofw6o-0 start">
        <li class="c7 li-bullet-0"><span>If </span><span class="c5">A </span><span>is a </span><span
                class="c5">covariance matrix</span><span>, then the eigenvectors are the </span><span
                class="c5">principal axes</span></li>
        <li class="c7 li-bullet-0"><span class="c1">The eigenvalues are proportional to the variance of the data along
                each eigenvector</span></li>
        <li class="c7 li-bullet-0"><span>The eigenvector corresponding to the </span><span class="c5">largest
            </span><span>eigenvalue is the first </span><span class="c1">principal component.</span></li>
    </ul>
    <h3 class="c22" id="h.rtu5z6v9alav"><span class="c48 c29 c21">Finding Values</span></h3>
    <ul class="c10 lst-kix_shlkajuua2gd-0 start">
        <li class="c7 li-bullet-0"><span class="c29">For small matrices (</span><span class="c29 c6">n&le;4</span><span
                class="c2">) there are algebraic solutions to finding all the eigenvector-eigenvalues pairs</span></li>
        <li class="c7 li-bullet-0"><span class="c29">For larger matrices, numerical solutions to the </span><span
                class="c29 c5">Eigendecomposition </span><span class="c2">must be sought.</span></li>
    </ul>
    <h3 class="c22" id="h.ao76kyhu56nv"><span class="c26 c21">Eigendecomposition</span></h3>
    <p class="c9"><span>Eigendecomposition takes a matrix and represents it in terms of its eigenvalues and
            eigenvectors.</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 395.00px; height: 90.00px;"><img
                alt="" src="assets/computer-vision/image220.png"
                style="width: 395.00px; height: 90.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_lsi3f5tzornn-0 start">
        <li class="c7 li-bullet-0"><span>Columns of </span><span class="c5">Q</span><span class="c1">&nbsp;are the
                eigenvectors</span></li>
        <li class="c7 li-bullet-0"><span>Diagonal eigenvalue matrix (</span><span class="c5">&Lambda;</span><span
                class="c42">ii</span><span>&nbsp;= &lambda;</span><span class="c42">i</span><span class="c1">)</span>
        </li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_7gq8elg7byps-0 start">
        <li class="c7 li-bullet-0"><span>If </span><span class="c5">A</span><span>&nbsp;is </span><span class="c6">real
                symmetric</span><span>&nbsp;(i.e. a covariance matrix), then </span><span class="c5">Q</span><span
                class="c66">-1</span><span>&nbsp;= </span><span class="c5">Q</span><span class="c66">T</span><span
                class="c1">&nbsp;(i.e. eigenvectors are orthogonal), so:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 379.00px; height: 96.00px;"><img
                    alt="" src="assets/computer-vision/image128.png"
                    style="width: 379.00px; height: 96.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h3 class="c22" id="h.m5y0717acyg1"><span class="c21 c26">Summary</span></h3>
    <p class="c9"><span>The Eigendecomposition of a covariance matrix </span><span class="c5">A</span><span
            class="c1">:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 136.50px; height: 34.58px;"><img
                alt="" src="assets/computer-vision/image128.png"
                style="width: 136.50px; height: 34.58px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Gives you the principal axes and their relative magnitudes.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.9xipgpz465iz"><span class="c48 c29 c21">Ordering</span></h3>
    <ul class="c10 lst-kix_31rrwb7ecyfr-0 start">
        <li class="c7 li-bullet-0"><span class="c29">Standard Eigendecomposition implementations will order the
                eigenvectors (columns of </span><span class="c29 c5">Q</span><span class="c29">) such that the
                eigenvalues (in the diagonal of </span><span class="c29 c5">&Lambda;</span><span class="c2">) are sorted
                in order of decreasing value.</span></li>
    </ul>
    <ul class="c10 lst-kix_31rrwb7ecyfr-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c29">Some solvers are optimised to only find the top </span><span
                class="c29 c6">k</span><span class="c2">&nbsp;eigenvalues and corresponding eigenvectors, rather than
                all of them.</span></li>
    </ul>
    <h2 class="c19" id="h.oybzg79020yb"><span class="c23 c21">Principal Component Analysis</span></h2>
    <h3 class="c22" id="h.vdbp53b2ulxj"><span>Linear Transform</span></h3>
    <ul class="c10 lst-kix_b91ruwgb84g4-0 start">
        <li class="c7 li-bullet-0"><span>A linear transform </span><span class="c5">W</span><span
                class="c1">&nbsp;projects data from one space into another:</span></li>
    </ul>
    <ul class="c10 lst-kix_b91ruwgb84g4-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">T </span><span>= </span><span class="c15 c5">ZW</span></li>
    </ul>
    <ul class="c10 lst-kix_b91ruwgb84g4-2 start">
        <li class="c9 c12 li-bullet-0"><span>Original data stored in the rows of </span><span class="c5">Z</span></li>
    </ul>
    <ul class="c10 lst-kix_b91ruwgb84g4-1">
        <li class="c9 c16 li-bullet-0"><span>T can have fewer dimensions than </span><span class="c5">Z</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 219.00px; height: 437.00px;"><img
                alt="" src="assets/computer-vision/image167.png"
                style="width: 219.00px; height: 437.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.qgppvkwnwvsr"><span class="c26 c21">Linear Transforms</span></h3>
    <ul class="c10 lst-kix_b2s83s8hvcaw-0 start">
        <li class="c7 li-bullet-0"><span>The effects of a linear transform can be reversed if </span><span
                class="c5">W</span><span>&nbsp;is </span><span class="c5">invertible</span><span class="c1">:</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_b2s83s8hvcaw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Z </span><span>= </span><span class="c5">TW</span><span
                class="c66">-1</span></li>
    </ul>
    <ul class="c10 lst-kix_b2s83s8hvcaw-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">A lossy process if the dimensionality of the spaces is
                different</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 208.00px; height: 441.00px;"><img
                alt="" src="assets/computer-vision/image324.png"
                style="width: 208.00px; height: 441.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.bf42na9f5806"><span class="c23 c21">PCA</span></h2>
    <ul class="c10 lst-kix_3w0v2n5jbpuv-0 start">
        <li class="c7 li-bullet-0"><span>PCA is an </span><span class="c5">Orthogonal Linear Transform</span><span
                class="c1">&nbsp;that maps data from its original space to a space defined by the principal axes of the
                data.</span></li>
    </ul>
    <ul class="c10 lst-kix_3w0v2n5jbpuv-1 start">
        <li class="c9 c16 li-bullet-0"><span>The transform matrix </span><span class="c5">W </span><span>is just the
                eigenvector matrix </span><span class="c5">Q</span><span class="c1">&nbsp;from the Eigendecomposition of
                the covariance matrix of the data.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Dimensionality reduction can be achieved by removing the eigenvectors with
                low eigenvalues from </span><span class="c5">Q</span><span>&nbsp;(i.e. keeping the first </span><span
                class="c6">L </span><span>columns of </span><span class="c5">Q</span><span class="c1">&nbsp;assuming the
                eigenvectors are sorted by decreasing eigenvalue).</span></li>
    </ul>
    <h3 class="c22" id="h.tv78nbjwhe3t"><span class="c26 c21">PCA Algorithm</span></h3>
    <ol class="c10 lst-kix_6uiqmpzhlzlc-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c18 c21">Mean-centre the data vectors</span></li>
        <li class="c7 li-bullet-0"><span class="c35 c21">Form the vectors into a matrix </span><span
                class="c5 c35">Z</span><span class="c18 c21">, such that each row corresponds to a vector</span></li>
        <li class="c7 li-bullet-0"><span class="c35 c21">Perform the Eigendecomposition of the matrix </span><span
                class="c5 c35">Z</span><span class="c35 c21 c66">T</span><span class="c5 c35">Z</span><span
                class="c35 c21">, to recover the eigen matrix </span><span class="c5 c35">Q</span><span
                class="c35 c21">&nbsp;and diagonal eigenvalue matrix </span><span class="c5 c35">&Lambda;: Z</span><span
                class="c35 c21 c66">T</span><span class="c5 c35">Z </span><span class="c35 c21">=</span><span
                class="c5 c35">&nbsp;Q&Lambda;Q</span><span class="c35 c21 c66">T</span></li>
        <li class="c7 li-bullet-0"><span class="c35 c21">Sort the columns of </span><span class="c5 c35">Q</span><span
                class="c35 c21">&nbsp;and corresponding diagonal values of </span><span class="c5 c35">&Lambda;
            </span><span class="c18 c21">so that the eigenvalues are decreasing</span></li>
        <li class="c7 li-bullet-0"><span class="c35 c21">Select the L largest eigenvectors of </span><span
                class="c5 c35">Q </span><span class="c35 c21">(the first L columns) to create the transform matrix
                Q</span><span class="c42 c35 c21">L</span></li>
        <li class="c7 li-bullet-0"><span class="c35 c21">Project the original vectors into a lower dimensional space,
            </span><span class="c5 c35">T</span><span class="c42 c5 c35">L</span><span class="c5 c35">: T</span><span
                class="c42 c5 c35">L</span><span class="c5 c35">&nbsp;= ZQ</span><span class="c42 c35 c21">L</span></li>
    </ol>
    <h2 class="c19" id="h.pgjbjnsl3ht2"><span class="c11">Eigenfaces</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 292.00px;"><img
                alt="" src="assets/computer-vision/image276.png"
                style="width: 602.00px; height: 292.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c2">Spooky 0_0</span></p>
    <h3 class="c22" id="h.b4t5dgr4hgqw"><span class="c48 c29 c21">Making Invariant</span></h3>
    <ul class="c10 lst-kix_dt53vd1y2m3m-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Require (almost) the same object pose across images (i.e. full
                frontal faces)</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Align (rotate, scale and translate) the images so that a common
                feature is in the same place (i.e. the eyes in a set of face images)</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Make all the aligned images the same size</span></li>
        <li class="c7 li-bullet-0"><span class="c2">(optional) Normalise (or perhaps histogram equalise) the images so
                they are invariant to global intensity changes</span></li>
    </ul>
    <h3 class="c22" id="h.4cfvm0yi5j3i"><span class="c48 c29 c21">Problems</span></h3>
    <ul class="c10 lst-kix_vzuuhifg7c3z-0 start">
        <li class="c7 li-bullet-0"><span class="c29">Featurevectors</span><span class="c2">&nbsp;are huge</span></li>
    </ul>
    <ul class="c10 lst-kix_vzuuhifg7c3z-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">If the images are 100x200 pixels, the vector has 20000
                dimensions</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">That&rsquo;s not really practical&hellip;</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Also, the vectors are still highly susceptible to imaging noise
                and variations due to slight misalignments.</span></li>
    </ul>
    <h3 class="c22" id="h.xgz2qy88ff0i"><span class="c48 c29 c21">Potential Solution&hellip; Apply PCA</span></h3>
    <ul class="c10 lst-kix_3vudj8e2x12-0 start">
        <li class="c7 li-bullet-0"><span class="c2">PCA can be used to reduce the dimensionality</span></li>
    </ul>
    <ul class="c10 lst-kix_3vudj8e2x12-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Smaller number of dimensions allows greater robustness to noise
                and mis-alignment</span></li>
    </ul>
    <ul class="c10 lst-kix_3vudj8e2x12-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">There are fewer degrees of freedom, so noise/misalignment has
                much less effect</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c2">And the dominant features are captured</span></li>
    </ul>
    <ul class="c10 lst-kix_3vudj8e2x12-1">
        <li class="c9 c16 li-bullet-0"><span class="c2">Fewer dimensions makes applying machine-learning much more
                tractable</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h1 class="c46" id="h.eqyupxg60g7w"><span class="c31 c21">Lecture 4: Types of image feature and segmentation</span>
    </h1>
    <h2 class="c19" id="h.w0yhkccpw81g"><span class="c23 c21">Image Feature Morphology</span></h2>
    <ul class="c10 lst-kix_y1xxj3b8khuz-0 start">
        <li class="c7 li-bullet-0"><span class="c1">There are 4 main ways of extracting features from an image:</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_y1xxj3b8khuz-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Global</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Grid/Block-based</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Region based</span></li>
        <li class="c9 c16 li-bullet-0"><span>Local</span></li>
    </ul>
    <h3 class="c22" id="h.1vbc0xw8x9xz"><span class="c26 c21">Global Features</span></h3>
    <ul class="c10 lst-kix_e9wvgipxq2gh-0 start">
        <li class="c7 li-bullet-0"><span>A </span><span class="c5">Global Feature </span><span class="c1">is extracted
                from the contents of an entire image.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 266.67px;"><img
                alt="" src="assets/computer-vision/image321.png"
                style="width: 602.00px; height: 266.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.b4x5o1ibh85z"><span class="c26 c21">Grid or Block-based Features</span></h3>
    <ul class="c10 lst-kix_2pyu23s254iu-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Multiple features are extracted; one per block</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 284.00px;"><img
                alt="" src="assets/computer-vision/image290.png"
                style="width: 602.00px; height: 284.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.vc54aveoejqd"><span class="c26 c21">Region-based Features</span></h3>
    <ul class="c10 lst-kix_2pyu23s254iu-0">
        <li class="c7 li-bullet-0"><span class="c1">Multiple features are extracted; one per region</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 285.33px;"><img
                alt="" src="assets/computer-vision/image177.png"
                style="width: 602.00px; height: 285.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.7zb3wepl6bvu"><span class="c26 c21">Local Features</span></h3>
    <ul class="c10 lst-kix_l7fxqor6y4on-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Multiple features are extracted; one per local interest point</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 281.33px;"><img
                alt="" src="assets/computer-vision/image174.png"
                style="width: 602.00px; height: 281.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.d1b2ik55rt54"><span class="c23 c21">Global Features</span></h2>
    <h3 class="c22" id="h.oeiysmjdwhvh"><span class="c26 c21">Image Histograms</span></h3>
    <ul class="c10 lst-kix_rbc0pcoka18b-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Simple global features can be computed from the average of the
                colour bands of the image&rsquo;s histogram.</span></li>
    </ul>
    <ul class="c10 lst-kix_rbc0pcoka18b-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">This wasn&rsquo;t particularly robust, and couldn&rsquo;t deal
                well with multiple colours in the image.</span></li>
    </ul>
    <ul class="c10 lst-kix_rbc0pcoka18b-0">
        <li class="c7 li-bullet-0"><span class="c1">A more common approach to computing a global image description is to
                compute a histogram of the pixel values.</span></li>
    </ul>
    <h3 class="c22" id="h.xd305kbo099q"><span class="c26 c21">Joint-colour histogram</span></h3>
    <ul class="c10 lst-kix_3qptpxwb787f-0 start">
        <li class="c7 li-bullet-0"><span class="c1">A joint colour histogram measures the number of times each colour
                appears in an image.</span></li>
    </ul>
    <ul class="c10 lst-kix_3qptpxwb787f-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">These are different to histograms in image editing programs with
                compute separate histograms for each channel.</span></li>
        <li class="c9 c16 li-bullet-0"><span>The colour space is </span><span class="c6">quantised</span><span
                class="c1">&nbsp;into bins, and we accumulate the number of pixels in each bin.</span></li>
    </ul>
    <ul class="c10 lst-kix_3qptpxwb787f-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Technically, it&rsquo;s a multidimensional histogram, but we
                flatten it (unwrap) to make it a feature vector.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_n4r2j1z85wye-0 start">
        <li class="c7 li-bullet-0"><span class="c29">Normalisation (i.e. by the number of pixels) allows the histogram
                to be </span><span class="c29 c6">invariant </span><span class="c2">to image size.</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Choice of colour-space can make it invariant to uniform lighting
                changes (e.g. H-S histogram)</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Invariant to rotation</span></li>
        <li class="c7 li-bullet-0"><span class="c2">But vastly different images can have the same histogram! Like these
                two below:</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 283.69px; height: 228.50px;"><img
                alt="" src="assets/computer-vision/image253.png"
                style="width: 283.69px; height: 228.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 282.00px; height: 227.00px;"><img
                alt="" src="assets/computer-vision/image302.png"
                style="width: 282.00px; height: 227.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_7ziy6zy71a1m-0 start">
        <li class="c7 li-bullet-0"><span class="c36 c68 c21">Cool, right? Even though it&rsquo;s, uh, bad; not invariant
                to this kinda problem lol</span></li>
    </ul>
    <h2 class="c19" id="h.ypi7l1q2v3ep"><span class="c23 c21">Image Segmentation</span></h2>
    <h3 class="c22" id="h.z2crchf8lzi7"><span>What is segmentation?</span></h3>
    <ul class="c10 lst-kix_3qnu1l9j5hyy-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The first part in the process of creating region-based
                descriptions&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_3qnu1l9j5hyy-1 start">
        <li class="c9 c16 li-bullet-0"><span>The process of partitioning the image into </span><span
                class="c6 c5">sets</span><span>&nbsp;of pixels often called </span><span
                class="c6 c5">segments</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Pixels within a segment typically share certain visual
                characteristics.</span></li>
    </ul>
    <h3 class="c22" id="h.aq04qk7gtqno"><span class="c26 c21">Global Binary Thresholding</span></h3>
    <ul class="c10 lst-kix_h7dhdp2ia8qd-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Thresholding is the simplest form of segmentation</span></li>
    </ul>
    <ul class="c10 lst-kix_h7dhdp2ia8qd-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Turns grey level images into binary (2 segments) by assigning
                all pixels with a value less than a predetermined threshold to one segment, and all other pixels to the
                other.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Really fast</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Required a manually set static threshold</span></li>
    </ul>
    <ul class="c10 lst-kix_h7dhdp2ia8qd-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Not robust to lightning changes</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Can work well in applications with lots of physical constraints
                (lighting control and / or high-contrast objects)</span></li>
    </ul>
    <h3 class="c22" id="h.r8jii5w2jsl0"><span class="c26 c21">Otsu&rsquo;s thresholding method</span></h3>
    <ul class="c10 lst-kix_hox8qb15f4dn-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Otsu&rsquo;s method (named after Nobuyuki Otsu) provides a way to
                automatically find the threshold.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Assume there are two classes (i.e. foreground &amp;
                background)</span></li>
    </ul>
    <ul class="c10 lst-kix_hox8qb15f4dn-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">The histogram must have two peaks</span></li>
    </ul>
    <ul class="c10 lst-kix_hox8qb15f4dn-0">
        <li class="c7 li-bullet-0"><span class="c1">Exhaustively search for the threshold that maximises interclass
                variance.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 423.50px; height: 359.36px;"><img
                alt="" src="assets/computer-vision/image72.png"
                style="width: 423.50px; height: 359.36px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Otsu%2527s_method&amp;sa=D&amp;source=editors&amp;ust=1623775880449000&amp;usg=AOvVaw35FdC6vBV79iE959WHnmiR">More
                detailed look over at wikipedia!</a></span></p>
    <h3 class="c22" id="h.b1i5vo8596sf"><span class="c26 c21">Adaptive / local thresholding</span></h3>
    <ul class="c10 lst-kix_7vu7sl7vgbno-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Local (or Adaptive) thresholding operators compute a different
                threshold value for every pixel in an image based on the surrounding pixels.</span></li>
    </ul>
    <ul class="c10 lst-kix_7vu7sl7vgbno-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Usually a square or rectangular window around the current pixel
                is used to define the neighbours</span></li>
    </ul>
    <h3 class="c22" id="h.1se2cwtf55o3"><span class="c26 c21">Mean adaptive thresholding</span></h3>
    <p class="c9"><span class="c6">Set the current pixel to 0 if its value is less than the </span><span
            class="c6 c5">mean</span><span class="c6">&nbsp;of its neighbours plus a </span><span
            class="c6 c5">constant</span><span class="c6">&nbsp;value; otherwise set to 1.</span></p>
    <ul class="c10 lst-kix_d25bgjne25gw-0 start">
        <li class="c7 li-bullet-0"><span class="c43 c6 c21">Parameters:</span></li>
    </ul>
    <ul class="c10 lst-kix_d25bgjne25gw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c43 c6 c21">Size of window</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c43 c6 c21">Constant offset value</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_2wbe2d770ajp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Good invariance to uneven lighting / contrast</span></li>
        <li class="c7 li-bullet-0"><span class="c1">But&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_2wbe2d770ajp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Computationally expensive (at least compared to global
                methods)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Can be difficult to choose the window size</span></li>
    </ul>
    <ul class="c10 lst-kix_2wbe2d770ajp-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">If the object being imaged can appear at different distance to
                the camera then it could break&hellip;</span></li>
    </ul>
    <h3 class="c22" id="h.jzgxig4pxzl6"><span class="c26 c21">Segmentation with K-Means</span></h3>
    <ul class="c10 lst-kix_91a6fwl0zyk7-0 start">
        <li class="c7 li-bullet-0"><span class="c1">K-Means clustering also provides a simple method for performing
                segmentation:</span></li>
    </ul>
    <ul class="c10 lst-kix_91a6fwl0zyk7-1 start">
        <li class="c9 c16 li-bullet-0"><span>Cluster the colour vectors (i.e. [</span><span
                class="c89">r</span><span>,</span><span>&nbsp;</span><span class="c49">g</span><span>, </span><span
                class="c13">b</span><span class="c1">]) of all the pixels, and then assign each pixel to a segment based
                on the closest cluster centroid.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Works best if the colour-space and distance function are
                compatible</span></li>
    </ul>
    <ul class="c10 lst-kix_91a6fwl0zyk7-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">E.g. Lab colour-space is designed so that Euclidean distances
                are proportional to perceptual colour differences</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_iuvbjmyohm8g-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Na&iuml;ve approach to segmentation using k-means doesn&rsquo;t
                attempt to preserve continuity of segments</span></li>
    </ul>
    <ul class="c10 lst-kix_iuvbjmyohm8g-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Might end up with single pixels assigned to a segment, far away
                from other pixels in that segment.</span></li>
    </ul>
    <ul class="c10 lst-kix_iuvbjmyohm8g-0">
        <li class="c7 li-bullet-0"><span>Can also encode spatial position in the vectors being clustered:
                &nbsp;[</span><span class="c89">r</span><span>, </span><span class="c49">g</span><span>, </span><span
                class="c13">b</span><span class="c1">, x, y]</span></li>
    </ul>
    <ul class="c10 lst-kix_iuvbjmyohm8g-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Normalise x and y by the width and height of the image to take
                away the effect of different images sizes</span></li>
        <li class="c9 c16 li-bullet-0"><span>Scale x and y so they have more or less effect than the colour
                components</span></li>
    </ul>
    <h3 class="c22" id="h.cdamjurmh46r"><span class="c26 c21">Advanced segmentation techniques</span></h3>
    <ul class="c10 lst-kix_weimnzqkumm2-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Lots of ongoing research into better segmentation techniques:</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_weimnzqkumm2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Techniques that can automatically determine the number of
                segments</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">&ldquo;Semantic segmentation&rdquo; techniques that try to
                create segments that fit the objects in the scene based on training examples</span></li>
    </ul>
    <h2 class="c19" id="h.qjtv8cw0rkr9"><span class="c23 c21">Connected Components</span></h2>
    <h3 class="c22" id="h.2quijahlnq4t"><span class="c26 c21">Pixel Connectivity</span></h3>
    <ul class="c10 lst-kix_pgn2mka57hml-0 start">
        <li class="c7 li-bullet-0"><span class="c1">A pixel is said to be connected with another if they are spatially
                adjacent to each other.</span></li>
    </ul>
    <ul class="c10 lst-kix_pgn2mka57hml-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Two standard ways of defining this adjacency:</span></li>
    </ul>
    <ul class="c10 lst-kix_pgn2mka57hml-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">4-connectivity</span></li>
        <li class="c9 c12 li-bullet-0"><span>8-connectivity </span><span class="c36 c68 c21">(like minesweeper!)</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 422.39px; height: 232.50px;"><img
                alt="" src="assets/computer-vision/image345.png"
                style="width: 422.39px; height: 232.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.ly56umo30dfb"><span class="c48 c29 c21">Connected Component</span></h3>
    <p class="c9"><span class="c29">A connected component is a set of pixels in which every pixel is connected either
            directly or through any connected path of pixels from the set.</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 372.00px; height: 372.00px;"><img
                alt="" src="assets/computer-vision/image233.png"
                style="width: 372.00px; height: 372.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.1vptw2gx0ctk"><span class="c26 c21">Connected Component Labelling</span></h3>
    <ul class="c10 lst-kix_7yzyp2cmecw1-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Connected Component Labelling is the process of finding all the
                connected components within a binary (segmented) image.</span></li>
    </ul>
    <ul class="c10 lst-kix_7yzyp2cmecw1-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Each connected segment is identified as a connected
                component.</span></li>
    </ul>
    <ul class="c10 lst-kix_7yzyp2cmecw1-0">
        <li class="c7 li-bullet-0"><span class="c1">Lots of different algorithms to perform connected component
                labelling</span></li>
    </ul>
    <ul class="c10 lst-kix_7yzyp2cmecw1-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Different performance tradeoffs (memory verses time)</span></li>
    </ul>
    <h3 class="c22" id="h.p25mkdd477mz"><span class="c26 c21">The two-pass algorithm</span></h3>
    <ol class="c10 lst-kix_aqop2jyuh14e-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c18 c21">On the first pass:</span></li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-1 start" start="1">
        <li class="c9 c16 li-bullet-0"><span class="c18 c21">Iterate through each element of the data by column, then by
                row (Raster Scanning)</span></li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c18 c21">If the element is not the background</span></li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-3 start" start="1">
        <li class="c9 c55 li-bullet-0"><span class="c18 c21">Get the neighbouring elements of the current element</span>
        </li>
        <li class="c9 c55 li-bullet-0"><span class="c18 c21">If there are no neighbours, uniquely label the current
                element and continue</span></li>
        <li class="c9 c55 li-bullet-0"><span class="c35 c21">Otherwise, find the neighbour with the smallest label and
                assign it to </span><span class="c35 c21">the</span><span class="c18 c21">&nbsp;current element</span>
        </li>
        <li class="c9 c55 li-bullet-0"><span class="c18 c21">Store the equivalence between neighbouring labels</span>
        </li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-0" start="2">
        <li class="c7 li-bullet-0"><span class="c18 c21">On the second pass:</span></li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-1 start" start="1">
        <li class="c9 c16 li-bullet-0"><span class="c18 c21">Iterate through each element of the data by column, then by
                row</span></li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c18 c21">If the element is not the background</span></li>
    </ol>
    <ol class="c10 lst-kix_aqop2jyuh14e-3 start" start="1">
        <li class="c9 c55 li-bullet-0"><span class="c35 c21">Relabel the element with the lowest equivalent label</span>
        </li>
    </ol>
    <h1 class="c46" id="h.36kzsod8q2go"><span class="c31 c21">Lecture 5: Shape description and modelling</span></h1>
    <h2 class="c19" id="h.170xuhz620u5"><span class="c23 c21">Extracting features from shapes represented by connected
            components</span></h2>
    <h3 class="c22" id="h.sdil8cl9yrga"><span class="c26 c21">Borders</span></h3>
    <ul class="c10 lst-kix_e24ddp2se0au-0 start">
        <li class="c7 li-bullet-0"><span>There are </span><span class="c5">2</span><span>&nbsp;types of pixel borders:
            </span><span class="c5">inner </span><span>and </span><span class="c5">outer</span><span class="c1">.</span>
        </li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">Say you have this pixel shape:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 293.00px; height: 152.00px;"><img
                alt="" src="assets/computer-vision/image330.png"
                style="width: 293.00px; height: 152.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h4 class="c17" id="h.os565i2g2oc1"><span class="c72 c41 c21">Inner Border</span></h4>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 303.00px; height: 159.00px;"><img
                alt="" src="assets/computer-vision/image92.png"
                style="width: 303.00px; height: 159.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">A border made up of only pixels from the shape; the outermost pixels within the
            shape.</span></p>
    <h4 class="c17" id="h.y0v7fiyt9qt1"><span class="c72 c41 c21">Outer Border</span></h4>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 386.00px; height: 243.00px;"><img
                alt="" src="assets/computer-vision/image81.png"
                style="width: 386.00px; height: 243.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">A border where the outline of pixels outside the shape make up the border.</span></p>
    <h3 class="c22" id="h.4hiwo6kmmfjo"><span class="c26 c21">Two ways to describe shape</span></h3>
    <ol class="c10 lst-kix_d4hiyhf2dbbt-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Region Description</span></li>
        <li class="c7 li-bullet-0"><span>Boundary Description</span></li>
    </ol>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 256.00px;"><img
                alt="" src="assets/computer-vision/image143.png"
                style="width: 602.00px; height: 256.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.rnuyumkn9a3j"><span class="c23 c21">Region Description: Simple Scalar Shape Features</span>
    </h2>
    <h3 class="c22" id="h.w87tf1nedhwj"><span class="c26 c21">Area and Perimeter</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 292.00px;"><img
                alt="" src="assets/computer-vision/image344.png"
                style="width: 602.00px; height: 292.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.upn2q7f6warm"><span class="c26 c21">Compactness</span></h3>
    <ul class="c10 lst-kix_a91jlpumzzfl-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Compactness measures how tightly packed the pixels in the component
                are.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">It&rsquo;s often computed as the weighted ratio of area to perimeter
                squared:</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 259.00px; height: 117.00px;"><img
                alt="" src="assets/computer-vision/image351.png"
                style="width: 259.00px; height: 117.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_a91jlpumzzfl-0">
        <li class="c7 li-bullet-0"><span class="c1">Examples:</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 282.87px; height: 281.50px;"><img
                alt="" src="assets/computer-vision/image230.png"
                style="width: 282.87px; height: 281.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.kyaowyx54gxy"><span class="c26 c21">Centre of Mass</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 447.73px; height: 290.50px;"><img
                alt="" src="assets/computer-vision/image258.png"
                style="width: 447.73px; height: 290.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.6uzukm6c0zt"><span class="c26 c21">Irregularity / Dispersion</span></h3>
    <p class="c9"><span class="c1">A measure of how &ldquo;spread-out&rdquo; the shape is</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 524.50px; height: 324.49px;"><img
                alt="" src="assets/computer-vision/image214.png"
                style="width: 524.50px; height: 324.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.o43xkdlyavsz"><span class="c23 c21">Moments</span></h2>
    <h3 class="c22" id="h.f2ekr7sflkrn"><span class="c26 c21">Standard Moments</span></h3>
    <ul class="c10 lst-kix_q7g6vgnth9j6-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Moments describe the distribution of pixels in a shape.</span></li>
    </ul>
    <ul class="c10 lst-kix_q7g6vgnth9j6-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Moments can be computed for any grey-level image. For the
                purposes of describing shape, we&rsquo;ll just focus on moments of a connected component</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Standard two-dimensional Cartesian moment of an image, with
                order p and q and I(s) as the pixel intensity, it is defined as:</span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 380.50px; height: 68.29px;"><img
                    alt="" src="assets/computer-vision/image144.png"
                    style="width: 380.50px; height: 68.29px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">In the case of a connected component, this simplifies to:</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 189.50px; height: 65.31px;"><img
                    alt="" src="assets/computer-vision/image157.png"
                    style="width: 189.50px; height: 65.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_q7g6vgnth9j6-2 start">
        <li class="c9 c12 li-bullet-0"><span>The zero order moment of a connected component m</span><span
                class="c42">00</span><span class="c1">&nbsp;is just the area of the component. The centre of mass is
                (centroid):</span></li>
        <li class="c9 c12 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 175.00px; height: 53.00px;"><img
                    alt="" src="assets/computer-vision/image190.png"
                    style="width: 175.00px; height: 53.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h3 class="c22" id="h.b85r2j8dofai"><span class="c26 c21">Central Moments</span></h3>
    <ul class="c10 lst-kix_jcslqfavcgof-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Standard 2D moments can be used as shape descriptors</span></li>
    </ul>
    <ul class="c10 lst-kix_jcslqfavcgof-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">But, they&rsquo;re not invariant to translation, rotation and
                scaling</span></li>
    </ul>
    <ul class="c10 lst-kix_jcslqfavcgof-0">
        <li class="c7 li-bullet-0"><span class="c5">Central Moments</span><span class="c1">&nbsp;are computed about the
                centroid of the shape, and are thus translation invariant:</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 354.00px; height: 72.00px;"><img
                alt="" src="assets/computer-vision/image216.png"
                style="width: 354.00px; height: 72.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_eot4voq0kis7-0 start">
        <li class="c7 li-bullet-0"><span>Note: </span><span>&mu;</span><span class="c42">01</span><span>&nbsp;and
                &mu;</span><span class="c42">10</span><span class="c1">&nbsp;are always 0, so have no descriptive
                power</span></li>
    </ul>
    <h3 class="c22" id="h.18gql5oqgvgo"><span class="c26 c21">Normalised Central Moments</span></h3>
    <ul class="c10 lst-kix_wbhw884cphe5-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Normalised Central Moments</span><span class="c1">&nbsp;are both
                scale and translation invariant</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 117.33px;"><img
                alt="" src="assets/computer-vision/image191.png"
                style="width: 602.00px; height: 117.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.yzzsbu2n9p7k"><span class="c23 c21">Boundary Description</span></h2>
    <h3 class="c22" id="h.w8he9ccgnnsg"><span class="c26 c21">Chain Codes</span></h3>
    <ul class="c10 lst-kix_26vsb2l60kye-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Simple way of encoding a boundary.</span></li>
    </ul>
    <ul class="c10 lst-kix_26vsb2l60kye-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Walk around the boundary and encode the direction you take on
                each step as a number.</span></li>
    </ul>
    <ul class="c10 lst-kix_26vsb2l60kye-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Some direction examples are shown below left.</span></li>
    </ul>
    <ul class="c10 lst-kix_26vsb2l60kye-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Then cyclically shift the code so it forms the smallest possible
                integer value (making it invariant to the starting point)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 174.80px; height: 370.50px;"><img
                alt="" src="assets/computer-vision/image247.png"
                style="width: 174.80px; height: 370.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 384.00px; height: 371.00px;"><img
                alt="" src="assets/computer-vision/image87.gif"
                style="width: 384.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.evssub9r3lz3"><span class="c26 c21">Chain Code Invariance</span></h3>
    <ul class="c10 lst-kix_l8l9j9hjv14f-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Can be made rotation invariant:</span></li>
    </ul>
    <ul class="c10 lst-kix_l8l9j9hjv14f-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Encode the differences in direction rather than absolute
                values.</span></li>
    </ul>
    <ul class="c10 lst-kix_l8l9j9hjv14f-0">
        <li class="c7 li-bullet-0"><span class="c1">Can be made scale invariant:</span></li>
    </ul>
    <ul class="c10 lst-kix_l8l9j9hjv14f-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Resample the component to a fixed size</span></li>
    </ul>
    <ul class="c10 lst-kix_l8l9j9hjv14f-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Doesn&rsquo;t work well in practice</span></li>
    </ul>
    <h3 class="c22" id="h.hmduyiaiflow"><span class="c48 c29 c21">Chain Code Advantages and Limitations</span></h3>
    <ul class="c10 lst-kix_efsfeez1pom1-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Can be used for computing perimeter area, moments, etc.</span></li>
    </ul>
    <ul class="c10 lst-kix_efsfeez1pom1-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Perimeter for and 8-connected chain code is N(even numbers in
                code) + &radic;2N(odd numbers in code)</span></li>
    </ul>
    <p class="c3"><span class="c2"></span></p>
    <ul class="c10 lst-kix_bn5h1edneqmw-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Practically speaking, not so good for shape matching</span></li>
    </ul>
    <ul class="c10 lst-kix_bn5h1edneqmw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Problems with noise, resampling effects, etc</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c29">Difficult to find good similarity/distance measures</span></li>
    </ul>
    <h3 class="c22" id="h.82ge272fzh4n"><span class="c48 c29 c21">Fourier Descriptors</span></h3>
    <ul class="c10 lst-kix_kqq4cj19gijh-0 start">
        <li class="c7 li-bullet-0"><span class="c2">The Fourier transform can be used to encode shape information by
                decomposing the boundary into a (small) set of frequency components.</span></li>
    </ul>
    <ul class="c10 lst-kix_kqq4cj19gijh-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">There are two main steps to consider:</span></li>
    </ul>
    <ul class="c10 lst-kix_kqq4cj19gijh-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">Defining a representation of a curve (the boundary)</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c2">Expanding the representation using Fourier theory</span></li>
    </ul>
    <ul class="c10 lst-kix_kqq4cj19gijh-1">
        <li class="c9 c16 li-bullet-0"><span class="c2">By choosing these steps carefully it is possible to create
                rotation, translation and scale invariant boundary descriptions that can be used for recognition,
                etc.</span></li>
    </ul>
    <h2 class="c19" id="h.bnd5a67osaq"><span class="c23 c21">Region Adjacency Graphs</span></h2>
    <ul class="c10 lst-kix_x7bq6xasun86-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Build a graph from a set of connected components</span></li>
    </ul>
    <ul class="c10 lst-kix_x7bq6xasun86-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Each node corresponds to a component</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Nodes connected if they share a border</span></li>
    </ul>
    <ul class="c10 lst-kix_x7bq6xasun86-0">
        <li class="c7 li-bullet-0"><span class="c1">Can easily detect patterns in the graph</span></li>
    </ul>
    <ul class="c10 lst-kix_x7bq6xasun86-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">E.g. &ldquo;a node with one child with four
                children&rdquo;</span></li>
    </ul>
    <ul class="c10 lst-kix_x7bq6xasun86-0">
        <li class="c7 li-bullet-0"><span>Invariant to non-linear distortions, but not to </span><span
                class="c6">occlusion</span><span>.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 209.33px;"><img
                alt="" src="assets/computer-vision/image313.png"
                style="width: 602.00px; height: 209.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c36 c13 c21"></span></p>
    <p class="c3"><span class="c36 c13 c21"></span></p>
    <p class="c9"><span class="c36 c13 c21">Theres some more stuff in the slides which isn&rsquo;t hand with bow-ed, go
            have a look</span></p>
    <p class="c9"><span class="c13">Slides 40-47: </span><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=http://comp3204.ecs.soton.ac.uk/lectures/pdf/L5-shapedescription.pdf&amp;sa=D&amp;source=editors&amp;ust=1623775880465000&amp;usg=AOvVaw3HDqQ0s0PDsFxdPAxo5b5e">http://comp3204.ecs.soton.ac.uk/lectures/pdf/L5-shapedescription.pdf</a></span>
    </p>
    <h2 class="c19" id="h.9bt76860dlus"><span class="c23 c21">Active Shape Models and Constrained Local Models</span>
    </h2>
    <ul class="c10 lst-kix_gk0n3oaxf2jm-0 start">
        <li class="c7 li-bullet-0"><span>ASMs/CLMs extend a </span><span>PDM </span><span class="c1">(Point Distribution
                Model) by also learning local appearance around each point</span></li>
    </ul>
    <ul class="c10 lst-kix_gk0n3oaxf2jm-1 start">
        <li class="c9 c16 li-bullet-0"><span>Typically just as an image </span><span class="c6">template</span><span
                class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_gk0n3oaxf2jm-0">
        <li class="c7 li-bullet-0"><span class="c1">Using a constrained optimisation algorithm, the shape can be
                optimally fitted to an image</span></li>
    </ul>
    <ul class="c10 lst-kix_gk0n3oaxf2jm-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Constraints:</span></li>
    </ul>
    <ul class="c10 lst-kix_gk0n3oaxf2jm-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c43 c6 c21">Plausible shape</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c6">Good template matching</span></li>
    </ul>
    <h1 class="c46" id="h.hawd7v91o2fl"><span class="c31 c21">Lecture 6: Local interest points</span></h1>
    <h2 class="c19" id="h.igxj4uizlu6v"><span>What makes a good interest point?</span></h2>
    <ul class="c10 lst-kix_qhrbg9nmkxe-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Invariance to brightness change (local changes as well as global
                ones)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Sufficient texture variation in the local neighbourhood</span></li>
    </ul>
    <ul class="c10 lst-kix_qhrbg9nmkxe-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">But not too much!</span></li>
    </ul>
    <ul class="c10 lst-kix_qhrbg9nmkxe-0">
        <li class="c7 li-bullet-0"><span class="c1">Invariance to changes between the angle / position of the scene to
                the camera</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 343.00px; height: 220.00px;"><img
                alt="" src="assets/computer-vision/image104.png"
                style="width: 343.00px; height: 220.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.rqc5a1xpinmw"><span class="c23 c21">How to find interest points</span></h2>
    <ul class="c10 lst-kix_gyu5qzs38oti-0 start">
        <li class="c7 li-bullet-0"><span class="c1">There are lots of different types of interest point types to choose
                from</span></li>
    </ul>
    <ul class="c10 lst-kix_gyu5qzs38oti-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">We&rsquo;ll focus on two specific types and look in detail at
                common detection algorithms:</span></li>
    </ul>
    <ul class="c10 lst-kix_gyu5qzs38oti-2 start">
        <li class="c9 c12 li-bullet-0"><span>Corner detection - </span><span class="c43 c6 c21">Harris and
                stephens</span></li>
        <li class="c9 c12 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 190.00px; height: 207.00px;"><img
                    alt="" src="assets/computer-vision/image357.png"
                    style="width: 190.00px; height: 207.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c12 li-bullet-0"><span>Blob Detection - </span><span class="c6">Difference-of-Gaussian
                Extrema</span></li>
        <li class="c9 c12 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 188.00px; height: 209.00px;"><img
                    alt="" src="assets/computer-vision/image118.png"
                    style="width: 188.00px; height: 209.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.xj82bw5edhf3"><span class="c23 c21">The Harris and Stephens corner detector</span></h2>
    <h3 class="c22" id="h.56s1ffw478lw"><span class="c26 c21">Basic Idea</span></h3>
    <ul class="c10 lst-kix_ix0y0zxdz0ga-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Search for corners by looking through a small window</span></li>
        <li class="c7 li-bullet-0"><span>Shifting that window by a small amount in </span><span class="c6">any direction
            </span><span>should give a </span><span class="c6">large change</span><span class="c1">&nbsp;in
                intensity</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 177.01px; height: 171.50px;"><img
                    alt="" src="assets/computer-vision/image343.png"
                    style="width: 177.01px; height: 171.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 258.67px;"><img
                alt="" src="assets/computer-vision/image328.png"
                style="width: 602.00px; height: 258.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.ri611ke4amb1"><span class="c26 c21">Harris &amp; Stephens: Mathematics</span></h3>
    <p class="c9"><span class="c1">Weighted average change in intensity between a window and a shifted version [by
            (&Delta;x,&Delta;y)] of that window:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 277.33px;"><img
                alt="" src="assets/computer-vision/image209.png"
                style="width: 602.00px; height: 277.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_iu45052tfu7v-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The Taylor expansion allows us to approximate the shifted
                intensity.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Taking the first order terms we get this:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 133.33px;"><img
                    alt="" src="assets/computer-vision/image183.png"
                    style="width: 602.00px; height: 133.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_8z6h6wmsx3v9-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Substituting and simplifying gives:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 357.33px;"><img
                    alt="" src="assets/computer-vision/image221.png"
                    style="width: 602.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c36 c81 c21">Bruh.</span></li>
    </ul>
    <h3 class="c22" id="h.n3yj36hzpyw3"><span class="c26 c21">Structure Tensor</span></h3>
    <ul class="c10 lst-kix_wpdt6p3oi1ad-0 start">
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">square symmetric</span><span>&nbsp;matrix
            </span><span class="c5">M</span><span>&nbsp;is called the </span><span class="c6">Structure
                Tensor</span><span>&nbsp;or the </span><span class="c6">Second Moment matrix</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 128.00px;"><img
                    alt="" src="assets/computer-vision/image160.png"
                    style="width: 602.00px; height: 128.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c1">It concisely encodes how the local shape intensity function of the
                window changes with small shifts</span></li>
    </ul>
    <h3 class="c22" id="h.ga25farzxogb"><span class="c26 c21">Eigenvalues of the Structure Tensor</span></h3>
    <ul class="c10 lst-kix_18yhs1u4wa4k-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Think back to covariance matrices&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_18yhs1u4wa4k-1 start">
        <li class="c9 c16 li-bullet-0"><span>As with the 2D covariance matrix, the structure tensor describes and
                ellipse: x</span><span class="c66">T</span><span class="c5">M</span><span>x=c (this is a </span><span
                class="c6">quadratic form</span><span class="c1">)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">The eigenvalues and vectors tell us the rates of change and
                their respective directions</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 508.00px;"><img
                alt="" src="assets/computer-vision/image307.png"
                style="width: 602.00px; height: 508.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.ttaafybqugor"><span class="c26 c21">Harris &amp; Stephens Response Function</span></h3>
    <ul class="c10 lst-kix_ofw3otfrokp3-0 start">
        <li class="c7 li-bullet-0"><span>Rather than compute the eigenvalues directly, Harris and Stephens defined a
                corner response function in terms of the determinant and trace of </span><span class="c5">M</span><span
                class="c1">:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 237.33px;"><img
                    alt="" src="assets/computer-vision/image136.png"
                    style="width: 602.00px; height: 237.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c36 c21 c81">Smart.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 505.33px;"><img
                alt="" src="assets/computer-vision/image155.png"
                style="width: 602.00px; height: 505.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.v8j250vcxfdu"><span class="c26 c21">Harris &amp; Stephens Detector</span></h3>
    <ul class="c10 lst-kix_nzaxky30uhb2-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Simple algorithm:</span></li>
    </ul>
    <ul class="c10 lst-kix_nzaxky30uhb2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Take all points with the response value above a threshold</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Keep only the points that are local maxima (i.e. where the
                current response is bigger than the 8 neighbouring pixels)</span></li>
    </ul>
    <h2 class="c19" id="h.1h601c8x29j3"><span class="c23 c21">Scale in Computer Vision</span></h2>
    <h3 class="c22" id="h.83v5p4nxrfdp"><span class="c26 c21">The problem of scale</span></h3>
    <ul class="c10 lst-kix_fdlj02gbdmgu-0 start">
        <li class="c7 li-bullet-0"><span class="c1">As an object moves closer to the camera it gets larger with more
                detail&hellip; as it moves further away it gets smaller and loses detail&hellip;</span></li>
        <li class="c7 li-bullet-0"><span class="c1">If you&rsquo;re using a technique that uses a fixed size processing
                window (e.g. Harris corners, or indeed anything that involves a fixed kernel) then this is a bit of a
                problem!</span></li>
    </ul>
    <h3 class="c22" id="h.262gckmizhdc"><span class="c26 c21">Scale space theory</span></h3>
    <ul class="c10 lst-kix_r5zq848ees2b-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Scale space theory is a formal framework for handling the scale
                problem.</span></li>
    </ul>
    <ul class="c10 lst-kix_r5zq848ees2b-1 start">
        <li class="c9 c16 li-bullet-0"><span>Represents the image by a series of increasingly smoothed / blurred images
                parameterised by a scale parameter </span><span class="c6">t</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c6">t</span><span class="c1">&nbsp;represents the amount of
                smoothing.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Key notion: </span><span>Image structures smaller than
                &radic;</span><span class="c6">t</span><span>&nbsp;have been smoothed away at scale </span><span
                class="c6">t</span><span class="c1">.</span></li>
    </ul>
    <h3 class="c22" id="h.mlec6uwrpjtk"><span class="c26 c21">The Gaussian Scale Space</span></h3>
    <ul class="c10 lst-kix_w9zoz2i8sv21-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Many possible types of scale space are possible (depending on the
                smoothing function), but only the Gaussian function has the desired properties for image
                representation.</span></li>
    </ul>
    <ul class="c10 lst-kix_w9zoz2i8sv21-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c29">These provable properties are called the &ldquo;</span><span
                class="c29 c6">scale space axioms</span><span class="c2">&rdquo;.</span></li>
    </ul>
    <p class="c9"><span class="c1">Formally, Gaussian scale space is defined as:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 97.33px;"><img
                alt="" src="assets/computer-vision/image206.png"
                style="width: 602.00px; height: 97.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Where t &ge; 0 and,</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 582.00px; height: 154.00px;"><img
                alt="" src="assets/computer-vision/image179.png"
                style="width: 582.00px; height: 154.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span>Normally, only a fixed set of values of </span><span class="c6">t</span><span
            class="c1">&nbsp;are used - it&rsquo;s common to use integer powers of 2 or &radic;2</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 338.00px;"><img
                alt="" src="assets/computer-vision/image257.png"
                style="width: 602.00px; height: 417.00px; margin-left: 0.00px; margin-top: -79.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.3wxc3i44ofge"><span class="c26 c21">Nyquist-Shannon Sampling theorem</span></h3>
    <p class="c9"><span class="c15 c5">If a function x(t) contains no frequencies higher than B hertz, it is completely
            determined by giving its ordinates at a series of points spaced 1/(2B) seconds apart.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span>...</span><span class="c43 c6 c21">so, if you filter the signal with a low-pass filter that
            halves the frequency content, you can also half the sampling rate without loss of information&hellip;</span>
    </p>
    <h3 class="c22" id="h.pupmen7hxoec"><span class="c26 c21">Gaussian Pyramid</span></h3>
    <ul class="c10 lst-kix_khnlnvue68gc-0 start">
        <li class="c7 li-bullet-0"><span>Every time you double </span><span class="c6">t</span><span class="c1">&nbsp;in
                scale space, you can half the image size without loss off information!</span></li>
    </ul>
    <ul class="c10 lst-kix_khnlnvue68gc-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Leads to a much more efficient representation</span></li>
    </ul>
    <ul class="c10 lst-kix_khnlnvue68gc-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Faster processing</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Less memory</span></li>
    </ul>
    <h2 class="c19" id="h.zdifhduyxv6y"><span class="c23 c21">Multi-scale Harris &amp; Stephens</span></h2>
    <ul class="c10 lst-kix_mf92uhiyqhty-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Extending the Harris and Stephens detector to work across scales is
                easy&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_mf92uhiyqhty-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">We define a Gaussian scale space with a fixed set of scales and
                compute the corner response function at every pixel of each scale and keep only those with a response
                above a certain threshold.</span></li>
    </ul>
    <h2 class="c19" id="h.qh88fr9bfd5j"><span>Blob Detection </span><span class="c61 c56 c21 c104">Finally</span></h2>
    <h3 class="c22" id="h.5cbud18u9rd5"><span class="c26 c21">Laplacian of Gaussian</span></h3>
    <ul class="c10 lst-kix_vjq736cv37fv-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Recall that the LoG is the second derivative of a Gaussian</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_vjq736cv37fv-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Used in the Marr-Hildreth edge detector</span></li>
    </ul>
    <ul class="c10 lst-kix_vjq736cv37fv-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Zero crossing of LoG convolution</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 358.00px; height: 380.00px;"><img
                alt="" src="assets/computer-vision/image116.png"
                style="width: 365.00px; height: 380.00px; margin-left: -7.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_ghwj7932k3m8-0 start">
        <li class="c7 li-bullet-0"><span class="c1">By finding local minima or maxima, you get a blob detector!</span>
        </li>
    </ul>
    <h3 class="c22" id="h.kdpbqcwpepu9"><span class="c26 c21">Scale space LoG</span></h3>
    <ul class="c10 lst-kix_gcasr1n9xg8g-0 start">
        <li class="c7 li-bullet-0"><span>Normalised scale space LoG defined as:</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 366.00px; height: 47.00px;"><img
                    alt="" src="assets/computer-vision/image238.png"
                    style="width: 366.00px; height: 47.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span>By finding extrema of this function in scale space, you can find </span><span
                class="c6">blobs</span><span class="c1">&nbsp;at their representative scale (~&radic;2t )</span></li>
    </ul>
    <ul class="c10 lst-kix_gcasr1n9xg8g-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Just need to look at the neighbouring pixels!</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 348.00px; height: 287.00px;"><img
                alt="" src="assets/computer-vision/image320.png"
                style="width: 348.00px; height: 287.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c29 c5">Very useful property: </span><span class="c29 c6">if a blob is detected at
            (x</span><span class="c29 c42 c6">0</span><span class="c29 c6">, y</span><span class="c29 c42 c6">0
        </span><span class="c29 c6">; t</span><span class="c29 c42 c6">0</span><span class="c29 c6">) in an image, then
            under a scaling of that image by a factor s, the same blob would be detected at (sx</span><span
            class="c29 c42 c6">0</span><span class="c29 c6">, sy</span><span class="c29 c42 c6">0 </span><span
            class="c29 c6">; s</span><span class="c29 c6 c66">2</span><span class="c29 c6">t</span><span
            class="c29 c42 c6">0</span><span class="c6 c21 c24">) in the scaled image.</span></p>
    <h3 class="c22" id="h.jy4a9e7f5j5n"><span class="c26 c21">Scale space DoG</span></h3>
    <ul class="c10 lst-kix_obukyr11xpb8-0 start">
        <li class="c7 li-bullet-0"><span class="c1">In practice it&rsquo;s computationally expensive to build a LoG
                scale space.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">But, the following approximation can be made:</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 533.50px; height: 56.72px;"><img
                alt="" src="assets/computer-vision/image264.png"
                style="width: 533.50px; height: 56.72px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_764oj9gxoesf-0 start">
        <li class="c7 li-bullet-0"><span class="c1">This is called a Difference-of-Gaussians (DoG)</span></li>
    </ul>
    <ul class="c10 lst-kix_764oj9gxoesf-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Implies that the LoG scale space can be built from subtracting
                adjacent scales of a Gaussian scale space</span></li>
    </ul>
    <h3 class="c22" id="h.rhv7ytpf40bl"><span class="c26 c21">DoG Pyramid</span></h3>
    <ul class="c10 lst-kix_m7aeh9hv4k2h-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Of course, for efficiency you can also build a DoG pyramid</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_m7aeh9hv4k2h-1 start">
        <li class="c9 c16 li-bullet-0"><span>An </span><span class="c6">oversampled</span><span class="c1">&nbsp;pyramid
                as there are multiple images between a doubling of scale.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Images between a doubling of scale are an </span><span
                class="c6">octave</span><span>.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 444.00px;"><img
                alt="" src="assets/computer-vision/image301.png"
                style="width: 602.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h1 class="c46" id="h.94rmmib8ayrb"><span class="c31 c21">Lecture 7: Local features and matching</span></h1>
    <h2 class="c19" id="h.kv93s9lqardj"><span class="c23 c21">Local features and matching basics</span></h2>
    <h3 class="c22" id="h.a94ltbrr545s"><span class="c26 c21">Local Features</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 280.00px;"><img
                alt="" src="assets/computer-vision/image342.png"
                style="width: 602.00px; height: 280.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">Multiple features are extracted; one per local interest point</span></p>
    <h3 class="c22" id="h.uo3mtcmihwam"><span class="c26 c21">Why extract local features?</span></h3>
    <ul class="c10 lst-kix_65h60nyt50u8-0 start">
        <li class="c7 li-bullet-0"><span>Feature points are used for:</span></li>
    </ul>
    <ul class="c10 lst-kix_65h60nyt50u8-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c15 c5">Image alignment</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Camera pose estimate &amp; Camera calibration</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">3D reconstruction</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Motion tracking</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c15 c5">Object recognition</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Indexing and database retrieval</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Robot navigation</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">&hellip;</span></li>
    </ul>
    <h3 class="c22" id="h.o8qtj511mxa5"><span class="c48 c29 c21">Example: Building a panorama</span></h3>
    <ul class="c10 lst-kix_ltb7hs5ye4rw-0 start">
        <li class="c7 li-bullet-0"><span class="c29">You need to </span><span class="c29 c5">match </span><span
                class="c29">and </span><span class="c29 c5">align </span><span class="c2">the images</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Detect feature points in both images</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Find corresponding pairs</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Use the pairs to align the images</span></li>
    </ul>
    <h4 class="c17" id="h.vzbl4jemkzdb"><span class="c72 c29 c21">Problem 1:</span></h4>
    <ul class="c10 lst-kix_dbn9bqafonht-0 start">
        <li class="c7 li-bullet-0"><span class="c29">Detect the same points </span><span class="c29 c6">independently
            </span><span class="c2">in both images</span></li>
    </ul>
    <ul class="c10 lst-kix_2p156f52vui3-0 start">
        <li class="c7 li-bullet-0"><span class="c29">We need a </span><span class="c29 c5">repeatable</span><span
                class="c2">&nbsp;detector</span></li>
    </ul>
    <h4 class="c17" id="h.v5tbtuywcbar"><span class="c72 c29 c21">Problem 2:</span></h4>
    <ul class="c10 lst-kix_dtdablx195ri-0 start">
        <li class="c7 li-bullet-0"><span class="c2">For each point correctly recognise the corresponding one</span></li>
        <li class="c7 li-bullet-0"><span class="c29">We need an </span><span class="c29 c5">invariant, robust
            </span><span class="c29">and </span><span class="c5 c29">distinctive</span><span
                class="c2">&nbsp;descriptor</span></li>
    </ul>
    <h2 class="c19" id="h.667ot0q29brs"><span class="c21 c23">Two distinct types of matching problem</span></h2>
    <ul class="c10 lst-kix_1klcp9f8wlli-0 start">
        <li class="c7 li-bullet-0"><span class="c1">In stereo vision (for 3D reconstruction) there are two important
                concepts related to matching:</span></li>
    </ul>
    <ul class="c10 lst-kix_1klcp9f8wlli-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Narrow-baseline stereo</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Wide-baseline stereo</span></li>
    </ul>
    <h3 class="c22" id="h.z5cfwxbd2q3g"><span class="c26 c21">Narrow-baseline stereo</span></h3>
    <ul class="c10 lst-kix_vuetbk2ong23-0 start">
        <li class="c7 li-bullet-0"><span class="c1">This is where the two images are very similar - the local features
                have only moved by a few pixels.</span></li>
    </ul>
    <ul class="c10 lst-kix_vuetbk2ong23-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Typically the images are from similar points in time</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 281.33px;"><img
                alt="" src="assets/computer-vision/image243.png"
                style="width: 602.00px; height: 281.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c8">(Notice how the red-circled background object only appears in the second image; so
            these two images have a slight difference to them)</span></p>
    <h3 class="c22" id="h.c217tv97nlt2"><span class="c26 c21">Wide-baseline stereo</span></h3>
    <ul class="c10 lst-kix_67pufvf2vl5p-0 start">
        <li class="c7 li-bullet-0"><span>This is where the difference in views is much bigger.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 281.33px;"><img
                alt="" src="assets/computer-vision/image176.png"
                style="width: 602.00px; height: 281.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c81">(I don&rsquo;t think I need to circle the whole image lol)</span></p>
    <h3 class="c22" id="h.rl1wzlffpqks"><span class="c48 c29 c21">Two distinct types of matching problem</span></h3>
    <ul class="c10 lst-kix_7tjr16koiw1x-0 start">
        <li class="c7 li-bullet-0"><span class="c2">These concepts extend to general matching: </span></li>
    </ul>
    <ul class="c10 lst-kix_7tjr16koiw1x-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">The techniques for narrow-baseline stereo are applicable to
                tracking where the object doesn&rsquo;t move too much between frames</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">The techniques for wide-baseline stereo are applicable to
                generic matching tasks (object recognition, panoramas, etc.).</span></li>
    </ul>
    <h2 class="c19" id="h.knnlmmm0f1eo"><span class="c23 c21">Robust local description</span></h2>
    <h3 class="c22" id="h.2l0pv3el8ip"><span class="c26 c21">Descriptor Requirements</span></h3>
    <ul class="c10 lst-kix_c364lnjdyby6-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Dependent on task:</span></li>
    </ul>
    <ul class="c10 lst-kix_c364lnjdyby6-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Narrow baseline:</span></li>
    </ul>
    <ul class="c10 lst-kix_c364lnjdyby6-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Robustness to rotation and lighting is not so important.</span>
        </li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Descriptiveness can be reduced as the search is over a smaller
                area.</span></li>
    </ul>
    <ul class="c10 lst-kix_c364lnjdyby6-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Wide baseline</span></li>
    </ul>
    <ul class="c10 lst-kix_c364lnjdyby6-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Need to be robust to intensity change, invariant to
                rotation.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Need to be highly descriptive to avoid mismatches (but not so
                distinctive that you can&rsquo;t find any matches!)</span></li>
        <li class="c9 c12 li-bullet-0"><span>Robust to </span><span class="c6">small</span><span
                class="c1">&nbsp;localisation errors of the interest point</span></li>
    </ul>
    <ul class="c10 lst-kix_c364lnjdyby6-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c1">The descriptor should not change too much if we move it by a few
                pixels, but to change more rapidly once we move further away.</span></li>
    </ul>
    <ul class="c10 lst-kix_c364lnjdyby6-8 start">
        <li class="c9 c62 c99 li-bullet-0"><span class="c36 c56 c21">Lol</span></li>
    </ul>
    <h2 class="c19" id="h.ffrg7zp5sqbc"><span class="c23 c21">Matching by correlation (template matching)</span></h2>
    <h3 class="c22" id="h.54go8u4x2ip6"><span class="c26 c21">(Narrow baseline) template matching</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 214.67px;"><img
                alt="" src="assets/computer-vision/image197.png"
                style="width: 602.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_vi0w7nbn73s0-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Interest points in two images with a slight change in
                position</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 204.00px;"><img
                alt="" src="assets/computer-vision/image218.png"
                style="width: 602.00px; height: 204.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_ngcnafdpwejg-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Local search windows, based on the interest point in the first
                image</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 599.00px; height: 276.00px;"><img
                alt="" src="assets/computer-vision/image162.png"
                style="width: 599.00px; height: 276.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_fh6cjj2llov3-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The template can then be matched against target interest points in
                the second image</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h3 class="c22" id="h.kjybdojf3feh"><span class="c26 c21">Problems with wider baselines</span></h3>
    <ul class="c10 lst-kix_150lym566w8q-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Not robust to rotation</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Sensitive to localisation of interest point</span></li>
    </ul>
    <ul class="c10 lst-kix_150lym566w8q-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">(although not such a problem with a small search window)</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_150lym566w8q-0">
        <li class="c7 li-bullet-0"><span class="c1">With wider baselines you can&rsquo;t assume a search area</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_150lym566w8q-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Need to consider all the interest points in the second
                image</span></li>
    </ul>
    <ul class="c10 lst-kix_150lym566w8q-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">More likely to mismatch :(</span></li>
    </ul>
    <h2 class="c19" id="h.h3k19glbgll"><span class="c23 c21">Local Intensity Histograms</span></h2>
    <h3 class="c22" id="h.u6hohw8t1lca"><span class="c26 c21">Use local histograms instead of pixel patches</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 589.00px; height: 284.00px;"><img
                alt="" src="assets/computer-vision/image284.png"
                style="width: 589.00px; height: 284.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_cwehf2hqnxia-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Describe the region around each interest point with a pixel
                histogram</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Match each interest point in the first image to the most similar
                point in the second image (i.e. in terms of Euclidean distance [or other measure] between the
                histograms)</span></li>
    </ul>
    <h3 class="c22" id="h.bcuajgzcm5u0"><span class="c26 c21">Local histograms</span></h3>
    <ul class="c10 lst-kix_jiji0hxfp7o7-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Problems:</span></li>
    </ul>
    <ul class="c10 lst-kix_jiji0hxfp7o7-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Not necessarily very distinctive</span></li>
    </ul>
    <ul class="c10 lst-kix_jiji0hxfp7o7-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Many interest points likely to have similar distribution of
                grey-values</span></li>
    </ul>
    <ul class="c10 lst-kix_jiji0hxfp7o7-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Not rotation invariant if the sampling window is square or
                rectangular</span></li>
    </ul>
    <ul class="c10 lst-kix_jiji0hxfp7o7-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Can be overcome using a circular window</span></li>
    </ul>
    <ul class="c10 lst-kix_jiji0hxfp7o7-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Not invariant to illumination changes</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Sensitive to interest point localisation</span></li>
    </ul>
    <h3 class="c22" id="h.9qw6wvot1pj3"><span class="c26 c21">Overcoming localisation sensitivity</span></h3>
    <ul class="c10 lst-kix_xsb21psmfm8j-0 start">
        <li class="c7 li-bullet-0"><span>Want to allow the window around the</span><span>&nbsp;interest
                point</span><span class="c1">&nbsp;to move a few pixels in any direction without changing the
                descriptor</span></li>
    </ul>
    <ul class="c10 lst-kix_xsb21psmfm8j-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Apply a weighting so that pixels near the edge of the sampling
                patch have less of an effect, and those near the interest point have a greater effect</span></li>
    </ul>
    <ul class="c10 lst-kix_xsb21psmfm8j-2 start">
        <li class="c9 c12 li-bullet-0"><span>Common to use </span><span class="c5">Gaussian weighting</span><span
                class="c1">&nbsp;centred on the interest point for this.</span></li>
    </ul>
    <h3 class="c22" id="h.8j0g0w9614gy"><span class="c26 c21">Overcoming lack of illumination invariance</span></h3>
    <ul class="c10 lst-kix_51cyvf4g3bfp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Illumination invariance potentially achievable by normalising or
                equalising the pixel patches before constructing the histogram</span></li>
        <li class="c7 li-bullet-0"><span>...but there is another alternative!.....</span><span
                class="c70">.....</span><span class="c68">.......</span><span>&nbsp;</span><span class="c81">I&rsquo;m
                not going to tell you&hellip;&hellip;. </span><span class="c36 c21 c56">Joking&hellip;&hellip;.</span>
        </li>
    </ul>
    <h2 class="c19" id="h.t9mzxc5epxg8"><span class="c23 c21">Local Gradient Histograms</span></h2>
    <h3 class="c22" id="h.2mogkv9ngvm2"><span>Gradient Magnitudes and Directions</span></h3>
    <ul class="c10 lst-kix_blnm5sohj395-0 start">
        <li class="c7 li-bullet-0"><span class="c1">From the partial derivatives of an image (e.g. from applying
                convolution with Sobel), it is easy to compute the gradient orientations / directions and
                magnitudes</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 534.50px; height: 103.88px;"><img
                alt="" src="assets/computer-vision/image350.png"
                style="width: 534.50px; height: 103.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.xdmc0mhafssu"><span class="c26 c21">Gradient Histograms</span></h3>
    <ul class="c10 lst-kix_2uitznaqxijk-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Instead of building histograms of the raw pixel values we could
                instead build histograms that encode the gradient magnitude and direction for each pixel in the sampling
                patch.</span></li>
    </ul>
    <ul class="c10 lst-kix_2uitznaqxijk-1 start">
        <li class="c9 c16 li-bullet-0"><span>Gradient magnitudes (and directions) are </span><span class="c5">invariant
                to brightness</span><span class="c1">&nbsp;change!</span></li>
        <li class="c9 c16 li-bullet-0"><span>The gradient magnitude and direction histogram is also </span><span
                class="c5">more distinctive.</span></li>
    </ul>
    <h3 class="c22" id="h.z7ppojyidx8v"><span class="c26 c21">Building gradient histograms</span></h3>
    <ul class="c10 lst-kix_4li8gdl80cyd-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Quantise the directions (0&deg;-360&deg;) into a number of
                bins</span></li>
    </ul>
    <ul class="c10 lst-kix_4li8gdl80cyd-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Usually around 8 bins</span></li>
    </ul>
    <ul class="c10 lst-kix_4li8gdl80cyd-0">
        <li class="c7 li-bullet-0"><span class="c1">For each pixel in the sampling patch, accumulate the gradient
                magnitude of that pixel in the respective orientation bin</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 335.00px; height: 410.00px;"><img
                alt="" src="assets/computer-vision/image88.png"
                style="width: 335.00px; height: 410.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.f14skbp3f7gx"><span class="c26 c21">Rotation Invariance</span></h3>
    <ul class="c10 lst-kix_w2g5pwhis43y-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Gradient histograms are not naturally rotation invariant</span></li>
    </ul>
    <ul class="c10 lst-kix_w2g5pwhis43y-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">But, can be made invariant by finding the dominant orientation
                and cyclically shifting the histogram so the dominant orientation is in the first bin.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 142.67px;"><img
                alt="" src="assets/computer-vision/image198.png"
                style="width: 602.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.yeanesignxvv"><span class="c23 c21">The SIFT feature</span></h2>
    <h3 class="c22" id="h.115gzxwf7ocl"><span class="c26 c21">Adding spatial awareness</span></h3>
    <ul class="c10 lst-kix_dgf5rphqyhzz-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The SIFT (Scale Invariant Feature Transformer) feature is widely
                used</span></li>
    </ul>
    <ul class="c10 lst-kix_dgf5rphqyhzz-1 start">
        <li class="c9 c16 li-bullet-0"><span>Builds on the idea of a local gradient histogram by incorporating
            </span><span class="c6">spatial binning</span><span class="c1">, which in essence creates multiple gradient
                histograms about the interest point and appends them all together into a longer feature.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Standard SIFT geometry appends a spatial 4x4 grid of histograms
                with 8 orientations</span></li>
    </ul>
    <ul class="c10 lst-kix_dgf5rphqyhzz-2 start">
        <li class="c9 c12 li-bullet-0"><span>Leading to a 128-dimensional feature which is highly </span><span
                class="c5">discriminative </span><span>and </span><span class="c5">robust!</span></li>
    </ul>
    <h3 class="c22" id="h.n5lhgh3yxan"><span>SIFT Construction: sampling</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 313.33px;"><img
                alt="" src="assets/computer-vision/image127.png"
                style="width: 602.00px; height: 313.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.lloepz129yci"><span class="c26 c21">SIFT Construction: weighting</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 309.33px;"><img
                alt="" src="assets/computer-vision/image171.png"
                style="width: 602.00px; height: 309.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.r99fc4uiwwqc"><span class="c26 c21">SIFT Construction: binning</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 348.00px;"><img
                alt="" src="assets/computer-vision/image289.png"
                style="width: 602.00px; height: 348.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.4s9gpi5a0k9a"><span class="c23 c21">Matching SIFT features</span></h2>
    <h3 class="c22" id="h.hpkjqhtinuoc"><span class="c26 c21">Euclidean Matching</span></h3>
    <ul class="c10 lst-kix_7za10yff5w55-0 start">
        <li class="c7 li-bullet-0"><span class="c1">SImplest way to match SIFT features is to take each feature in turn
                from the first image and find the most similar in the second image</span></li>
    </ul>
    <ul class="c10 lst-kix_7za10yff5w55-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Threshold can be used to reject poor matches</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Unfortunately, doesn&#39;t work that well and results in lots of
                mismatches.</span></li>
    </ul>
    <h3 class="c22" id="h.nys8rasilcyk"><span class="c26 c21">Improving matching performance</span></h3>
    <ul class="c10 lst-kix_q80dsmflrh7v-0 start">
        <li class="c7 li-bullet-0"><span class="c1">A better solution is to take each feature from the first image, and
                find the two closest features in the second image.</span></li>
    </ul>
    <ul class="c10 lst-kix_q80dsmflrh7v-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Only form a match if the ratio of distances between the closest
                and second closest matches is less than a threshold.</span></li>
    </ul>
    <ul class="c10 lst-kix_q80dsmflrh7v-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Typically set at 0.8, meaning that the distance to the closest
                feature must be at least 80% of the second closest.</span></li>
    </ul>
    <ul class="c10 lst-kix_q80dsmflrh7v-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">This leads to a much more robust matching strategy.</span></li>
    </ul>
    <h1 class="c46" id="h.nmuw6dn8i020"><span class="c31 c21">Lecture 8: Consistent matching</span></h1>
    <h2 class="c19" id="h.v61p14xdbuf9"><span class="c23 c21">Feature distinctiveness</span></h2>
    <ul class="c10 lst-kix_1i2korzjem0-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Even though the most advanced local features can be prone to being
                mismatched.</span></li>
    </ul>
    <ul class="c10 lst-kix_1i2korzjem0-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">There is always a tradeoff in feature distinctiveness.</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c1">If it&rsquo;s too distinctive it will not match subtle
                variations due to noise of imaging conditions.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">If it&rsquo;s not distinctive enough it will match
                everything.</span></li>
    </ul>
    <h2 class="c19" id="h.4dcuukn8u0ji"><span class="c11">Constrained matching</span></h2>
    <ul class="c10 lst-kix_xz3964500n-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Assume we are given a number of correspondences between the interest
                points in a pair of images</span></li>
    </ul>
    <ul class="c10 lst-kix_xz3964500n-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c29">Is it possible to estimate which of those correspondences
                &nbsp;are </span><span class="c29 c5">inliers </span><span class="c29">(correct) or </span><span
                class="c29 c5">outliers</span><span class="c2">&nbsp;(incorrect/mismatches)?</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c29">What </span><span class="c29 c5">assumptions</span><span
                class="c2">&nbsp;do we have to make?</span></li>
    </ul>
    <ul class="c10 lst-kix_xz3964500n-0">
        <li class="c7 li-bullet-0"><span class="c2">By assuming a geometric mapping between the two scenes, can we
                recover that mapping and eliminate the mismatches?</span></li>
    </ul>
    <h2 class="c19" id="h.p47y378x78t8"><span class="c23 c21">Geometric Mappings</span></h2>
    <h3 class="c22" id="h.szoindpt596n"><span class="c26 c21">What are geometric transforms?</span></h3>
    <ul class="c10 lst-kix_ilalmisp71ms-0 start">
        <li class="c7 li-bullet-0"><span class="c1">In general, a geometric mapping can be thought of as a transform
                function that maps the x, y coordinates of points in one image to another.</span></li>
    </ul>
    <p class="c9"><span>Go have a look at some on Wikipedia here: </span><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Geometric_transformation&amp;sa=D&amp;source=editors&amp;ust=1623775880499000&amp;usg=AOvVaw3yioc2MVN3it61qoHjkqMy">https://en.wikipedia.org/wiki/Geometric_transformation</a></span>
    </p>
    <h3 class="c22" id="h.3y9nu1gliosj"><span class="c26 c21">Point Transforms</span></h3>
    <p class="c9"><span class="c6">We&rsquo;re interested in transforms that take the following form: </span><span
            class="c18 c21">x&rsquo;=Tx</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 242.67px;"><img
                alt="" src="assets/computer-vision/image84.png"
                style="width: 602.00px; height: 242.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.2t35nvh8ktf8"><span class="c26 c21">The Affine Transform</span></h3>
    <p class="c9"><span class="c6">The affine transform is defined as</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 357.00px; height: 304.00px;"><img
                alt="" src="assets/computer-vision/image248.png"
                style="width: 357.00px; height: 304.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c6">It&rsquo;s more convenient to write this as a single transform matrix by adding an
            extra dimension to each vector:</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 279.00px; height: 128.00px;"><img
                alt="" src="assets/computer-vision/image187.png"
                style="width: 279.00px; height: 128.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.tcu2nyev1sa0"><span class="c26 c21">Translation</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 300.00px;"><img
                alt="" src="assets/computer-vision/image308.png"
                style="width: 602.00px; height: 300.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.i86slkyzyvz2"><span class="c26 c21">Translation and Rotation</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 405.33px;"><img
                alt="" src="assets/computer-vision/image272.png"
                style="width: 602.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.yqsn0mmodxwj"><span class="c26 c21">Scaling</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 562.00px; height: 396.00px;"><img
                alt="" src="assets/computer-vision/image299.png"
                style="width: 562.00px; height: 396.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.la982dbsyv5t"><span class="c26 c21">Aspect Ratio</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 533.00px; height: 418.00px;"><img
                alt="" src="assets/computer-vision/image336.png"
                style="width: 533.00px; height: 418.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.x85a8deg6f5i"><span class="c26 c21">Shear</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 479.00px; height: 406.00px;"><img
                alt="" src="assets/computer-vision/image251.png"
                style="width: 479.00px; height: 406.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.q6zvatlwypym"><span class="c23 c21">Degrees of Freedom</span></h2>
    <h3 class="c22" id="h.wpl9ssdfi9tt"><span class="c26 c21">Affine Transform</span></h3>
    <h3 class="c22" id="h.j3d7dsk2ym0a"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 284.00px;"><img
                alt="" src="assets/computer-vision/image262.png"
                style="width: 602.00px; height: 284.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></h3>
    <p class="c9"><span class="c1">6 DoF: translation + rotation + scale + aspect ratio + shear</span></p>
    <h3 class="c22" id="h.sdeg1gdhr5bt"><span class="c26 c21">Similarity Transform</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 333.33px;"><img
                alt="" src="assets/computer-vision/image119.png"
                style="width: 602.00px; height: 333.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c1">4 DoF: translation+rotation+scale</span></p>
    <h2 class="c19" id="h.h5lnl02h5m20"><span class="c23 c21">More degrees of freedom</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 443.00px; height: 186.00px;"><img
                alt="" src="assets/computer-vision/image117.png"
                style="width: 443.00px; height: 186.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span>Normalise by </span><span class="c6">w</span><span class="c1">&nbsp;so that the transformed
            vector is [&bull;,&bull;,1]</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 222.00px; height: 149.00px;"><img
                alt="" src="assets/computer-vision/image180.png"
                style="width: 222.00px; height: 149.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.gybzp8rgcdx1"><span class="c23 c21">Homogeneous coordinates</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 160.00px; height: 278.00px;"><img
                alt="" src="assets/computer-vision/image241.png"
                style="width: 160.00px; height: 278.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.gzlo5cezv4by"><span>The Planar Homography (Projective Transformation) </span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 354.67px;"><img
                alt="" src="assets/computer-vision/image131.png"
                style="width: 602.00px; height: 354.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.6h01l96qh3w3"><span class="c23 c21">Recovering a geometric mapping</span></h2>
    <h3 class="c22" id="h.lobh3qgx7jej"><span class="c26 c21">Simultaneous equations</span></h3>
    <ul class="c10 lst-kix_8bsljxmb7vyi-0 start">
        <li class="c7 li-bullet-0"><span class="c1">It is possible to estimate a transform matrix from a set of point
                matches by solving a set of simultaneous equations</span></li>
    </ul>
    <ul class="c10 lst-kix_8bsljxmb7vyi-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Need at least 4 point matches to solve a Homography or 3 to
                solve an affine transform</span></li>
    </ul>
    <ul class="c10 lst-kix_8bsljxmb7vyi-0">
        <li class="c7 li-bullet-0"><span class="c1">The actual solution technique isn&rsquo;t important&hellip;</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_8bsljxmb7vyi-1 start">
        <li class="c9 c16 li-bullet-0"><span>It is important to note that in the presence of noise, and with potentially
                more matches than required, that we have to solve an </span><span class="c6">overdetermined
                system</span></li>
        <li class="c9 c16 li-bullet-0"><span>We need to seek the minimum error or </span><span
                class="c5">least-squares</span><span class="c1">&nbsp;solution</span></li>
    </ul>
    <h2 class="c19" id="h.qpgxw9ebmfwz"><span class="c23 c21">Least-squares</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 442.67px;"><img
                alt="" src="assets/computer-vision/image63.png"
                style="width: 602.00px; height: 442.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 318.67px;"><img
                alt="" src="assets/computer-vision/image139.png"
                style="width: 602.00px; height: 318.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.dqzefd8s3rxm"><span>Robust Estimation</span></h2>
    <h3 class="c22" id="h.fqmx1z6ovw62"><span class="c48 c29 c21">Problem: Noisy data</span></h3>
    <ul class="c10 lst-kix_cseysjdgeas2-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Need a way to deal with estimating a model (i.e. a transform matrix)
                in the presence of high amounts of noise (i.e. mis-matches)</span></li>
    </ul>
    <ul class="c10 lst-kix_cseysjdgeas2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Least-squares will be highly suboptimal, and probably find a
                very bad solution.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Ideally, we want to identify the correct data (the inliers) and
                the bad data (the outliers)</span></li>
    </ul>
    <ul class="c10 lst-kix_cseysjdgeas2-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">Then estimate the model using only the good data.</span></li>
    </ul>
    <h3 class="c22" id="h.ltogbcgd5mwc"><span class="c29 c21 c48">Robust estimation techniques</span></h3>
    <ul class="c10 lst-kix_95gq6snzoodp-0 start">
        <li class="c7 li-bullet-0"><span class="c29">The problem of learning a model in the presence of inliers and
                outliers comes under an area of mathematics called </span><span class="c29 c5">robust
                estimation</span><span class="c29">&nbsp;or </span><span class="c36 c29 c5">robust model fitting</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_95gq6snzoodp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">There are a number of different possible techniques</span></li>
    </ul>
    <h3 class="c22" id="h.7b3n2rimkra"><span class="c26 c21">RANSAC: RANdom SAmple Consensus</span></h3>
    <p class="c9"><span>This is an iterative method to estimate parameters of a mathematical model for a set of observed
            data that contains outliers. </span></p>
    <p class="c9"><span class="c5 c18">Assume:</span></p>
    <p class="c9"><span class="c18 c21">M data items required to estimate model T</span></p>
    <p class="c9"><span class="c18 c21">N data items in total</span></p>
    <p class="c3"><span class="c18 c21"></span></p>
    <p class="c9"><span class="c18 c5">Algorithm:</span></p>
    <ol class="c10 lst-kix_rt9x161657du-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c18 c21">Select M data items at random</span></li>
        <li class="c7 li-bullet-0"><span class="c18 c21">Estimate model T</span></li>
        <li class="c7 li-bullet-0"><span class="c18 c21">Find how many of the N data items fit T within tolerance tol,
                call this K (i.e. compute how many times the absolute residual is less than tol). The points that have
                an absolute residual less than tol are the inliers; the other points are the outliers.</span></li>
        <li class="c7 li-bullet-0"><span class="c18 c21">If K is large enough, either accept T, or compute the
                least-squares estimate using all inliers, and exit with success.</span></li>
        <li class="c7 li-bullet-0"><span class="c18 c21">Repeat steps 1..4 nIterations times</span></li>
        <li class="c7 li-bullet-0"><span class="c18 c21">Fail - no good T fit of data</span></li>
    </ol>
    <h2 class="c19" id="h.tszxj8k70th5"><span class="c11">Further applications of robust local matching</span></h2>
    <h3 class="c22" id="h.rhjj7c3myh5c"><span class="c48 c29 c21">Object recognition &amp; AR</span></h3>
    <ul class="c10 lst-kix_kp0s1j3jzesv-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Object recognition</span></li>
    </ul>
    <ul class="c10 lst-kix_kp0s1j3jzesv-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Image of object is matched against scene, and recognised if
                there is a consistent match</span></li>
    </ul>
    <ul class="c10 lst-kix_kp0s1j3jzesv-0">
        <li class="c7 li-bullet-0"><span class="c2">Augmented reality</span></li>
    </ul>
    <ul class="c10 lst-kix_kp0s1j3jzesv-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Data can be added to a scene on the basis of a match</span></li>
    </ul>
    <h3 class="c22" id="h.7w7wc7i6ts61"><span class="c48 c29 c21">3D reconstruction</span></h3>
    <ul class="c10 lst-kix_vkn4ab9epctf-0 start">
        <li class="c7 li-bullet-0"><span class="c2">It&rsquo;s possible to estimate depth, and ultimately build a
                complete 3d scene from sets of point correspondences formed from matching local features</span></li>
    </ul>
    <h2 class="c19" id="h.7tgbqj1tuhbw"><span class="c23 c21">Problems with direct local feature matching</span></h2>
    <h3 class="c22" id="h.gegp1v49xorn"><span class="c26 c21">Local feature matching is slow!</span></h3>
    <ul class="c10 lst-kix_17jvbdo1puy9-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Typical image (800x600) might have ~2000 DoG Interest points/SIFT
                descriptors</span></li>
    </ul>
    <ul class="c10 lst-kix_17jvbdo1puy9-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Each SIFT descriptor is 128 dimensions</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Now assume you want to match a query image against a database of
                image&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_17jvbdo1puy9-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">The distance between every query feature and every other feature
                needs to be calculated</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Can this be optimised somehow?</span></li>
    </ul>
    <h3 class="c22" id="h.cqy63c4g5pf4"><span class="c26 c21">Efficient Nearest Neighbour Search</span></h3>
    <ul class="c10 lst-kix_wo1we0zdr7x8-0 start">
        <li class="c7 li-bullet-0"><span>How can we </span><span class="c5">quickly</span><span class="c1">&nbsp;find
                the nearest neighbour to a query point in a high dimensional space?</span></li>
    </ul>
    <ul class="c10 lst-kix_wo1we0zdr7x8-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Index the points in some kind of tree structure?</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Hash the points?</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Quantise the space?</span></li>
    </ul>
    <h3 class="c22" id="h.br4w9beok9x8"><span class="c26 c21">K-D Trees</span></h3>
    <ul class="c10 lst-kix_y5rhvcs15keu-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Binary tree structure that partitions the space along axis-aligned
                hyperplanes</span></li>
    </ul>
    <ul class="c10 lst-kix_y5rhvcs15keu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Typically take each dimension in turn and splits on the median
                of the points in the enclosing partition.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Stop after a certain depth, or when the number of points in a
                leaf is less than a threshold</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 245.33px;"><img
                alt="" src="assets/computer-vision/image352.png"
                style="width: 602.00px; height: 245.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 234.67px;"><img
                alt="" src="assets/computer-vision/image100.png"
                style="width: 602.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_dr6irwp3f05i-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Search by walking down the tree until a leaf is hit, and then
                brute-force search to find the best in the leaf.</span></li>
    </ul>
    <ul class="c10 lst-kix_dr6irwp3f05i-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">This is not guaranteed to be the best though&hellip;</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">To have to walk back up the tree and see if there are any better
                matches, and only stop once the root is reached.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">(note you don&rsquo;t have to check a subtree if it&rsquo;s
                clear that all points in that subtree are further than the current best.)</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 274.67px;"><img
                alt="" src="assets/computer-vision/image327.png"
                style="width: 602.00px; height: 274.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 233.33px;"><img
                alt="" src="assets/computer-vision/image271.png"
                style="width: 602.00px; height: 233.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 238.67px;"><img
                alt="" src="assets/computer-vision/image232.png"
                style="width: 602.00px; height: 238.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 238.67px;"><img
                alt="" src="assets/computer-vision/image286.png"
                style="width: 602.00px; height: 238.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 245.33px;"><img
                alt="" src="assets/computer-vision/image194.png"
                style="width: 602.00px; height: 245.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 276.00px;"><img
                alt="" src="assets/computer-vision/image256.png"
                style="width: 602.00px; height: 276.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.p6exul1isbpl"><span class="c26 c21">K-D Tree problems</span></h3>
    <ul class="c10 lst-kix_tfjges6iuha5-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Doesn&rsquo;t scale well to high dimensions</span></li>
    </ul>
    <ul class="c10 lst-kix_tfjges6iuha5-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">You tend to end up needing to search most of the tree</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_tfjges6iuha5-0">
        <li class="c7 li-bullet-0"><span>There are </span><span class="c6">approximate</span><span
                class="c1">&nbsp;versions that won&rsquo;t necessarily return the exact answer that do scale (if you
                don&rsquo;t mind the potential for mismatch)</span></li>
    </ul>
    <h3 class="c22" id="h.2ns91rh6ogtq"><span class="c26 c21">Hashing</span></h3>
    <ul class="c10 lst-kix_1jwc7kbyerzz-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Locality Sensitive Hashing (LSH) creates hash codes for vectors such
                that similar vectors have similar hash codes!</span></li>
    </ul>
    <h3 class="c22" id="h.i91ftrl89i72"><span class="c48 c29 c21">Sketching</span></h3>
    <ul class="c10 lst-kix_ce62w03lv77h-0 start">
        <li class="c7 li-bullet-0"><span class="c2">A technique called sketching concatenates binary hashes into a bit
                string.</span></li>
    </ul>
    <ul class="c10 lst-kix_ce62w03lv77h-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">With the correct LSH function, the Hamming distance between a
                pair of sketches is proportional to the Euclidean distance between the original vectors</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Can easily compress SIFT features to 128 bits</span></li>
    </ul>
    <ul class="c10 lst-kix_ce62w03lv77h-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">Hamming distance computation is cheap</span></li>
    </ul>
    <ul class="c10 lst-kix_ce62w03lv77h-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c29">Lookup tables and bitwise operations</span></li>
    </ul>
    <h1 class="c46" id="h.qm6is335tqam"><span class="c31 c21">Lecture 9: Image search and Bags of Visual Words</span>
    </h1>
    <h2 class="c19" id="h.kj7684lbh0xy"><span class="c23 c21">Text Information Retrieval</span></h2>
    <h3 class="c22" id="h.cszw2vs2nfxt"><span>The </span><span class="c6">bag </span><span class="c26 c21">data
            structure</span></h3>
    <ul class="c10 lst-kix_tgdkyumu6q7d-0 start">
        <li class="c7 li-bullet-0"><span>A bag is an </span><span class="c5">unordered </span><span>data like a
            </span><span class="c6">set</span><span>, but which unlike a set allows elements to be </span><span
                class="c5">inserted multiple times</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_tgdkyumu6q7d-1 start">
        <li class="c9 c16 li-bullet-0"><span>Sometimes called a </span><span class="c6">multiset</span><span>&nbsp;or a
            </span><span class="c6">counted set</span></li>
    </ul>
    <h3 class="c22" id="h.iu4ukqoy6sn9"><span class="c26 c21">Bag of Words</span></h3>
    <ul class="c10 lst-kix_u9myfols934-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Say you have a document with this content:</span></li>
    </ul>
    <ul class="c10 lst-kix_u9myfols934-1 start">
        <li class="c9 c16 li-bullet-0"><span>&ldquo;</span><span class="c35 c21">the quick brown fox jumped over the
                lazy dog</span><span class="c1">&rdquo;</span></li>
    </ul>
    <ul class="c10 lst-kix_u9myfols934-0">
        <li class="c7 li-bullet-0"><span class="c1">A bag of words describing this document would be:</span></li>
    </ul>
    <ul class="c10 lst-kix_u9myfols934-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 221.00px; height: 332.00px;"><img
                    alt="" src="assets/computer-vision/image322.png"
                    style="width: 221.00px; height: 332.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.r7cubjp1kxys"><span class="c23 c21">Text processing (feature extraction)</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 318.67px;"><img
                alt="" src="assets/computer-vision/image259.png"
                style="width: 602.00px; height: 318.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.wp6dpvupt7ju"><span class="c26 c21">The Vector-Space Model</span></h3>
    <ul class="c10 lst-kix_fro22blg1gsg-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Conceptually simple:</span></li>
    </ul>
    <ul class="c10 lst-kix_fro22blg1gsg-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Model each document by a vector</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Model each query by a vector</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Assumption: documents that are &ldquo;close together&rdquo; in
                space are similar in meaning.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Use standard similarity measures to rank each document to a
                query in terms of decreasing similarity</span></li>
    </ul>
    <h3 class="c22" id="h.qk348d10icl9"><span class="c26 c21">Bag of Words Vectors</span></h3>
    <ul class="c10 lst-kix_83bccjo3kria-0 start">
        <li class="c7 li-bullet-0"><span>The lexicon or vocabulary is the </span><span class="c5">set</span><span
                class="c1">&nbsp;of all (processed) words across all documents known to the system.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">We can create vectors for each document with as many dimensions as
                there are words in the lexicon</span></li>
    </ul>
    <ul class="c10 lst-kix_83bccjo3kria-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Each word in the document&rsquo;s bag of words contributes to a
                count to the corresponding element of the vector for that word.</span></li>
    </ul>
    <ul class="c10 lst-kix_83bccjo3kria-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">In essence, each vector is a histogram of the word occurrences
                in the respective document.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Vectors will have a very high number of dimensions, but will be
                very sparse.</span></li>
    </ul>
    <h3 class="c22" id="h.yt2hh2nqw8tt"><span class="c48 c29 c21">The Vector-space Model</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 397.00px;"><img
                alt="" src="assets/computer-vision/image339.png"
                style="width: 602.00px; height: 397.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.z0nxr5bjz7ci"><span class="c48 c29 c21">Searching the VSM</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 376.00px;"><img
                alt="" src="assets/computer-vision/image306.png"
                style="width: 602.00px; height: 376.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.whw51oxsv0ws"><span class="c29">Recap:</span><span class="c26 c21">&nbsp;Cosine
            Similarity</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 249.33px;"><img
                alt="" src="assets/computer-vision/image353.png"
                style="width: 602.00px; height: 249.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 342.67px;"><img
                alt="" src="assets/computer-vision/image82.png"
                style="width: 602.00px; height: 342.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.sh7m1mrqgvyu"><span>Inverted Indexes</span></h3>
    <ul class="c10 lst-kix_myitigiga7yz-0 start">
        <li class="c7 li-bullet-0"><span class="c1">A map of words to lists of postings</span></li>
    </ul><a id="t.b13a7df09ad152da8c19b1e73ebc63cdf19aee13"></a><a id="t.1"></a>
    <table class="c65">
        <tbody>
            <tr class="c51">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Aardvark</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">[doc3:4]</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Astronomy</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">[doc1:2]</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Diet</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">[doc2:9; doc3:8]</span></p>
                </td>
            </tr>
            <tr class="c101">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">...</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14 c87"><span class="c1"></span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Movie</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">[doc2:10]</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Star</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">[doc:13; doc2:4]</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c69" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">Telescope</span></p>
                </td>
                <td class="c52" colspan="1" rowspan="1">
                    <p class="c14"><span class="c1">[doc1:15]</span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_7va0h4z4m5yr-0 start">
        <li class="c7 li-bullet-0"><span>A </span><span class="c5">posting</span><span>&nbsp;is a pair formed by a
            </span><span class="c5">document ID </span><span>and the </span><span class="c5">number of times
            </span><span class="c1">the specific word appeared in that document</span></li>
        <li class="c7 li-bullet-0"><span>So for the first entry: </span><span class="c6">Aardvark </span><span>appeared
            </span><span class="c6">4</span><span>&nbsp;times in </span><span class="c6">document 3</span><span
                class="c1">.</span></li>
    </ul>
    <h3 class="c22" id="h.epwoag43sy7"><span class="c26 c21">Computing the Cosine Similarity</span></h3>
    <ul class="c10 lst-kix_rnonahaj5em7-0 start">
        <li class="c7 li-bullet-0"><span class="c1">For each word in the query, lookup the relevant posting list and
                accumulate similarities for only the documents seen in those postings lists</span></li>
    </ul>
    <ul class="c10 lst-kix_rnonahaj5em7-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Much more efficient than fully comparing vectors&hellip;</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 237.33px;"><img
                alt="" src="assets/computer-vision/image215.png"
                style="width: 602.00px; height: 237.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.kgx6lglo3hg7"><span class="c26 c21">Weighting the vectors</span></h3>
    <ul class="c10 lst-kix_xh45npg3j5wp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">The number of times a word occurs in a document reflects the
                importance of that word in the document.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Intuitions:</span></li>
    </ul>
    <ul class="c10 lst-kix_xh45npg3j5wp-1 start">
        <li class="c9 c16 li-bullet-0"><span>A term that appears in many documents is not important: e.g., </span><span
                class="c43 c6 c21">the, going come,...</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">If a term is frequent in a document and rare across other
                documents, it is probably important in that document.</span></li>
    </ul>
    <h3 class="c22" id="h.gus1kmt2ss5q"><span class="c26 c21">Possible weighting schemes</span></h3>
    <ul class="c10 lst-kix_guhkywcemciw-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Binary weights</span></li>
    </ul>
    <ul class="c10 lst-kix_guhkywcemciw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Only presence (1) or absence (0) of a term recorded in
                vector.</span></li>
    </ul>
    <ul class="c10 lst-kix_guhkywcemciw-0">
        <li class="c7 li-bullet-0"><span class="c1">Raw frequency</span></li>
    </ul>
    <ul class="c10 lst-kix_guhkywcemciw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Frequency of occurrence of term in document included in
                vector.</span></li>
    </ul>
    <ul class="c10 lst-kix_guhkywcemciw-0">
        <li class="c7 li-bullet-0"><span class="c1">TF / IDF</span></li>
    </ul>
    <ul class="c10 lst-kix_guhkywcemciw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Term frequency is the frequency count of a term in a
                document.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Inverse document frequency (idf) provides high values for rare
                words and low values for common words.</span></li>
    </ul>
    <h2 class="c19" id="h.608thq1r83uq"><span class="c23 c21">Vector Quantisation</span></h2>
    <h3 class="c22" id="h.gmvt9otz6d0n"><span class="c26 c21">Learning a Vector Quantiser</span></h3>
    <ul class="c10 lst-kix_m14x9jaz9t5a-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Vector quantisation is a lossy data compression technique.</span>
        </li>
        <li class="c7 li-bullet-0"><span class="c1">Given a set of vectors, a technique like K-Means clustering can be
                used to learn a fixed size set of representative vectors.</span></li>
    </ul>
    <ul class="c10 lst-kix_m14x9jaz9t5a-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">The representatives are the mean vector of each cluster in
                k-means.</span></li>
        <li class="c9 c16 li-bullet-0"><span>The set of representation vectors is called a </span><span
                class="c5">codebook</span></li>
    </ul>
    <h4 class="c17" id="h.wiiev4ur5of1"><span class="c72 c41 c21">Vector Quantisation</span></h4>
    <ul class="c10 lst-kix_lm5r8a1dn2j-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Vector quantisation is achieved by representing a vector by another
                approximate vector, which is drawn from a pool of representative vectors.</span></li>
    </ul>
    <ul class="c10 lst-kix_lm5r8a1dn2j-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Each input vector is assigned to the &ldquo;closest&rdquo;
                vector from the pool.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 270.00px; height: 314.00px;"><img
                alt="" src="assets/computer-vision/image75.png"
                style="width: 270.00px; height: 314.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.h3cjrb9y5hgl"><span class="c23 c21">Visual Words</span></h2>
    <h3 class="c22" id="h.lik4ufp2b31f"><span class="c26 c21">SIFT Visual Words</span></h3>
    <ul class="c10 lst-kix_lef7yidg8ukj-0 start">
        <li class="c7 li-bullet-0"><span class="c1">We can vector quantise SIFT descriptors (or any other local
                feature)</span></li>
    </ul>
    <ul class="c10 lst-kix_lef7yidg8ukj-1 start">
        <li class="c9 c16 li-bullet-0"><span>Each descriptor is replaced by a representative vector known as a
            </span><span class="c5">visual word</span></li>
    </ul>
    <ul class="c10 lst-kix_lef7yidg8ukj-2 start">
        <li class="c9 c12 li-bullet-0"><span>In essence the </span><span class="c6">visual word</span><span
                class="c1">&nbsp;describes a small image patch with a certain pattern of pixels</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">In many ways the process of applying vector quantisation to
                local features is analogous to the process of stemming words.</span></li>
    </ul>
    <ul class="c10 lst-kix_lef7yidg8ukj-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">The codebook is the visual equivalent of a lexicon or
                vocabulary.</span></li>
    </ul>
    <h3 class="c22" id="h.wkq0cik291i6"><span class="c48 c29 c21">Bags of Visual Words</span></h3>
    <ul class="c10 lst-kix_wky9687uby5e-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Once we&rsquo;ve quantised the local features into visual words,
                they can be put into a bag.</span></li>
    </ul>
    <ul class="c10 lst-kix_wky9687uby5e-1 start">
        <li class="c9 c16 li-bullet-0"><span>This is a </span><span class="c15 c5">Bag of Visual Words (BoVW)</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c1">We&rsquo;re basically ignoring where in the image the local
                features came from (including ignoring scale)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c36 c21 c97">So why are we doing all this word stuff for a module about
            vision?....</span></p>
    <h3 class="c22" id="h.33vrpzdqzggk"><span class="c26 c21">Histograms of Bags of Visual Words</span></h3>
    <ul class="c10 lst-kix_w3qwf09motfu-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Like in the case of text, once we have a BoVW and knowledge of the
                complete vocabulary (the codebook) we can build histograms of visual word occurrences!</span></li>
    </ul>
    <ul class="c10 lst-kix_w3qwf09motfu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">This is nice&hellip; it gives us a way of aggregating a variable
                number of local descriptors into a fixed length vector.</span></li>
    </ul>
    <ul class="c10 lst-kix_w3qwf09motfu-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Useful for machine learning</span></li>
        <li class="c9 c12 li-bullet-0"><span>But also allows us to apply techniques for text retrieval to images</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 366.50px; height: 425.68px;"><img
                alt="" src="assets/computer-vision/image312.png"
                style="width: 366.50px; height: 425.68px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.ovbs7g23s6zx"><span class="c11">Visualising Visual Words</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 426.67px;"><img
                alt="" src="assets/computer-vision/image95.png"
                style="width: 602.00px; height: 426.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.keznjdmb2abu"><span class="c23 c21">The effect of codebook size</span></h2>
    <ul class="c10 lst-kix_q53lit0strd-0 start">
        <li class="c7 li-bullet-0"><span>There is one </span><span class="c5">key parameter</span><span>&nbsp;in
                building visual word representations - </span><span class="c5">the size of the vocabulary</span><span
                class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_q53lit0strd-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Too small, and all vectors look the same</span></li>
    </ul>
    <ul class="c10 lst-kix_q53lit0strd-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Not distinctive</span></li>
    </ul>
    <ul class="c10 lst-kix_q53lit0strd-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Too big, and the same visual words might never appear across
                images</span></li>
    </ul>
    <ul class="c10 lst-kix_q53lit0strd-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Too distinctive</span></li>
    </ul>
    <h2 class="c19" id="h.duva7wq7k6dw"><span>Content-based Image Retrieval</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 401.33px;"><img
                alt="" src="assets/computer-vision/image89.png"
                style="width: 602.00px; height: 401.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.n20olp2clwfm"><span class="c26 c21">BoVW Retrieval</span></h3>
    <ul class="c10 lst-kix_pv8pym9xewig-0 start">
        <li class="c7 li-bullet-0"><span class="c1">With the visual word representation, everything used for text
                retrieval can be applied directly to images</span></li>
    </ul>
    <ul class="c10 lst-kix_pv8pym9xewig-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Vector space model</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Cosine similarity</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Weighting schemes</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Inverted index</span></li>
    </ul>
    <h3 class="c22" id="h.pmopc9y2tzfh"><span class="c26 c21">Optimal codebook size</span></h3>
    <ul class="c10 lst-kix_16lsxfflqhiq-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Inverted index only gives a performance gain if the vectors are
                sparse (you don&rsquo;t want to end up explicitly scoring all documents)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Visual words also need to be sufficiently distinctive to minimise
                mismatching</span></li>
    </ul>
    <ul class="c10 lst-kix_16lsxfflqhiq-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Implies a very big codebook</span></li>
    </ul>
    <ul class="c10 lst-kix_16lsxfflqhiq-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Modern research systems often use 1 million or more visual words
                for SIFT vectors</span></li>
    </ul>
    <h3 class="c22" id="h.rs0jr7b7mj19"><span class="c26 c21">Problems with big codebooks</span></h3>
    <ul class="c10 lst-kix_nfjg2elwpghn-0 start">
        <li class="c7 li-bullet-0"><span class="c1">There&rsquo;s a slight problem&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_nfjg2elwpghn-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Need to use k-means to learn 1 million clusters in 128
                dimensions from 10&rsquo;s of millions of features</span></li>
    </ul>
    <ul class="c10 lst-kix_nfjg2elwpghn-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Non-trivial!</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Vector quantisation has the same problems</span></li>
    </ul>
    <ul class="c10 lst-kix_nfjg2elwpghn-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c1">Have to use approximate methods, like approximate k-d
                trees</span></li>
    </ul>
    <h3 class="c22" id="h.6ijc0wdpooeh"><span class="c26 c21">Overall process for building a BoVW retrieval
            system</span></h3>
    <ol class="c10 lst-kix_8fefr88rqbhx-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Collect the corpus of images that are to be indexed and made
                searchable</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Extract local features from each image</span></li>
        <li class="c7 li-bullet-0"><span>Learn a </span><span class="c6">large</span><span class="c1">&nbsp;codebook
                from (a sample of) the features</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Vector quantise the features, and build BoVW representations for
                each image</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Construct an inverted index with the BoVW representations</span>
        </li>
    </ol>
    <h1 class="c46" id="h.mjg0o93plsl8"><span class="c31 c21">Lecture 10: Image classification and
            auto-annotation</span></h1>
    <h2 class="c19" id="h.y1uhj0bmn5jb"><span class="c23 c21">Multilabel classification</span></h2>
    <ul class="c10 lst-kix_syzpo3rx3739-0 start">
        <li class="c7 li-bullet-0"><span class="c36 c75 c21">Oh my gosh, this picture has a cat in it, so it must be
                classified as cat.</span></li>
        <li class="c7 li-bullet-0"><span class="c36 c75 c21">But wait, it has a dog in it as well, so it&rsquo;s
                classified as a dog.</span></li>
        <li class="c7 li-bullet-0"><span class="c36 c75 c21">AAHHHH there is both a cat and a dog in the image
                AAAAA&hellip;.</span></li>
        <li class="c7 li-bullet-0"><span class="c36 c75 c21">Wait&hellip;</span></li>
        <li class="c7 li-bullet-0"><span class="c36 c21 c75">Why can&rsquo;t we just classify it as both?</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 481.00px; height: 385.00px;"><img
                alt="" src="assets/computer-vision/image99.png"
                style="width: 481.00px; height: 385.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_vwna16kahqhv-0 start">
        <li class="c7 li-bullet-0"><span>In the context of images often called </span><span class="c6">Automatic
                Annotation</span></li>
    </ul>
    <h3 class="c22" id="h.r8atlnlaan9q"><span class="c26 c21">Object Detection / Localisation</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 447.00px; height: 259.00px;"><img
                alt="" src="assets/computer-vision/image291.png"
                style="width: 447.00px; height: 259.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.tdi28o987z9o"><span class="c29">Slide summary: Challenges in Computer Vision</span><span
            class="c23 c21">&nbsp;</span></h2>
    <p class="c9"><span>This is a summary of slides s</span><span class="c1">lides 7-16, go look in the slides if
            you&rsquo;re interested</span></p>
    <p class="c9"><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=http://comp3204.ecs.soton.ac.uk/lectures/pdf/L10-classification.pdf&amp;sa=D&amp;source=editors&amp;ust=1623775880540000&amp;usg=AOvVaw29URl-T6EaoC5owl7qhicy">http://comp3204.ecs.soton.ac.uk/lectures/pdf/L10-classification.pdf</a></span>
    </p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_sczm7e23p1br-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Object Recognition in natural scenes</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Scene/Activity Classification</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Automatic Annotation (it&rsquo;s not that good sometimes)</span>
        </li>
        <li class="c7 li-bullet-0"><span>The fundamental problem of computer vision: </span><span class="c15 c5">The
                Semantic Gap</span></li>
        <li class="c7 li-bullet-0"><span class="c1">In an image for computer vision there are:</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Semantics</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Object Labels</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Objects</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Descriptors</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Raw media</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-0">
        <li class="c7 li-bullet-0"><span class="c1">Upside-down cars lol</span></li>
        <li class="c7 li-bullet-0"><span class="c1">History:</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">1999 - SIFT matching</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Very powerful, but computationally demanding</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">2001 - Cascades of Haar-like features</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Very popular for face detection</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">2006 - SURF matching</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Combined ideas from SIFT and the integral images used for
                computing Haar-like features</span></li>
    </ul>
    <ul class="c10 lst-kix_sczm7e23p1br-0">
        <li class="c7 li-bullet-0"><span class="c1">Interest in auto-annotation grew from the late 90s Bags of
                &ldquo;Visual Words&rdquo; were rather important!</span></li>
    </ul>
    <h2 class="c19" id="h.ex37or3w10lx"><span class="c23 c21">Aside: Optimal codebook size</span></h2>
    <ul class="c10 lst-kix_nr42szp6omao-0 start">
        <li class="c7 li-bullet-0"><span>The codebook vocabulary needs to be much smaller than for doing image
                search</span><span class="c36 c13 c21">(ing?)</span></li>
    </ul>
    <ul class="c10 lst-kix_nr42szp6omao-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">In general, machine-learning techniques need much smaller
                vectors (for both performance and effectiveness)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">The visual words can be allowed to be less distinctive, allowing
                a little more variation between matching features.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Typically, the number of visual words might be as small as a few
                hundred, and up to a few thousand.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.wk5tvccx3g0q"><span class="c11">Another slide summary: Stuff</span></h2>
    <p class="c9"><span class="c1">Slides 18-26</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_rcx6imrasaua-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Machine Translation (2002)</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Identifying areas in an image, using visual words!</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-0">
        <li class="c7 li-bullet-0"><span class="c1">Semantic Spaces</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">SIngular Value Decomposition</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Probabilistic Latent Factor Models</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Non-negative Matrix Factorisation</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Visual words again!</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-0">
        <li class="c7 li-bullet-0"><span class="c1">Research focus shifted a little to use of bigger datasets in the
                mid-late 2000s. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">Interest in simpler (but more scalable) classifiers grew</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Classifying with BoVW</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">BoVW histogram representations are incredibly useful for image
                classification and object detection</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Commonly used with fast linear classifiers and SVMs</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-0">
        <li class="c7 li-bullet-0"><span class="c1">Over time the features used to create BoVW representations have
                improved</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Early global colour visual terms</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Consider each pixel as a visual word based on the quantisation
                of its colour to a discrete set of values.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">The BoVW Histogram is just a joint colour histogram that we saw
                earlier</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Sunset colours :o</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-0">
        <li class="c7 li-bullet-0"><span class="c1">Visual words from regions/segments</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Car in the night sky &#x1f60c;&#11088;</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-0">
        <li class="c7 li-bullet-0"><span class="c1">Visual words from interest points</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Salient region detection</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Local Descriptors</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Vector Quantisation</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Vocabulary of visual terms learnt through hierarchical
                k-means</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Word Occurrence Vectors</span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-0">
        <li class="c7 li-bullet-0"><span class="c1">Local features extracted around interest points work okay for
                classification, but there are more recent strategies that can work better&hellip; </span></li>
    </ul>
    <ul class="c10 lst-kix_rcx6imrasaua-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">densely sampled features</span></li>
    </ul>
    <h2 class="c19" id="h.w6csm04hotkg"><span class="c23 c21">Dense Local Image Patches</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 431.00px; height: 263.00px;"><img
                alt="" src="assets/computer-vision/image91.png"
                style="width: 431.00px; height: 263.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.oz6l7u8i71ld"><span class="c26 c21">Dense SIFT</span></h3>
    <ul class="c10 lst-kix_t01idielmxd9-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Rather than extracting your SIFT features at DoG interest points,
                you could extract them across a dense grid - this gives much more coverage of the entire image.</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 485.00px; height: 308.00px;"><img
                alt="" src="assets/computer-vision/image288.png"
                style="width: 485.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h3 class="c22" id="h.9xq7vq6q119k"><span class="c26 c21">Pyramid Dense SIFT</span></h3>
    <ul class="c10 lst-kix_mz3dsklbd6qf-0 start">
        <li class="c7 li-bullet-0"><span class="c1">For even better performance and coverage, you can sample in a
                Gaussian pyramid</span></li>
    </ul>
    <ul class="c10 lst-kix_mz3dsklbd6qf-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Note that the sampling region is a fixed size, so at higher
                scales you sample more content</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 346.00px; height: 341.00px;"><img
                alt="" src="assets/computer-vision/image341.png"
                style="width: 346.00px; height: 341.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c36 c63 c21">Egyptian Rhinoceros</span></p>
    <h3 class="c22" id="h.ours0s7049jz"><span class="c26 c21">Spatial Pyramids</span></h3>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 322.67px;"><img
                alt="" src="assets/computer-vision/image254.png"
                style="width: 602.00px; height: 322.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.hb3qtat72ije"><span class="c23 c21">Developing and benchmarking a BoVW scene classifier</span>
    </h2>
    <h3 class="c22" id="h.wktt7j1dxvv6"><span class="c26 c21">Evaluation Dataset</span></h3>
    <ul class="c10 lst-kix_1nzhdlhyea9z-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Common for academic research to use standardised datasets for
                developing scene classifiers and comparing results</span></li>
    </ul>
    <ul class="c10 lst-kix_1nzhdlhyea9z-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Datasets are usually split into labelled &ldquo;training&rdquo;
                and &ldquo;test&rdquo; sets.</span></li>
    </ul>
    <ul class="c10 lst-kix_1nzhdlhyea9z-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Only the training set can be used to train the classifier</span>
        </li>
        <li class="c9 c12 li-bullet-0"><span>Sometimes the test set labels are </span><span
                class="c6">withheld</span><span class="c1">&nbsp;completely to ensure there is no cheating</span></li>
    </ul>
    <h3 class="c22" id="h.35gjms3btr3w"><span class="c26 c21">Building the BoVW</span></h3>
    <ul class="c10 lst-kix_5a7zziv6town-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Firstly the raw features need to be extracted from the training
                images</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Then (if necessary) learn a codebook from these features</span></li>
    </ul>
    <ul class="c10 lst-kix_5a7zziv6town-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">i.e. using k-means on the raw features</span></li>
    </ul>
    <ul class="c10 lst-kix_5a7zziv6town-2 start">
        <li class="c9 c12 li-bullet-0"><span>Might be a </span><span class="c6">uniform random sample</span><span
                class="c1">&nbsp;of all the features rather than all of them</span></li>
    </ul>
    <ul class="c10 lst-kix_5a7zziv6town-0">
        <li class="c7 li-bullet-0"><span class="c1">Apply (vector) quantisation to the raw features and count the number
                of occurrences to build histograms for each image</span></li>
    </ul>
    <h3 class="c22" id="h.b74inykqb89i"><span class="c26 c21">Training classifiers</span></h3>
    <ul class="c10 lst-kix_cy912rrix0y3-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Classifiers can be trained using the histograms.</span></li>
    </ul>
    <ul class="c10 lst-kix_cy912rrix0y3-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">e.g. OvR linear classifiers with a kernel map.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">You might train on a subset of the training data</span></li>
    </ul>
    <ul class="c10 lst-kix_cy912rrix0y3-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">And use the remaining data to &ldquo;validate&rdquo; and
                optimise parameters.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Once you&rsquo;ve chosen the optimal parameters you can then
                re-train using the optimal values.</span></li>
    </ul>
    <h3 class="c22" id="h.tvkxxtnp7vpb"><span class="c26 c21">Classifying the test set</span></h3>
    <ul class="c10 lst-kix_mrg8c1yh2ly2-0 start">
        <li class="c7 li-bullet-0"><span class="c1">You&rsquo;re now in a position to apply the classifiers to the test
                data:</span></li>
    </ul>
    <ul class="c10 lst-kix_mrg8c1yh2ly2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Extract the features</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Quantise the features (using the codebook developed from the
                training set!)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">COmpute the occurrence histograms</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Use the classifiers to find the most likely class</span></li>
    </ul>
    <h3 class="c22" id="h.hrs4l9b67zv5"><span class="c26 c21">Evaluating Performance</span></h3>
    <ul class="c10 lst-kix_2slhnnshedy1-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Lots of ways to evaluate the performance of classification on the
                test (and validation) set.</span></li>
    </ul>
    <ul class="c10 lst-kix_2slhnnshedy1-1 start">
        <li class="c9 c16 li-bullet-0"><span>Conceptually the simplest summary measure is probably </span><span
                class="c6">average precision</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">This is literally the proportion of number of correct
                classifications to the total number of predictions</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c36 c13 c21">Phew, I think we&rsquo;ve covered all the examinable content. I&rsquo;ll
            summarise the bonus slides just for completeness.</span></p>
    <h1 class="c46" id="h.spxwuwtkjljg"><span class="c29">Lecture 11: Towards 3D vision</span></h1>
    <p class="c9"><span class="c13">Look at the slides for pictures :) </span><span class="c13 c57"><a class="c0"
                href="https://www.google.com/url?q=http://comp3204.ecs.soton.ac.uk/lectures/pdf/L11-towards3d.pdf&amp;sa=D&amp;source=editors&amp;ust=1623775880556000&amp;usg=AOvVaw24h5W8_x4nP5yyaJh8SnmJ">http://comp3204.ecs.soton.ac.uk/lectures/pdf/L11-towards3d.pdf</a></span>
    </p>
    <ul class="c10 lst-kix_qrtuz4mciepu-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Applications</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Architecture</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Urban Planning</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Virtual Tourism</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Clothing &amp; body measurement</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Art</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">SLAM (Simultaneous localization and mapping)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Cultural Heritage</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Forensics</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Surveillance</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Motion Capture (Films &amp; Games)</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-0">
        <li class="c7 li-bullet-0"><span class="c2">Cameras</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Camera Geometry</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Camera Calibration</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-0">
        <li class="c7 li-bullet-0"><span class="c2">Measuring Depth</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Narrow Baseline Stereo</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Stereo Camera</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Epipolar geometry</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Dense narrow-baseline stereo</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-0">
        <li class="c7 li-bullet-0"><span class="c2">Wide Baseline Stereo</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Multiple images can be used to jointly infer 3D structure, and
                the camera pose and intrinsics of each camera</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">Point matches (i.e. SIFT) are used as the basis for
                triangulating 3D points from the 2D images</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c24 c6 c21">Reconstructing Venice</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-0">
        <li class="c7 li-bullet-0"><span class="c2">Monocular Vision</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Shadow Scanner</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Structured Light Imaging</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Time of Flight Imaging</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-0">
        <li class="c7 li-bullet-0"><span class="c2">Non-visible techniques</span></li>
    </ul>
    <ul class="c10 lst-kix_qrtuz4mciepu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">LIDAR</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">PrimeSense (Kinect)</span></li>
    </ul>
    <h2 class="c19" id="h.2ekoomb6f6lt"><span class="c11">Summary Summary</span></h2>
    <ul class="c10 lst-kix_yixsdu3jx4lr-0 start">
        <li class="c7 li-bullet-0"><span class="c2">3D computer vision has lots of practical applications</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Camera models give a mathematical description of how a pixel in a 2D
                image is related to a point in a 3D scene</span></li>
    </ul>
    <ul class="c10 lst-kix_yixsdu3jx4lr-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Camera calibration can be used to find the parameters of a
                camera</span></li>
    </ul>
    <ul class="c10 lst-kix_yixsdu3jx4lr-0">
        <li class="c7 li-bullet-0"><span class="c2">Multiple views of a scene can be used to infer depth </span></li>
        <li class="c7 li-bullet-0"><span class="c29">There are lots of other techniques for capturing depth that only
                require a single sensor</span></li>
    </ul>
    <h1 class="c46" id="h.2po3i53z2ykf"><span class="c53 c29 c21">Programming for computer vision &amp; other musings
            related to the coursework</span></h1>
    <h2 class="c19" id="h.hmme0vxnjqiy"><span class="c11">Writing code for computer vision</span></h2>
    <ul class="c10 lst-kix_rjbczt8adk6z-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Images usually stored as arrays of integers</span></li>
    </ul>
    <ul class="c10 lst-kix_rjbczt8adk6z-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Typically 8-bits per pixel per channel</span></li>
    </ul>
    <ul class="c10 lst-kix_rjbczt8adk6z-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">12-16 bit increasingly common (e.g. HDR imaging)</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c2">Uses unsigned pixel values</span></li>
    </ul>
    <ul class="c10 lst-kix_rjbczt8adk6z-1">
        <li class="c9 c16 li-bullet-0"><span class="c2">Compressed using a variety of techniques</span></li>
    </ul>
    <ul class="c10 lst-kix_rjbczt8adk6z-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">Lossy or lossless</span></li>
    </ul>
    <h2 class="c19" id="h.g34n15jupn2i"><span class="c11">Most vision algorithms are continuous</span></h2>
    <ul class="c10 lst-kix_nnyhajemdbn9-0 start">
        <li class="c7 li-bullet-0"><span class="c2">E.g. convolution with a continuous function (i.e. Gaussian)</span>
        </li>
        <li class="c7 li-bullet-0"><span class="c2">If we were writing the next Adobe Photoshop, it would be important
                that we kept out images in a similar format (integer pixels, same number of bits)</span></li>
    </ul>
    <ul class="c10 lst-kix_nnyhajemdbn9-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">We would essentially round pixel values to the closest integer
                and clip those out of range</span></li>
    </ul>
    <ul class="c10 lst-kix_nnyhajemdbn9-0">
        <li class="c7 li-bullet-0"><span class="c2">For vision applications we don&rsquo;t want to do this as
                we&rsquo;ll lose precision</span></li>
    </ul>
    <h2 class="c19" id="h.kvspk4mrmqdt"><span class="c11">Always work with floating point pixels</span></h2>
    <ul class="c10 lst-kix_6hb4zz7uid8h-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Unless they&rsquo;ve been specifically optimised for integer math,
                all vision algorithms should use floating point pixel values</span></li>
    </ul>
    <ul class="c10 lst-kix_6hb4zz7uid8h-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Ensure the best possible discretisation from operations
                involving continuous functions</span></li>
    </ul>
    <ul class="c10 lst-kix_6hb4zz7uid8h-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c2">Higher effective bit depth (32/64 bits per pixel per
                band)</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c2">Ability to deal with negative values</span></li>
    </ul>
    <ul class="c10 lst-kix_6hb4zz7uid8h-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c2">Turns out to be very important for convolution!</span></li>
    </ul>
    <ul class="c10 lst-kix_6hb4zz7uid8h-2">
        <li class="c9 c12 li-bullet-0"><span class="c2">Ability to deal with numbers outside of the normal range</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_6hb4zz7uid8h-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c2">Just because a pixel has a grey level of 1.1 doesn&rsquo;t mean
                it&rsquo;s invalid, just that it&rsquo;s too bright to be displayed in the normal colour gamut.</span>
        </li>
    </ul>
    <h2 class="c19" id="h.uvbvdbpaxwhm"><span class="c11">Guidelines for writing vision code</span></h2>
    <ul class="c10 lst-kix_ak06mziepumf-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Convert any images to float types immediately once you&rsquo;ve read
                them</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Don&rsquo;t convert them back to integer types until you need to
                (i.e. for display or saving)</span></li>
    </ul>
    <ul class="c10 lst-kix_ak06mziepumf-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Be mindful that a meaningful conversion might not just involve
                rounding if you want to preserve the data.</span></li>
    </ul>
    <h2 class="c19" id="h.gfw67atdbn5x"><span class="c11">Convolution</span></h2>
    <p class="c9"><span class="c36 c13 c21">We probably do need to know how to do convolution so...</span></p>
    <ul class="c10 lst-kix_q2vb514njttg-0 start">
        <li class="c7 li-bullet-0"><span class="c2">Convolution is an element-wise multiplication in the Fourier domain
                (c.f. Convolution Theorem)</span></li>
        <li class="c7 li-bullet-0"><span class="c2">f&#65121;g = ifft(fft(f) . fft(g))</span></li>
        <li class="c7 li-bullet-0"><span class="c2">Whilst S and F might only contain real numbers, the FFTs are complex
                (real + imagj)</span></li>
    </ul>
    <ul class="c10 lst-kix_q2vb514njttg-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Need to do complex multiplication!</span></li>
    </ul>
    <ul class="c10 lst-kix_q2vb514njttg-0">
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 525.00px; height: 60.00px;"><img
                    alt="" src="assets/computer-vision/image130.png"
                    style="width: 525.00px; height: 60.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <h2 class="c19" id="h.adllfqjatp2e"><span class="c29 c6">Aside: phase and magnitude</span></h2>
    <ul class="c10 lst-kix_ba10zy4idecu-0 start">
        <li class="c7 li-bullet-0"><span class="c29">Given a complex number (n = real + imagj) from an FFT we can
                compute its </span><span class="c29 c5">phase </span><span class="c29">and </span><span
                class="c36 c29 c5">magnitude</span></li>
    </ul>
    <ul class="c10 lst-kix_ba10zy4idecu-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">phase = atan2(imag, real)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c2">magnitude = sqrt(real*real + imag*imag)</span></li>
    </ul>
    <ul class="c10 lst-kix_ba10zy4idecu-0">
        <li class="c7 li-bullet-0"><span class="c2">We might perform this transformation to display the FFT as it
                conceptually helps us understand what the FFT is doing</span></li>
        <li class="c7 li-bullet-0"><span class="c2">We can&rsquo;t use this representation to perform convolution
                however (need to transform back to complex form first)</span></li>
    </ul>
    <h2 class="c19" id="h.gfdnriorr11"><span class="c29 c6 c21 c61">Aside: Displaying FFTs</span></h2>
    <ul class="c10 lst-kix_i0sdd09hywxs-0 start">
        <li class="c7 li-bullet-0"><span class="c29">FFTs are often re-ordered so that the DC component (0- frequency)
                component is in the centre:</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 386.00px; height: 325.00px;"><img
                alt="" src="assets/computer-vision/image317.png"
                style="width: 386.00px; height: 325.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.58qqzn933xwu"><span class="c11">Template Convolution</span></h2>
    <ul class="c10 lst-kix_kgzsvyaw5k2o-0 start">
        <li class="c7 li-bullet-0"><span class="c2">In the time domain, convolution is:</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 441.00px; height: 150.00px;"><img
                alt="" src="assets/computer-vision/image222.png"
                style="width: 441.00px; height: 150.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_tsghj7qzhdtc-0 start">
        <li class="c7 li-bullet-0"><span class="c29 c5">Notice that the image or kernel is &ldquo;flipped&rdquo; in time
            </span></li>
    </ul>
    <ul class="c10 lst-kix_tsghj7qzhdtc-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c2">Also notice that the is no normalisation or similar</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 466.00px; height: 384.00px;"><img
                alt="" src="assets/computer-vision/image184.png"
                style="width: 466.00px; height: 384.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c39 c29 c35 c21">int kh = kernel.height; </span></p>
    <p class="c9"><span class="c39 c29 c35 c21">int kw = kernel.width; </span></p>
    <p class="c9"><span class="c39 c29 c35 c21">int hh = kh / 2; </span></p>
    <p class="c9"><span class="c39 c29 c35 c21">int hw = kw / 2; </span></p>
    <p class="c9"><span class="c39 c29 c35 c21">Image clone = new Image(image.width, image.height); </span></p>
    <p class="c9"><span class="c39 c29 c35 c21">for (int y = hh; y &lt; image.height - (kh - hh); y++) { </span></p>
    <p class="c9 c47"><span class="c39 c29 c35 c21">for (int x = hw; x &lt; image.width - (kw - hw); x++) { </span></p>
    <p class="c9 c47 c50"><span class="c39 c29 c35 c21">float sum = 0;</span></p>
    <p class="c9"><span
            class="c39 c29 c35 c21">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for
            (int j = 0, jj = kh - 1; j &lt; kh; j++, jj--) { </span></p>
    <p class="c9 c73"><span class="c39 c29 c35 c21">for (int i = 0, ii = kw - 1; i &lt; kw; i++, ii--) {</span></p>
    <p class="c9 c47 c73"><span class="c39 c29 c35 c21">int rx = x + i - hw; int ry = y + j - hh;</span></p>
    <p class="c9 c47 c73"><span class="c39 c29 c35 c21">sum += </span></p>
    <p class="c9 c47 c73"><span class="c39 c29 c35 c21">image.pixels[ry][rx] * kernel.pixels[jj][ii];</span></p>
    <p class="c9 c73"><span class="c39 c29 c35 c21">}</span></p>
    <p class="c9 c33"><span class="c39 c29 c35 c21">} </span></p>
    <p class="c9 c47 c50"><span class="c39 c29 c35 c21">clone.pixels[y][x] = sum;</span></p>
    <p class="c9 c47"><span class="c39 c29 c35 c21">}</span></p>
    <p class="c9"><span class="c29 c35 c21 c39">}</span></p>
    <p class="c9"><span class="c36 c21 c63">Formatting bruh</span></p>
    <h2 class="c19" id="h.xkxgxpeu1a6y"><span class="c23 c21">What if you don&rsquo;t flip the kernel?</span></h2>
    <ul class="c10 lst-kix_lois9ucbh8l6-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Obviously if the kernel is symmetric, there is no difference</span>
        </li>
        <li class="c7 li-bullet-0"><span class="c1">However, you&rsquo;re actually not computing convolution, but
                another operation called cross-correlation</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 367.00px; height: 67.00px;"><img
                alt="" src="assets/computer-vision/image305.png"
                style="width: 367.00px; height: 67.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_mna24bs1yy4o-0 start">
        <li class="c7 li-bullet-0"><span class="c1">* represents the complex conjugate</span></li>
        <li class="c7 li-bullet-0"><span class="c1">(you can compute this with the multiplication of the FFTs just like
                convolution: iFFT(FFT(f)* . FFT(g)) </span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 294.67px;"><img
                alt="" src="assets/computer-vision/image250.png"
                style="width: 602.00px; height: 294.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.w3ln0jlh0zum"><span class="c23 c21">Ideal Low-Pass filter</span></h2>
    <ul class="c10 lst-kix_j5w7jd3g8maj-0 start">
        <li class="c7 li-bullet-0"><span class="c1">&ldquo;Ideal&rdquo; low pass filter removes all frequencies above a
                cutoff</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 361.00px; height: 362.00px;"><img
                alt="" src="assets/computer-vision/image175.png"
                style="width: 361.00px; height: 362.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.qqkydnh85njg"><span class="c23 c21">Ideal Low-Pass filter - problems</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 360.00px;"><img
                alt="" src="assets/computer-vision/image283.png"
                style="width: 602.00px; height: 360.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.ky501pcxpt4o"><span class="c23 c21">Gaussian filters - why</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 539.00px; height: 362.00px;"><img
                alt="" src="assets/computer-vision/image90.png"
                style="width: 539.00px; height: 362.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.v0z03j8ax760"><span class="c23 c21">Building Gaussian Filters</span></h2>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 344.00px;"><img
                alt="" src="assets/computer-vision/image129.png"
                style="width: 602.00px; height: 344.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.4au8qchl9ui"><span class="c23 c21">High-pass filters</span></h2>
    <ul class="c10 lst-kix_xnwudi67gxad-0 start">
        <li class="c7 li-bullet-0"><span class="c1">&ldquo;To obtain a high-pass filtered image, subtract a lowpass
                filtered image from the image itself&rdquo;</span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 389.00px; height: 316.00px;"><img
                    alt="" src="assets/computer-vision/image358.png"
                    style="width: 389.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_xnwudi67gxad-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">ILP = I&#65121;G </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">IHP = I-ILP </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">IHP = I - I&#65121;G </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">IHP = I&#65121;&delta; - I&#65121;G </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">IHP = I&#65121;(&delta; - G)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.71m9hzfnx1cz"><span>Note - Don&rsquo;t do this!</span></h2>
    <ul class="c10 lst-kix_bju6cihjne3n-0 start">
        <li class="c7 li-bullet-0"><span>IHP = I&#65121;(&delta; - G) is not the same as IHP = I&#65121;(1 - G)</span>
        </li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 587.00px; height: 311.00px;"><img
                alt="" src="assets/computer-vision/image314.png"
                style="width: 587.00px; height: 311.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <h2 class="c19" id="h.6v4vm6kgouwl"><span class="c23 c21">High-pass filters have a mixture of negative and positive
            coefficients</span></h2>
    <ul class="c10 lst-kix_k725m1crijcy-0 start">
        <li class="c7 li-bullet-0"><span class="c1">&hellip;that means the resultant image will also have positive and
                negative pixels</span></li>
    </ul>
    <ul class="c10 lst-kix_k725m1crijcy-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">this is important - for example it can tell us about the
                direction of edges:</span></li>
    </ul>
    <ul class="c10 lst-kix_k725m1crijcy-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">[-0.5, 0.5] kernel</span></li>
    </ul>
    <ul class="c10 lst-kix_k725m1crijcy-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c1">(remember convolution means kernel flipped) </span></li>
        <li class="c9 c55 li-bullet-0"><span class="c1">+values in the output image mean edge from right to left</span>
        </li>
        <li class="c9 c55 li-bullet-0"><span class="c1">-values in output image mean edge from left to right</span></li>
    </ul>
    <ul class="c10 lst-kix_k725m1crijcy-0">
        <li class="c7 li-bullet-0"><span class="c1">Convolution implementation MUST NOT:</span></li>
    </ul>
    <ul class="c10 lst-kix_k725m1crijcy-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Normalise</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">result in unsigned types</span></li>
    </ul>
    <h2 class="c19" id="h.jqamhqjsy0dg"><span class="c23 c21">Building hybrid images</span></h2>
    <h3 class="c22" id="h.en4ii6yp5vbp"><span class="c26 c21">&hellip;is really simple</span></h3>
    <ul class="c10 lst-kix_xgnu8zxsigmp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Add the low pass and high-pass images together</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Don&rsquo;t:</span></li>
    </ul>
    <ul class="c10 lst-kix_xgnu8zxsigmp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">average the two images</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">do a weighted combination of the two images</span></li>
    </ul>
    <ul class="c10 lst-kix_xgnu8zxsigmp-0">
        <li class="c7 li-bullet-0"><span class="c1">just add them (and clip if necessary)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c79">Happy Revising!</span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 360.00px;"><img
                alt="" src="assets/computer-vision/image114.png"
                style="width: 602.00px; height: 360.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9"><span class="c36 c63 c21">(not my hybrid, add a suggestion if you know whose it is)</span></p>
    <p class="c3"><span class="c36 c63 c21"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 240.00px;"><img
                alt="" src="assets/computer-vision/image239.png"
                style="width: 602.00px; height: 240.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span class="c36 c13 c21">(- Thanks Matthew Barnes, god of notes (this is not a real
            hybrid lol))</span></p>
    <p class="c3"><span class="c36 c63 c21"></span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c13">Go look at the bonus lecture yourself: </span><span class="c57 c13"><a class="c0"
                href="https://www.google.com/url?q=http://comp3204.ecs.soton.ac.uk/lectures/pdf/VisionRetrospective.pdf&amp;sa=D&amp;source=editors&amp;ust=1623775880574000&amp;usg=AOvVaw1AzVoEfj2kJ7fSAUtQorTR">http://comp3204.ecs.soton.ac.uk/lectures/pdf/VisionRetrospective.pdf</a></span>
        <hr style="page-break-before:always;display:none;">
    </p>
    <h1 class="c46" id="h.32vczl3k1335"><span class="c21 c31">TL;DR</span></h1>
    <p class="c9"><span class="c36 c56 c21">The TL;DRs are TL;DRs themselves; so much content</span></p>
    <p class="c9"><span>The TL;DRs are actually pretty long, there&rsquo;s just a lot of important content.</span></p>
    <h2 class="c19" id="h.8j5rgmn7e95p"><span>Part 1: </span><span class="c23 c21">Mark</span></h2>
    <p class="c9"><span class="c48 c21 c89">See collab TL;DR below Jon&rsquo;s part.</span></p>
    <p class="c9"><span class="c13 c25"><a class="c0" href="#h.gr71k62go3oc">Mark (formatted by Joshua
                Gregory)</a></span></p>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.k06zf8tvxd71"><span>Part 2: </span><span class="c23 c21">Jon</span></h2>
    <p class="c9"><span class="c36 c13 c21">Summaries from end of slides and hand-out notes.</span></p>
    <h3 class="c22" id="h.qpxqxvun8m4x"><span class="c26 c21">Lec 1</span></h3>
    <p class="c9"><span>A computer vision system is not just software: it is any </span><span
            class="c5">hardware</span><span>, </span><span class="c5">software </span><span>and </span><span
            class="c5">wetware </span><span>(i.e. humans) that make up the complete system. To engineer a computer
            vision system, you need to think about how you can achieve the required level of </span><span
            class="c5">robustness </span><span>by </span><span class="c5">constraining </span><span>the problem at hand
            and incorporating sufficient </span><span class="c5">invariance </span><span>to potentially changing
        </span><span>environmental factors</span><span>.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_bxrgcdbrkef3-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Robust </span><span>and </span><span class="c5">repeatable
            </span><span>computer vision is achieved through engineered </span><span class="c5">invariance
            </span><span>and applied </span><span class="c5">constraints</span><span class="c1">.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_raucmqhg0cph-0 start">
        <li class="c7 li-bullet-0"><span class="c15 c5">Colour-spaces</span></li>
    </ul>
    <ul class="c10 lst-kix_raucmqhg0cph-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">RGB</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">HSV (Hue, Saturation, Value)</span></li>
    </ul>
    <h3 class="c22" id="h.8p9k7os3yqle"><span class="c26 c21">Lec 2</span></h3>
    <p class="c9"><span class="c5">Machine learning</span><span>&nbsp;is a fundamental part of </span><span
            class="c5">high-level</span><span>&nbsp;computer vision (interpreting what is seen, versus the </span><span
            class="c5">low-level</span><span>, which is all about processing the image). The standard computer vision
            pipeline goes from the </span><span class="c5">image</span><span>, through a process of </span><span
            class="c5">feature extraction</span><span>, to a </span><span class="c5">pattern recognition
            component</span><span>&nbsp;that makes inferences. Machine learning is a standard way of </span><span
            class="c5">training </span><span class="c1">the pattern recognition system.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_3k8dow5pza5p-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Extracting features</span><span class="c1">&nbsp;is a key part of
                computer vision</span></li>
    </ul>
    <ul class="c10 lst-kix_3k8dow5pza5p-1 start">
        <li class="c9 c16 li-bullet-0"><span>Typically, these are </span><span class="c5">numerical vectors</span><span
                class="c1">&nbsp;that can be used with machine-learning techniques.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Featurevectors </span><span>can be compared by measuring
            </span><span class="c5">distance</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_3k8dow5pza5p-0">
        <li class="c7 li-bullet-0"><span class="c5">Classification </span><span>learns what </span><span
                class="c5">class </span><span class="c1">to assign a feature to.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Clustering </span><span>groups </span><span class="c5">similar
            </span><span class="c1">features.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_qa0y81byskdl-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Sometimes you&rsquo;ll need to figure out the Euclidean distance
                between 2 points in the feature space.</span></li>
    </ul>
    <ul class="c10 lst-kix_qa0y81byskdl-1 start">
        <li class="c9 c16 li-bullet-0"><span>Point </span><span class="c5">p</span><span>=(p</span><span
                class="c42">1</span><span>, p</span><span class="c42">2</span><span>, &hellip;, p</span><span
                class="c42">n</span><span>) and </span><span class="c5">q</span><span>=(q</span><span
                class="c42">1</span><span>, q</span><span class="c42">2</span><span>, &hellip;, q</span><span
                class="c42">n</span><span class="c1">)</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 72.00px;"><img
                alt="" src="assets/computer-vision/image319.png"
                style="width: 602.00px; height: 72.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_3ogqvj3gjogk-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Cosine similarity another measure for vectors. It is not a distance
                measure.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Similarity = 1 if vectors same direction; decreases as the angle
                increases.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 125.00px;"><img
                alt="" src="assets/computer-vision/image200.png"
                style="width: 602.00px; height: 131.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_eng429scswtw-0 start">
        <li class="c7 li-bullet-0"><span>Classification: assign</span><span class="c5">&nbsp;class labels</span><span>,
            </span><span class="c5">binary </span><span>or </span><span class="c5">multiclass</span><span
                class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>ML algorithm learns on </span><span class="c5">pre-labelled training
                data</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Hyperplane </span><span>through the feature space, </span><span
                class="c5">separates the classes</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>Linear classifiers: think of it as the hyperplane is a </span><span
                class="c5">straight line</span><span class="c1">&nbsp;in the vector space.</span></li>
    </ul>
    <ul class="c10 lst-kix_eng429scswtw-1 start">
        <li class="c9 c16 li-bullet-0"><span>Linear classifiers </span><span class="c5">more efficient</span><span
                class="c1">&nbsp;than KNN, don&rsquo;t need training data and only need to check side of hyperplane for
                unlabelled point.</span></li>
    </ul>
    <ul class="c10 lst-kix_eng429scswtw-0">
        <li class="c7 li-bullet-0"><span>Non-linear classifier: </span><span class="c5">Support Vector
                Machine</span><span class="c1">&nbsp;(SVM)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_iylv1l5qtjml-0 start">
        <li class="c7 li-bullet-0"><span class="c15 c5">K-nearest-neighbours (KNN)</span></li>
    </ul>
    <ul class="c10 lst-kix_iylv1l5qtjml-1 start">
        <li class="c9 c16 li-bullet-0"><span>Find class of unlabelled vector by finding majority class of </span><span
                class="c6">closest K</span><span class="c6 c5">&nbsp;</span><span class="c6">training points</span><span
                class="c6 c5">.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Can become computationally </span><span class="c5">expensive</span><span
                class="c1">&nbsp;when lots of training example or large dimensions.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_2l743lz80iqa-0 start">
        <li class="c7 li-bullet-0"><span class="c5">K-Means</span></li>
    </ul>
    <ul class="c10 lst-kix_2l743lz80iqa-1 start">
        <li class="c9 c16 li-bullet-0"><span>Algorithm to </span><span class="c5">cluster </span><span class="c1">data
                in feature space.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Clusters represented by </span><span class="c5">centroids</span><span
                class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Algorithm:</span></li>
    </ul>
    <ul class="c10 lst-kix_2l743lz80iqa-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">K value set before</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Randomly chose centroids</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Each point assigned closest centroid</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Centroid recomputed as mean</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">If Centroid has no points assigned, randomly
                re-initialise</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">This is done iteratively until the centroids don&rsquo;t
                move.</span></li>
    </ul>
    <ul class="c10 lst-kix_2l743lz80iqa-1">
        <li class="c9 c16 li-bullet-0"><span class="c15 c5">K-means always converges, but not necessarily to most
                optimal solution.</span></li>
    </ul>
    <h3 class="c22" id="h.1b8lw1n9rer3"><span class="c26 c21">Lec 3</span></h3>
    <p class="c9"><span>Understanding the </span><span class="c5">shape </span><span>of data in a feature space is
            important to </span><span class="c5">effectively using</span><span>&nbsp;it. In addition, by understanding
            the </span><span class="c5">distribution </span><span>of really highly dimensional data, it is possible to
            determine the most important modes of </span><span class="c5">variation </span><span>of that data, and thus
            represent the data in a space with many </span><span class="c5">fewer dimensions</span><span>.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_d5mhd2r5yemq-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Covariance </span><span class="c1">measures the &ldquo;shape&rdquo;
                of data by measuring how different dimensions change together.</span></li>
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">principle axes</span><span>&nbsp;are a </span><span
                class="c5">basis</span><span>, aligned such they describe most directions of </span><span
                class="c5">greatest variance</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">Eigendecomposition </span><span>of the covariance
                matrix produces pairs of </span><span class="c5">eigenvectors </span><span>(corresponding to the
                principal axes) and </span><span class="c5">eigenvalues </span><span class="c1">(proportional to the
                variance along the respective axis).</span></li>
        <li class="c7 li-bullet-0"><span class="c5">PCA </span><span>(Principal Component Analysis) aligns data with its
                principal axes, and allows </span><span class="c5">dimensionality reduction</span><span
                class="c1">&nbsp;by discounting axes with low variance.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Eigenfaces </span><span class="c1">applies PCA to vectors made from
                pixel values to make robust low-dimensional image descriptors.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_x3majt9m5zdf-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Variance</span><span class="c1">&nbsp;- how &ldquo;spread-out&rdquo;
                the data is from the mean</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 230.00px; height: 80.00px;"><img
                alt="" src="assets/computer-vision/image106.png"
                style="width: 230.00px; height: 80.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_x3majt9m5zdf-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c6">n </span><span>data points: </span><span
                class="c6">x</span><span class="c42 c6">i </span><span class="c1">...</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c6">&mu;</span><span class="c1">&nbsp;mean</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_x3majt9m5zdf-0">
        <li class="c7 li-bullet-0"><span class="c5">Covariance </span><span class="c1">- how 2 variables change
                together. </span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 303.50px; height: 75.59px;"><img
                alt="" src="assets/computer-vision/image252.png"
                style="width: 303.50px; height: 75.59px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_mrs63u2t1mtp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Variance = covariance when 2 variables the same.</span></li>
        <li class="c7 li-bullet-0"><span>Variable </span><span class="c5">uncorrelated</span><span class="c1">&nbsp;when
                covariance = 0.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_b2hiysxv6wx9-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Covariance matrix</span><span>&nbsp;- </span><span
                class="c6">square</span><span>&nbsp;</span><span class="c6">symmetric </span><span class="c1">matrix
                containing all the covariance values.</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.50px; height: 82.12px;"><img
                alt="" src="assets/computer-vision/image355.png"
                style="width: 320.50px; height: 82.12px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_k1m8zwdozgml-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Principal axes of variation</span><span class="c1">&nbsp;- linearly
                independent vectors, orthogonal, act as basis</span></li>
    </ul>
    <ul class="c10 lst-kix_k1m8zwdozgml-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Major axis data most spread</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Minor axis perpendicular to major</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_yx4crzjfu2w1-0 start">
        <li class="c7 li-bullet-0"><span class="c15 c5">Eigendecomposition of covariance matrix</span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 128.00px; height: 38.00px;"><img
                alt="" src="assets/computer-vision/image107.png"
                style="width: 128.00px; height: 38.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_yx4crzjfu2w1-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">A </span><span class="c1">is square matrix</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">v is non-zero eigenvector</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">&lambda; is eigenvalue</span></li>
    </ul>
    <ul class="c10 lst-kix_yx4crzjfu2w1-0">
        <li class="c7 li-bullet-0"><span>If matrix </span><span class="c5">A</span><span>&nbsp;is covariance matrix,
                then </span><span class="c5">eigenvectors are principal components</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_yx4crzjfu2w1-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Vector with largest eigenvalue is first principal axis and so
                on&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_yx4crzjfu2w1-0">
        <li class="c7 li-bullet-0"><span class="c5">The Eigendecomposition is thus a way of finding the principal
                axes</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_djdsyemnbeqf-0 start">
        <li class="c7 li-bullet-0"><span class="c1">PCA projects data in an original space to a new space defined by the
                basis of principal axes.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Reduce the dimensionality </span><span class="c1">of the data, get
                rid of axes with small variance.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">PCA steps summary:</span></p>
    <ol class="c10 lst-kix_1srhxltp0aq8-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Mean-centre the data vectors</span></li>
        <li class="c7 li-bullet-0"><span>Form vectors in matrix </span><span class="c5">Z</span><span class="c1">, so
                each row corresponds to vector</span></li>
        <li class="c7 li-bullet-0"><span>Do Eigendecomposition of matrix </span><span class="c5">Z</span><span
                class="c5 c66">T</span><span class="c5">Z</span><span>, to get eigenvector matrix </span><span
                class="c5">Q</span><span>&nbsp;and diagonal eigenvalue matrix </span><span
                class="c15 c5">&Lambda;:</span></li>
    </ol>
    <ol class="c10 lst-kix_1srhxltp0aq8-1 start" start="1">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 185.00px; height: 42.00px;"><img
                    alt="" src="assets/computer-vision/image120.png"
                    style="width: 185.00px; height: 42.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ol>
    <ol class="c10 lst-kix_1srhxltp0aq8-0" start="4">
        <li class="c7 li-bullet-0"><span>Sort columns of </span><span class="c5">Q </span><span>and values of
            </span><span class="c5">&Lambda;</span><span class="c1">&nbsp;to decreasing order.</span></li>
        <li class="c7 li-bullet-0"><span>Select </span><span class="c6">L </span><span>largest eigenvectors of
            </span><span class="c5">Q </span><span>(first </span><span class="c6">L</span><span>&nbsp;columns) to make
                transform matrix </span><span class="c5">Q</span><span class="c42">L</span><span class="c1">.</span>
        </li>
        <li class="c7 li-bullet-0"><span>Project original vectors into lower dimensional space, </span><span
                class="c5">T</span><span class="c42">L</span><span class="c1">:</span></li>
    </ol>
    <ol class="c10 lst-kix_1srhxltp0aq8-1 start" start="1">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 105.00px; height: 29.00px;"><img
                    alt="" src="assets/computer-vision/image217.png"
                    style="width: 105.00px; height: 29.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ol>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_rioljmb7k3ao-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Eigenfaces </span><span class="c1">- face recognition, PCA to
                features, represent images far fewer dimensions.</span></li>
    </ul>
    <ul class="c10 lst-kix_rioljmb7k3ao-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">All images need to be same size, aligned</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Also generative model</span></li>
    </ul>
    <p class="c9"><span class="c15 c5">Overall approach</span></p>
    <p class="c9"><span class="c1">Training images:</span></p>
    <ol class="c10 lst-kix_7azkj589y8q5-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Images flattened to vectors</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Mean vector computed and stored</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Vectors mean centred</span></li>
        <li class="c7 li-bullet-0"><span class="c1">PCA applied, project to lower dimensional space. Transform matrix
                stored.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Low dimensional vectors used as training data for classifier</span>
        </li>
    </ol>
    <ol class="c10 lst-kix_7azkj589y8q5-1 start" start="1">
        <li class="c9 c16 li-bullet-0"><span class="c1">KNN with distance threshold</span></li>
    </ol>
    <p class="c9"><span class="c1">Testing image:</span></p>
    <ol class="c10 lst-kix_6540m2g773ud-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Image flattened to vector, mean vector subtracted</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Vector projected by PCA basis (transform matrix) to lower
                dimensional space</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Vector given to classifier, generates class label</span></li>
    </ol>
    <h3 class="c22" id="h.u4z9m0jn9o9i"><span class="c26 c21">Lec 4</span></h3>
    <p class="c9"><span class="c5">Features </span><span>that can be extracted from images fall into </span><span
            class="c5">four</span><span>&nbsp;main categories. </span><span class="c5">Global </span><span>features are
            extracted from the </span><span class="c5">entire </span><span>image. </span><span class="c5">Region-based
        </span><span>features are extracted from </span><span class="c5">regions </span><span>of the image called
        </span><span class="c5">connected components</span><span>. Detecting connected components requires that you
            first apply a process called </span><span class="c5">segmentation </span><span>to partition the image into
            multiple segments.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <p class="c9"><span class="c1">Image features can be categorised into one of four main categories:</span></p>
    <ol class="c10 lst-kix_oyiv6ofttupf-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Global</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Grid-based (block-based)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Region-based</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Local, &ldquo;interest points&rdquo;</span></li>
    </ol>
    <p class="c3 c50"><span class="c1"></span></p>
    <ul class="c10 lst-kix_hqyzg95cagko-0 start">
        <li class="c7 li-bullet-0"><span>A common type of global feature is a </span><span class="c5">global colour
                histogram</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>Region-based methods need </span><span class="c5">regions </span><span>to be
                detected - this process is called </span><span class="c5">segmentation</span><span class="c1">... many
                different approaches</span></li>
        <li class="c7 li-bullet-0"><span>Connected components are </span><span class="c5">segments </span><span
                class="c1">in which the pixels are all reachable by a connected path.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_eubvxhhqgjlj-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Feature morphology refers to the form or shape of a feature</span>
        </li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ur3u0expqy54-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Joint colour histograms </span><span class="c1">- (global)
                accumulate binned pixel values.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Normalisation </span><span class="c1">of histogram for image of
                different sizes.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Colour space important.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_q06436ogo25-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Segmentation </span><span class="c1">- (region) set of pixels share
                certain visual characteristics.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Thresholding </span><span class="c1">simplest form, grey image
                &rarr; binary image.</span></li>
    </ul>
    <ul class="c10 lst-kix_q06436ogo25-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Work well when constrained, designed to stand out (QR
                codes)</span></li>
    </ul>
    <ul class="c10 lst-kix_q06436ogo25-0">
        <li class="c7 li-bullet-0"><span class="c1">Manual thresholding value, or ...</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Otsu&rsquo;s thresholding method </span><span class="c1">- assumes 2
                classes, bi-modal histogram.</span></li>
    </ul>
    <ul class="c10 lst-kix_q06436ogo25-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Combined spread of 2 classes minimal (intra-class
                variance)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_q06436ogo25-0">
        <li class="c7 li-bullet-0"><span class="c5">Adaptive thresholding</span><span class="c1">: e.g. sets pixel to bg
                (background) if the value less than mean of neighbours plus offset, fg foreground otherwise.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ff7tfbl7j8nr-0 start">
        <li class="c7 li-bullet-0"><span class="c5">K-Means clustering</span><span class="c1">&nbsp;for
                segmentation.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_mqz58082lamp-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Connected Components </span><span class="c1">- segment where all
                pixels reachable from other (adjacently)</span></li>
    </ul>
    <ul class="c10 lst-kix_mqz58082lamp-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 289.00px; height: 162.00px;"><img
                    alt="" src="assets/computer-vision/image227.png"
                    style="width: 289.00px; height: 162.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_mqz58082lamp-0">
        <li class="c7 li-bullet-0"><span class="c5">Connected-component labelling</span><span class="c1">&nbsp;- binary
                image &rarr; set of connected components</span></li>
    </ul>
    <p class="c9"><span class="c5">Two-pass </span><span class="c1">algorithm:</span></p>
    <p class="c9"><span class="c1">First pass</span></p>
    <ol class="c10 lst-kix_6xitzsl51yaz-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Raster scan data</span></li>
        <li class="c7 li-bullet-0"><span class="c1">If element not bg, then get neighbour elements</span></li>
        <li class="c7 li-bullet-0"><span class="c1">No neighbours? Uniquely label current element</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Otherwise find neighbour with smallest label, assign current
                element</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Store equivalence between neighbouring labels</span></li>
    </ol>
    <p class="c9"><span class="c1">Second pass</span></p>
    <ol class="c10 lst-kix_s7lru4v3amf7-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Raster scan again</span></li>
        <li class="c7 li-bullet-0"><span class="c1">If element not bg, then relabel element with lowest equivalent
                label</span></li>
    </ol>
    <h3 class="c22" id="h.wy4sy56pq33z"><span class="c26 c21">Lec 5</span></h3>
    <p class="c9"><span>Basic </span><span class="c5">shape description</span><span>&nbsp;involves extracting
        </span><span class="c5">characteristic </span><span>features that describe the shape of a </span><span
            class="c5">connected component</span><span>. Shape descriptors can be used together with </span><span
            class="c5">machine learning</span><span>, or </span><span class="c5">manually defined
            models</span><span>&nbsp;to </span><span class="c5">classify </span><span>shapes into different classes; a
            common example of this is classifying shapes into letters of the </span><span class="c5">alphabet
        </span><span>in order to achieve optical character recognition. Statistical shape models describe how the shape
            of an object (or set of objects) can change (through internal movement and/or through changes in pose). In
            addition to describing shapes, statistical shape models can be used to find instances of a shape in an
            image.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_p2ht2fuhkc6t-0 start">
        <li class="c7 li-bullet-0"><span>Many different ways to </span><span class="c5">describe </span><span>the
            </span><span class="c5">shape </span><span>of c</span><span class="c5">onnected components</span><span>, the
                choice depends on </span><span class="c15 c5">required invariance</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Multiple shapes</span><span>&nbsp;can efficiently be represented by
                a </span><span class="c5">RAG</span><span>, very </span><span class="c15 c5">robust</span></li>
        <li class="c7 li-bullet-0"><span>Point distribution models apply </span><span class="c5">PCA </span><span>to x-y
                coordinate pairs across multiple images to produce a </span><span class="c5">low-dimensional parametric
                model</span></li>
    </ul>
    <ul class="c10 lst-kix_p2ht2fuhkc6t-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">ASMs/CLMs</span><span class="c1">&nbsp;also model local
                appearance, and can use this to optimise the fit of the model parameter to match an image.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_87q4v461o7lq-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Scalar features </span><span class="c1">(specifically of connected
                components)</span></li>
    </ul>
    <ul class="c10 lst-kix_87q4v461o7lq-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c15 c5">Area</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Perimeter </span><span class="c1">length</span></li>
    </ul>
    <ul class="c10 lst-kix_87q4v461o7lq-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Inner border</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Outer border</span></li>
        <li class="c9 c12 li-bullet-0"><span>Approximated by: </span><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 414.00px; height: 66.00px;"><img
                    alt="" src="assets/computer-vision/image151.png"
                    style="width: 414.00px; height: 66.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_87q4v461o7lq-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Compactness </span><span class="c1">- ratio of area to perimeter
                squared:</span></li>
    </ul>
    <ul class="c10 lst-kix_87q4v461o7lq-2 start">
        <li class="c9 c12 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 171.00px; height: 69.00px;"><img
                    alt="" src="assets/computer-vision/image304.png"
                    style="width: 171.00px; height: 69.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_87q4v461o7lq-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Irregularity </span><span>(</span><span
                class="c5">dispersion</span><span class="c1">) - ratio of major chord length to area.</span></li>
    </ul>
    <ul class="c10 lst-kix_87q4v461o7lq-2 start">
        <li class="c9 c12 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 346.00px; height: 67.00px;"><img
                    alt="" src="assets/computer-vision/image237.png"
                    style="width: 346.00px; height: 67.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">x and y bar are coordinates of centroid.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_881wgvjofyol-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Moments </span><span class="c1">- describe distribution of pixels in
                a shape (connected component)</span></li>
        <li class="c7 li-bullet-0"><span>2D Cartesian moment, order </span><span class="c6">p</span><span>&nbsp;and
            </span><span class="c6">q</span><span class="c1">:</span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 350.00px; height: 71.00px;"><img
                    alt="" src="assets/computer-vision/image212.png"
                    style="width: 350.00px; height: 71.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-0">
        <li class="c7 li-bullet-0"><span class="c1">Connected component simplifies to:</span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 180.00px; height: 61.00px;"><img
                    alt="" src="assets/computer-vision/image267.png"
                    style="width: 180.00px; height: 61.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-0">
        <li class="c7 li-bullet-0"><span class="c5">Zero order moment</span><span>&nbsp;of connected component
            </span><span class="c6">m</span><span class="c42 c6">00</span><span class="c6">&nbsp;</span><span>is just
                the </span><span class="c5">area</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Centre of mass is (centroid):</span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 203.00px; height: 63.00px;"><img
                    alt="" src="assets/computer-vision/image193.png"
                    style="width: 203.00px; height: 63.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_881wgvjofyol-0">
        <li class="c7 li-bullet-0"><span class="c5">Central Moments </span><span class="c1">- translation invariant,
                compute about the centroid</span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 326.00px; height: 58.00px;"><img
                    alt="" src="assets/computer-vision/image208.png"
                    style="width: 326.00px; height: 64.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_881wgvjofyol-0">
        <li class="c7 li-bullet-0"><span class="c6">&mu;</span><span class="c42 c6">10 </span><span>&nbsp;and
            </span><span class="c6">&mu;</span><span class="c42 c6">10</span><span class="c6">&nbsp;</span><span>both
                equal 0, so give no information, but higher order do.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ljd0f1y1bemo-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Normalised central moment </span><span class="c1">both translation
                and scale invariant:</span></li>
    </ul>
    <ul class="c10 lst-kix_ljd0f1y1bemo-1 start">
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 346.00px; height: 67.00px;"><img
                    alt="" src="assets/computer-vision/image142.png"
                    style="width: 346.00px; height: 67.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_pdl334eemon7-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Chain codes </span><span class="c1">- encode boundary of object,
                step around object and note down direction of each step, either 4 or 8 directions.</span></li>
    </ul>
    <ul class="c10 lst-kix_pdl334eemon7-1 start">
        <li class="c9 c16 li-bullet-0"><span>Rotating the sequence so it is the smallest integer, makes it </span><span
                class="c5">start position invariant</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Rotation invariance</span><span class="c1">&nbsp;achieved by
                storing difference between consecutive numbers.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Scale invariance </span><span class="c1">theoretically by
                resampling shape, usually doesn&rsquo;t work well in practice.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Used to computer </span><span class="c5">area</span><span>, </span><span
                class="c5">perimeter</span><span>&nbsp;and </span><span class="c5">moments</span><span
                class="c1">&nbsp;directly!</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Not good for shape matching due to</span></li>
    </ul>
    <ul class="c10 lst-kix_pdl334eemon7-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Noise, resampling, problem generating good similarity/distance
                metrics.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_h8ro5kbj4bg8-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Fourier descriptors </span><span class="c1">- encode shape
                information by decomposing boundary into set of frequency components.</span></li>
        <li class="c7 li-bullet-0"><span>Two main steps, choose carefully to make very</span><span
                class="c5">&nbsp;invariant boundary descriptors</span><span class="c1">: </span></li>
    </ul>
    <ul class="c10 lst-kix_h8ro5kbj4bg8-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Define representation of curve (boundary)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Expanding representation using Fourier theory</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_4v0gryleojei-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Region Adjacency Graphs (RAG)</span><span>&nbsp;- (trees)
            </span><span class="c5">describe layout</span><span class="c1">&nbsp;of connected components relative to
                each other.</span></li>
    </ul>
    <ul class="c10 lst-kix_4v0gryleojei-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Nodes correspond to components and connected if shape
                border</span></li>
    </ul>
    <ul class="c10 lst-kix_4v0gryleojei-0">
        <li class="c7 li-bullet-0"><span class="c1">Invariant to: distortion (including rotation, scale, translation,
                non-linear transformations)</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Not invariant to</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_fo4ttmlhnmsr-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Point Distribution Models (PDM) </span><span class="c1">- Like
                eigenfaces, applies similar process to set of points representing a shape</span></li>
    </ul>
    <ul class="c10 lst-kix_fo4ttmlhnmsr-1 start">
        <li class="c9 c16 li-bullet-0"><span>Corresponding 2D points manually created from set of </span><span
                class="c6">N</span><span class="c1">&nbsp;training face images</span></li>
    </ul>
    <ul class="c10 lst-kix_fo4ttmlhnmsr-2 start">
        <li class="c9 c12 li-bullet-0"><span>Number of points fixed at </span><span class="c6">M</span></li>
    </ul>
    <ul class="c10 lst-kix_fo4ttmlhnmsr-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Iterative process called Generalized Procrustes Analysis, align
                points</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Mean shape created</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Shape matrix created</span></li>
    </ul>
    <ul class="c10 lst-kix_fo4ttmlhnmsr-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Each column stores information on how the x or y ordinate of a
                point on a face can change.</span></li>
    </ul>
    <ul class="c10 lst-kix_fo4ttmlhnmsr-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">PCA applied to matrix.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_rd9k3ml41qan-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Active Shape Models (ASM) / Constrained Local Models (CLM)
            </span><span class="c1">- take PDM further, incorporate what image should look like around each
                point.</span></li>
    </ul>
    <ul class="c10 lst-kix_rd9k3ml41qan-1 start">
        <li class="c9 c16 li-bullet-0"><span>Small pixel patch about each point - is </span><span
                class="c6">template</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Addition of data allows model to be better fitted to unseen
                image</span></li>
    </ul>
    <ul class="c10 lst-kix_rd9k3ml41qan-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Each point tried to move to local optimum while PDM contains all
                points </span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_vbg0edvdvuxn-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Active Appearance Models </span><span class="c1">- same thing as
                ASMs/CLMs, but instead of local features, try to jointly optimise global appearance of face against
                PDM.</span></li>
    </ul>
    <h3 class="c22" id="h.hoz14wvvq984"><span>Lec 6</span></h3>
    <p class="c9"><span>The detection of </span><span class="c5">local interest points</span><span>&nbsp;that are
        </span><span class="c5">stable</span><span>&nbsp;under varying imaging conditions has a huge number of
        </span><span class="c5">applications</span><span>&nbsp;in computer vision. Research in this area goes back as
            far as the 1960s and 70s. The </span><span class="c5">Harris and Stephens corner detection technique
        </span><span>developed in 1988 is a classic example of a detection technique with </span><span
            class="c5">impressive robustness</span><span>. A related problem to the detection of interest points is the
        </span><span class="c5">problem of scale</span><span>&nbsp;(the size at which an object appears in an image).
        </span><span class="c5">Scale space theory</span><span>&nbsp;allows interest point techniques to be developed
            that are</span><span class="c5">&nbsp;invariant to</span><span>&nbsp;changes in</span><span
            class="c5">&nbsp;scale</span><span>&nbsp;(i.e. the object moving further away). The </span><span
            class="c5">Difference-of-Gaussian</span><span>&nbsp;</span><span class="c5">blob detector</span><span
            class="c1">&nbsp;is an example of such a scale-space blob detection technique.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_pyfo5yblmhmd-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Interest points</span><span class="c1">&nbsp;have loads of
                applications in computer vision.</span></li>
    </ul>
    <ul class="c10 lst-kix_pyfo5yblmhmd-1 start">
        <li class="c9 c16 li-bullet-0"><span>They need to be r</span><span class="c5">obustly detected</span><span
                class="c1">, and invariant to rotation, lighting change etc. (sufficient but not too much texture
                variation in local neighbourhood)</span></li>
    </ul>
    <ul class="c10 lst-kix_pyfo5yblmhmd-0">
        <li class="c7 li-bullet-0"><span>There are 2 types: </span><span class="c5">corners </span><span>and
            </span><span class="c15 c5">blobs</span></li>
    </ul>
    <ul class="c10 lst-kix_pyfo5yblmhmd-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Harris &amp; Stephens </span><span>is common </span><span
                class="c15 c5">corner detector</span></li>
        <li class="c9 c16 li-bullet-0"><span>Finding </span><span class="c5">extrema </span><span>in a </span><span
                class="c5">multi scale DoG pyramid</span><span>&nbsp;provides robust </span><span class="c15 c5">blob
                detector</span></li>
    </ul>
    <ul class="c10 lst-kix_pyfo5yblmhmd-0">
        <li class="c7 li-bullet-0"><span class="c5">Scale space theory</span><span class="c1">&nbsp;allows us to find
                features (corners and blobs) of different sizes</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_wrnocb2kajhe-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Harris &amp; Stephens Corner Detector </span><span class="c1">-
                classic algorithm. </span></li>
    </ul>
    <ul class="c10 lst-kix_wrnocb2kajhe-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Considers the brightness of a small patch of image.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Then when you slightly shift that patch then</span></li>
    </ul>
    <ul class="c10 lst-kix_wrnocb2kajhe-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">If brightness same, original patch not stable point</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">If brightness changes a lot, original patch stable</span></li>
    </ul>
    <ul class="c10 lst-kix_wrnocb2kajhe-0">
        <li class="c7 li-bullet-0"><span class="c1">Computing the weighted sum-squared difference of window and shifted
                window:</span></li>
    </ul>
    <ul class="c10 lst-kix_wrnocb2kajhe-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Point (x,y) and shift (&#8710;x, &#8710;y):</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.00px; height: 74.00px;"><img
                alt="" src="assets/computer-vision/image229.png"
                style="width: 588.00px; height: 74.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_uf9umkjky4wf-0 start">
        <li class="c7 li-bullet-0"><span class="c13 c6 c5">This equation can be &ldquo;processed&rdquo; to make:</span>
        </li>
    </ul>
    <p class="c3"><span class="c13 c5 c36"></span></p>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 104.00px;"><img
                alt="" src="assets/computer-vision/image101.png"
                style="width: 602.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_ksz7we2cg3zr-0 start">
        <li class="c7 li-bullet-0"><span>Square symmetric matrix </span><span class="c5">M</span><span>&nbsp;concisely
                describes the </span><span class="c6">shape</span><span>&nbsp;of the local weighted difference
                function.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 198.50px; height: 59.99px;"><img
                alt="" src="assets/computer-vision/image323.png"
                style="width: 198.50px; height: 59.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_ksz7we2cg3zr-0">
        <li class="c7 li-bullet-0"><span class="c1">Basically encoding of image derivatives in the x,y and xy
                directions.</span></li>
        <li class="c7 li-bullet-0"><span>Called the </span><span class="c5">second moment matrix</span><span>&nbsp;aka
            </span><span class="c5">structure tensor</span><span class="c1">.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_fnjjgmkykjks-0 start">
        <li class="c7 li-bullet-0"><span>You can use the </span><span class="c5">absolute values</span><span>&nbsp;of
                the </span><span class="c5">eigenvalues </span><span class="c1">directly (explained somewhere
                else)</span></li>
        <li class="c7 li-bullet-0"><span>But Harris &amp; Stephens came up with a scheme that </span><span
                class="c5">avoids explicitly computing the Eigendecomposition</span><span>&nbsp;by formulating a
            </span><span class="c5">corner response function</span><span>&nbsp;(R(x, y) in terms of the determinant and
                trace of </span><span class="c5">M</span><span class="c1">:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 568.00px; height: 91.00px;"><img
                    alt="" src="assets/computer-vision/image224.png"
                    style="width: 568.00px; height: 91.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c7 li-bullet-0"><span class="c1">K usually 0.04 - 0.06</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Value of R:</span></li>
    </ul>
    <ul class="c10 lst-kix_fnjjgmkykjks-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">R &gt; 0: Corner</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">R &lt; 0: edge</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">| R | = small: flat</span></li>
    </ul>
    <ul class="c10 lst-kix_fnjjgmkykjks-0">
        <li class="c7 li-bullet-0"><span>Actually find corners, </span><span class="c5">compute R</span><span
                class="c1">&nbsp;for each pixel, keep only ones over threshold. </span></li>
        <li class="c7 li-bullet-0"><span class="c1">Filter out points not local maxima of R within small window (8
                neighbouring pixels)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_qgkab8v1hhw2-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Scale space theory </span><span>- formal framework for handling
                images at different scales by represent image as family of </span><span class="c5">smoothed
            </span><span>images </span><span class="c5">parameterized </span><span>by the size of the </span><span
                class="c5">smoothing kernel</span><span class="c1">&nbsp;used for suppressing fine detail.</span></li>
    </ul>
    <ul class="c10 lst-kix_qgkab8v1hhw2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Scale parameter: t, image structure of spatial size smaller than
                ~sqrt(t) mostly smoothed away in scale-space level at scale t.</span></li>
    </ul>
    <ul class="c10 lst-kix_qgkab8v1hhw2-0">
        <li class="c7 li-bullet-0"><span class="c5">Gaussian Scale Space</span><span class="c1">&nbsp;- smoothing
                function is Gaussian kernel</span></li>
    </ul>
    <ul class="c10 lst-kix_qgkab8v1hhw2-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Formally the Gaussian scale space of an image f(x, y) is the
                family of derived signals L(x, y; t) defined by the convolution of the image with the 2D Gaussian
                kernel:</span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 328.00px; height: 127.00px;"><img
                    alt="" src="assets/computer-vision/image210.png"
                    style="width: 328.00px; height: 127.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_qgkab8v1hhw2-0">
        <li class="c7 li-bullet-0"><span class="c1">Semicolon implies convolution only performed over variables x and
                y.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Definition valid for all t &ge; 0</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Gaussian Pyramids.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ja2c53vg4ujo-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Multiscale Harris &amp; Stephens </span><span class="c1">- define
                Gaussian scale space with fixed set of scales and compute corner response function at every pixel of
                each scale, keep only those with response function above threshold.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_7orv2lfhynus-0 start">
        <li class="c7 li-bullet-0"><span class="c15 c5">Local extrema in DoG Scale Space</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Laplacian of Gaussian</span><span>&nbsp;(LoG) is the 2</span><span
                class="c66">nd</span><span>&nbsp;differential of a Gaussian </span><span class="c5">convolved
            </span><span class="c1">with an image (the kernel is shaped like a Mexican hat).</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Zero-crossings</span><span>&nbsp;of function, get </span><span
                class="c15 c5">Marr-Hildreth edge detector.</span></li>
        <li class="c7 li-bullet-0"><span>By finding local max and min, you get </span><span class="c5">blob</span><span
                class="c1">&nbsp;detector.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Very useful property: </span><span>if blob is detected at
                (x</span><span class="c42">0</span><span>,y</span><span class="c42">0</span><span>; t</span><span
                class="c42">0</span><span>) then in the scaled image (factor of s) same blob detected at (sx</span><span
                class="c42">0</span><span>,sy</span><span class="c42">0</span><span>; s</span><span
                class="c66">2</span><span>t</span><span class="c42">0</span><span class="c1">)</span></li>
        <li class="c7 li-bullet-0"><span>In practice, </span><span class="c5">DoG approximation</span><span
                class="c1">&nbsp;used instead of LoG.</span></li>
    </ul>
    <ul class="c10 lst-kix_7orv2lfhynus-1 start">
        <li class="c9 c16 li-bullet-0"><span>Build gaussian scale space, </span><span class="c5">subtract
            </span><span>adjacent scales to produce DoG scale space to then </span><span class="c5">search for
                extrema</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_7orv2lfhynus-0">
        <li class="c7 li-bullet-0"><span>Every time you double scale, you can half image size, pyramid can be
                constructed.</span></li>
    </ul>
    <h3 class="c22" id="h.85lvrv7skst6"><span class="c26 c21">Lec 7</span></h3>
    <p class="c9"><span>How to </span><span class="c5">extract local features</span><span>&nbsp;from these </span><span
            class="c5">interest points</span><span>. A number of techniques have been proposed in the past in order to
            extract robust local descriptors, starting from </span><span class="c5">simple pixel
            histograms</span><span>, through to advanced features like the </span><span class="c5">SIFT
            descriptor</span><span>, which </span><span class="c5">encode weighted local image gradients</span><span>.
            Once these descriptors have been extracted, they can be used for </span><span class="c5">image
            matching</span><span>.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_poyk0gdf0nwc-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Features extracted around interest points have lots of practical
                uses in computer vision.</span></li>
        <li class="c7 li-bullet-0"><span>Matching scenarios basically fall into </span><span class="c5">two
                categories</span><span class="c1">:</span></li>
    </ul>
    <ul class="c10 lst-kix_poyk0gdf0nwc-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Narrow-baseline</span><span class="c1">&nbsp;where the
                difference in image is slight</span></li>
    </ul>
    <ul class="c10 lst-kix_poyk0gdf0nwc-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c5">Local image templates </span><span class="c1">are often suitable
                descriptors</span></li>
    </ul>
    <ul class="c10 lst-kix_poyk0gdf0nwc-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Wide-baseline </span><span class="c1">where there are bigger
                differences in pose</span></li>
    </ul>
    <ul class="c10 lst-kix_poyk0gdf0nwc-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c5">Gradient histogram</span><span class="c1">&nbsp;descriptors are
                good here</span></li>
    </ul>
    <ul class="c10 lst-kix_poyk0gdf0nwc-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c15 c5">Especially SIFT!</span></li>
    </ul>
    <p class="c3"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_5pfdllckvtps-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Local feature matching basics </span><span class="c1">- find all
                local features in one images that have correspondences in another image.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Applications: image retrieval, 3D reconstruction, panoramas,
                tracking&hellip;.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Stereo vision, 2 concepts:</span></li>
    </ul>
    <ul class="c10 lst-kix_5pfdllckvtps-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Narrow-baseline</span><span class="c1">&nbsp;stereo is where 2
                images very similar - local features moved by few pixels.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Wide-baseline </span><span class="c1">stereo where differences
                much bigger.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_jbhbs1z9h01x-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Robust local description </span><span>- type of descriptor
            </span><span class="c5">dependant </span><span class="c1">on task.</span></li>
    </ul>
    <ul class="c10 lst-kix_jbhbs1z9h01x-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Narrow-baseline</span><span class="c1">, rotation not issue,
                descriptiveness not too important, lighting not changed much.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Wider baselines</span><span class="c1">, local descriptors with
                attributes:</span></li>
    </ul>
    <ul class="c10 lst-kix_jbhbs1z9h01x-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c5">Robust </span><span>to uniform </span><span class="c5">intensity
                changes</span><span class="c1">&nbsp;in pixel values around interest point.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Invariance </span><span>to </span><span
                class="c5">orientation</span><span class="c1">, features not change as image rotated.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Robustness </span><span class="c1">to placing of interest point
                by few pixels</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Descriptors for visually differing local regions be unique and
                far apart in feature space.</span></li>
    </ul>
    <ul class="c10 lst-kix_jbhbs1z9h01x-0">
        <li class="c7 li-bullet-0"><span class="c5">Matching by correlation (template matching)</span><span
                class="c1">&nbsp;- rectangle region around interest point, use pixel values directly.</span></li>
    </ul>
    <ul class="c10 lst-kix_jbhbs1z9h01x-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Sum-Squared-Difference </span><span class="c1">perform basic
                matching.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Work well with small differences, but not in
                wide-baseline.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_9skgfmdd9l6-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Local Intensity Histograms </span><span class="c1">- histogram of
                pixel intensities of local region.</span></li>
    </ul>
    <ul class="c10 lst-kix_9skgfmdd9l6-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Circular</span><span>&nbsp;window, (mostly) r</span><span
                class="c5">otation invariant</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Can use </span><span class="c5">Gaussian weighting</span><span
                class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Not invariant to illumination changes.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Histograms not very distinctive :(</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_bgdtj0nip89y-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Local Gradient Histograms</span><span class="c1">&nbsp;- encode
                gradient directions within a window</span></li>
    </ul>
    <ul class="c10 lst-kix_bgdtj0nip89y-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Easy to compute in x and y directions.</span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 187.00px; height: 56.00px;"><img
                    alt="" src="assets/computer-vision/image331.png"
                    style="width: 187.00px; height: 56.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Magnitude of gradient:</span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 218.00px; height: 80.00px;"><img
                    alt="" src="assets/computer-vision/image260.png"
                    style="width: 218.00px; height: 80.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_bgdtj0nip89y-0">
        <li class="c7 li-bullet-0"><span class="c1">Gaussian weighting can be applied</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Invariant to uniform intensity changes.</span></li>
        <li class="c7 li-bullet-0"><span class="c15 c5">Not rotation invariant!</span></li>
    </ul>
    <ul class="c10 lst-kix_bgdtj0nip89y-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Have to robustly compute &ldquo;dominant orientation&rdquo;
                subtract from pixels orientation to be rotation invariant.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_581rfzye1yp-0 start">
        <li class="c7 li-bullet-0"><span class="c5">The SIFT Feature</span><span>&nbsp;- builds </span><span
                class="c5">spatial array</span><span>&nbsp;of </span><span class="c5">orientation-magnitude
                histograms</span><span class="c1">&nbsp;about the interest point.</span></li>
    </ul>
    <ul class="c10 lst-kix_581rfzye1yp-1 start">
        <li class="c9 c16 li-bullet-0"><span>Pixel contributions </span><span class="c5">linearly
                interpolated</span><span>&nbsp;across nearest spatial bins </span><span class="c15 c5">avoid
                discontinuities</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Magnitudes weighted </span><span>by </span><span
                class="c5">Gaussian </span><span class="c1">centred on interest point</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Typical: 4x4 spatial grid, 8 orientation bins; 128 dimensional
                feature vector.</span></li>
    </ul>
    <ul class="c10 lst-kix_581rfzye1yp-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Very descriptive and discriminative feature</span></li>
    </ul>
    <ul class="c10 lst-kix_581rfzye1yp-0">
        <li class="c7 li-bullet-0"><span class="c5">Matching SIFT Features </span><span class="c1">- often compared
                using Euclidean distance</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Take each feature from first image and find closest in second
                image.</span></li>
    </ul>
    <ul class="c10 lst-kix_581rfzye1yp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Threshold </span><span class="c1">to stop poor matches</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c1">However, tends to result in lots of incorrect matches, not
                robust to big viewpoint changes.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Better: take each feature from the first image, find 2 closest in second
                image, only form match if ratio of distances between closest and second closest is less than threshold
                (typically 0.8)</span></li>
    </ul>
    <h3 class="c22" id="h.uy6r4e69lw72"><span class="c26 c21">Lec 8</span></h3>
    <p class="c9"><span>When comparing two images by matching local feature, we need to</span><span
            class="c5">&nbsp;eliminate mismatches</span><span>. By applying </span><span class="c5">geometric
            constraints</span><span>&nbsp;to the problem of finding corresponding interest points between pairs of
            images, it is possible to both reduce the number of mismatches and potentially </span><span class="c5">learn
            a geometric mapping</span><span class="c1">&nbsp;between the two images. Amongst many other applications,
            these transforms can be used to build panoramas from multiple images. The presence of such a transform is a
            good indicator for a match between the two images, and is commonly used in object recognition and image
            retrieval applications.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_sa0rg8fry0dp-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Inconsistent</span><span>&nbsp;</span><span class="c5">local feature
                matches</span><span>&nbsp;can be removed by assuming some form of </span><span class="c5">constraint
            </span><span class="c1">holds between the two images</span></li>
    </ul>
    <ul class="c10 lst-kix_sa0rg8fry0dp-1 start">
        <li class="c9 c16 li-bullet-0"><span>This is usually a </span><span class="c15 c5">geometric mapping</span></li>
    </ul>
    <ul class="c10 lst-kix_sa0rg8fry0dp-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c5">Affine transform </span><span>or </span><span
                class="c15 c5">Homography</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Can be estimated by finding the least-squares solution of a set
                of simultaneous equations</span></li>
    </ul>
    <ul class="c10 lst-kix_sa0rg8fry0dp-1">
        <li class="c9 c16 li-bullet-0"><span>Robust methods such as </span><span class="c5">RANSAC </span><span>allow
            </span><span class="c5">inliers </span><span>and </span><span class="c5">outliers </span><span class="c1">to
                be determined whilst learning the mapping</span></li>
    </ul>
    <ul class="c10 lst-kix_sa0rg8fry0dp-0">
        <li class="c7 li-bullet-0"><span>Interest point matching is </span><span class="c15 c5">slow&hellip;</span></li>
    </ul>
    <ul class="c10 lst-kix_sa0rg8fry0dp-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">K-D Trees</span><span>&nbsp;and </span><span class="c5">Hashing
            </span><span class="c1">can help</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_xiasgn97ghc6-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Applying constraints to matching </span><span class="c1">- even best
                local features can be mismatched</span></li>
    </ul>
    <ul class="c10 lst-kix_xiasgn97ghc6-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Tradeoffs in distinctiveness:</span></li>
    </ul>
    <ul class="c10 lst-kix_xiasgn97ghc6-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Can be too distinctive or not enough, not match with subtle
                variations or not match at all</span></li>
    </ul>
    <ul class="c10 lst-kix_xiasgn97ghc6-1">
        <li class="c9 c16 li-bullet-0"><span>You can estimate which correspondences are </span><span class="c5">inliers
            </span><span>or </span><span class="c15 c5">outliers</span></li>
    </ul>
    <p class="c3"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_s94ixjaw9vkw-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Geometric mappings </span><span class="c1">- assume object is flat,
                then can search for geometric mapping satisfied by correct corresponding points.</span></li>
    </ul>
    <ul class="c10 lst-kix_s94ixjaw9vkw-1 start">
        <li class="c9 c16 li-bullet-0"><span>It is a </span><span class="c5">transform function</span><span
                class="c1">&nbsp;maps x,y coords from 1 image to other</span></li>
    </ul>
    <ul class="c10 lst-kix_s94ixjaw9vkw-2 start">
        <li class="c9 c12 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 74.00px; height: 31.00px;"><img
                    alt="" src="assets/computer-vision/image297.png"
                    style="width: 74.00px; height: 31.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">T </span><span class="c1">is transform matrix</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">x,y column vectors for coordinates</span></li>
    </ul>
    <ul class="c10 lst-kix_s94ixjaw9vkw-0">
        <li class="c7 li-bullet-0"><span class="c5">Affine Transform </span><span class="c1">- combination of
                translation, scaling, aspect ratio, rotation and skewing.</span></li>
        <li class="c7 li-bullet-0"><span>Affine transforms always </span><span class="c15 c5">preserve parallel
                lines</span></li>
    </ul>
    <ul class="c10 lst-kix_s94ixjaw9vkw-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Standard 2D transform: </span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 151.00px; height: 39.00px;"><img
                    alt="" src="assets/computer-vision/image202.png"
                    style="width: 151.00px; height: 39.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">A</span><span class="c1">&nbsp;is 2x2 transform matrix encodes
                scale, rotation, skew, and b is translation vector.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Single matrix multiplication (extra dimension of fixed value
                1):</span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 253.00px; height: 76.00px;"><img
                    alt="" src="assets/computer-vision/image282.png"
                    style="width: 253.00px; height: 76.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">3x3 matrix:</span></li>
        <li class="c9 c16 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 245.00px; height: 90.00px;"><img
                    alt="" src="assets/computer-vision/image225.png"
                    style="width: 245.00px; height: 90.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
        <li class="c9 c16 li-bullet-0"><span>Said to have </span><span class="c5">6 degrees of freedom</span><span
                class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_s94ixjaw9vkw-0">
        <li class="c7 li-bullet-0"><span class="c1">Doesn&rsquo;t allow for perspective effects, as it preserves
                parallel lines</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-0 start">
        <li class="c7 li-bullet-0"><span class="c5">2D projective transform </span><span>or</span><span
                class="c15 c5">&nbsp;(Planar) Homography:</span></li>
        <li class="c7 li-bullet-0"><span
                style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 380.00px; height: 85.00px;"><img
                    alt="" src="assets/computer-vision/image293.png"
                    style="width: 380.00px; height: 85.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                    title=""></span></li>
    </ul>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-1 start">
        <li class="c9 c16 li-bullet-0"><span>Normalization by </span><span class="c6">w</span><span
                class="c1">&nbsp;because non-linear.</span></li>
    </ul>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-2 start">
        <li class="c9 c12 li-bullet-0"><span>The vector [wx&rsquo;,wy&rsquo;,w]</span><span
                class="c66">T</span><span>&nbsp;is called a </span><span class="c5">homogeneous coordinate</span><span
                class="c1">.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Deal with transform as matrix</span></li>
    </ul>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">a-f are affine parameters.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">g-h define keystone distortions, make originally parallel lines
                come together after transform.</span></li>
    </ul>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-0">
        <li class="c7 li-bullet-0"><span>Solve set of homogeneous linear equations for </span><span class="c5">T</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-1 start">
        <li class="c9 c16 li-bullet-0"><span>Common to compute </span><span class="c5">least-squares</span><span
                class="c1">&nbsp;estimate of transform matrix.</span></li>
    </ul>
    <ul class="c10 lst-kix_sjdbsx5sdf9l-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">It minimises the sum-squared error in prediction.</span></li>
        <li class="c9 c12 li-bullet-0"><span>Error of single point called </span><span class="c5">residual</span><span
                class="c1">; difference between predicted and observed value.</span></li>
    </ul>
    <p class="c3 c50"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_f1xo0tkiafux-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Robust estimation </span><span class="c1">- least squares problem
                with noise.</span></li>
    </ul>
    <ul class="c10 lst-kix_f1xo0tkiafux-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Mismatches can throw off estimated transform</span></li>
    </ul>
    <ul class="c10 lst-kix_f1xo0tkiafux-0">
        <li class="c7 li-bullet-0"><span class="c1">How to determine inliners, we need them for better transform
                estimate</span></li>
        <li class="c7 li-bullet-0"><span>Number of algorithms one is </span><span class="c15 c5">RANSAC</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Random Sample Consensus</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Algorithm:</span></li>
    </ul>
    <ul class="c10 lst-kix_f1xo0tkiafux-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Assume: </span><span class="c1">M data items required to
                estimate model T, N data items in total</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ol class="c10 lst-kix_sn1k71h845vf-0 start" start="1">
        <li class="c7 li-bullet-0"><span class="c1">Select M data items at random</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Estimate model T</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Find how many of the N data items fit T within tolerance tol, call
                this K. points that have an absolute residual less than tol are the inliers; the other points are
                outliers.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">If K is large enough, either accept T, or compute least-squares
                estimate using all inliers, and exit with success.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Repeat steps 1..4 nIterations items</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Fail - no good T fit of data</span></li>
    </ol>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ov8fbgyydwqp-0 start">
        <li class="c7 li-bullet-0"><span class="c1">RANSAC picks some pairs of points randomly, estimates
                transform.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">If enough inliers, algorithm stops, transform
                re-estimated&hellip;&hellip;</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_qt1k2mli141a-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Improving matching speed </span><span class="c1">- biggest problem
                is speed.</span></li>
    </ul>
    <ul class="c10 lst-kix_qt1k2mli141a-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Brute-force of 128-D SIFT takes long.</span></li>
    </ul>
    <ul class="c10 lst-kix_qt1k2mli141a-0">
        <li class="c7 li-bullet-0"><span>Ways to speed it up: </span><span class="c15 c5">K-D Trees</span></li>
    </ul>
    <ul class="c10 lst-kix_qt1k2mli141a-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Binary tree structure</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Each node splits specific dimension of space in two</span></li>
        <li class="c9 c16 li-bullet-0"><span>Leaf nodes store number of points corresponding to the points that have
                made it down the tree to that point</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Fast nearest neighbour search done&hellip;&hellip;.</span></li>
    </ul>
    <ul class="c10 lst-kix_qt1k2mli141a-0">
        <li class="c7 li-bullet-0"><span class="c15 c5">Hashing</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Locality Sensitive hashing Functions, vectors that are spatially
                similar, similar hash codes.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Sketching </span><span>- binary string encodings for features,
                compared more efficiently</span></li>
    </ul>
    <h3 class="c22" id="h.ywv90kepaecj"><span class="c26 c21">Lec 9</span></h3>
    <p class="c9"><span class="c5">Content-based image retrieval</span><span>&nbsp;(</span><span
            class="c5">CBIR</span><span>) are systems that can </span><span class="c5">search </span><span>for images
            with an image as the </span><span class="c5">query</span><span>. Research on CBIR systems started in the
            early 90&rsquo;s, but it is only more recently with ubiquitous mobile computing and applications like Google
            Goggles that the technology has matured. We&rsquo;ve seen how (</span><span class="c5">local</span><span>)
        </span><span class="c5">descriptors </span><span>can be used to find </span><span class="c5">matching objects
        </span><span>within images, but we&rsquo;ve also seen that the matching process is rather </span><span
            class="c5">computationally expensive</span><span class="c1">. </span></p>
    <p class="c9"><span>For CBIR applications we need to be able to search datasets of </span><span class="c5">millions
        </span><span>of images almost </span><span class="c5">instantaneously</span><span>. In the field of </span><span
            class="c5">textual document search</span><span>, techniques to efficiently index and efficiently search
            massive datasets of text documents are well understood. One of the biggest advances in CBIR has been to
            apply these textual indexing techniques to the image domain by extracting </span><span class="c5">bags of
            visual words</span><span>&nbsp;from images and </span><span class="c5">indexing </span><span
            class="c1">these.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_hsodxml48zeq-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Effective </span><span>and </span><span class="c5">efficient
            </span><span>text search can be achieved with </span><span class="c5">bags of words</span><span>, the
            </span><span class="c5">vector-space model</span><span>&nbsp;and </span><span class="c5">inverted
                indexes</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Vector-quantisation </span><span>can be applied to local features,
                making them into </span><span class="c5">visual words</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_hsodxml48zeq-1 start">
        <li class="c9 c16 li-bullet-0"><span>Then you can apply all the </span><span class="c5">same
                techniques</span><span class="c1">&nbsp;used for text to make efficient retrieval systems</span></li>
    </ul>
    <ul class="c10 lst-kix_hsodxml48zeq-2 start">
        <li class="c9 c12 li-bullet-0"><span>This is a good way of making highly scalable, effective and efficient
            </span><span class="c15 c5">content-based image retrieval systems</span></li>
    </ul>
    <p class="c3"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_bq7yy8un2rdx-0 start">
        <li class="c7 li-bullet-0"><span>Most text-search systems represent text as a </span><span class="c5">bag of
                words</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-1 start">
        <li class="c9 c16 li-bullet-0"><span>A </span><span class="c5">bag </span><span>is an unordered data structure
                like a </span><span class="c5">set</span><span class="c1">, but can have elements multiple times.</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Create bag from text document:</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Break into words (tokenisation)</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Process words to reduce variability (eg get rid of
                &ldquo;ing&rdquo; at end)</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Remove common words (like &ldquo;the&rdquo;)</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-0">
        <li class="c7 li-bullet-0"><span class="c5">Vector-space model </span><span class="c1">- text documents
                represented by vectors</span></li>
        <li class="c7 li-bullet-0"><span>Vectors contain counts of frequency of words in the </span><span
                class="c5">lexicon </span><span class="c1">(the set of all possible words)</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Histograms of word counts, </span><span>and they are
            </span><span class="c5">highly sparse</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-0">
        <li class="c7 li-bullet-0"><span class="c1">Searching:</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-1 start">
        <li class="c9 c16 li-bullet-0"><span>Query turned into </span><span class="c5">vector </span><span>form, ranked
                by </span><span class="c5">similarity</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Cosine similarity </span><span class="c1">often used, less
                affected by magnitude.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Many documents have 0 similarity.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Often cosine sim can be </span><span class="c15 c5">weighted</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-2 start">
        <li class="c9 c12 li-bullet-0"><span>Words that </span><span class="c5">appear a lot</span><span>&nbsp;in docs
                should have </span><span class="c15 c5">less weight</span></li>
        <li class="c9 c12 li-bullet-0"><span>Common weighting scheme: </span><span class="c5">Frequency-inverse document
                frequency </span><span class="c1">(tf-idf)</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-0">
        <li class="c7 li-bullet-0"><span>In practice vectors never made, BoW just indexed directly as </span><span
                class="c5">inverted index</span><span class="c1">.</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Map of words to postings lists.</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c5">Posting </span><span>is a </span><span
                class="c5">pair</span><span class="c1">&nbsp;containing document identifier and word count.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Only made if word count &gt; 1</span></li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-0">
        <li class="c7 li-bullet-0"><span class="c1">Can quickly find which docs a word occurs in, and how many.</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_bq7yy8un2rdx-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Really efficient computation.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_7qli1xkfv2ap-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Vector-quantisation </span><span>- lossy </span><span
                class="c5">data compression</span><span class="c1">&nbsp;technique</span></li>
        <li class="c7 li-bullet-0"><span class="c5">K-Means clustering </span><span>used to learn </span><span
                class="c5">fixed size set of representative vectors</span><span class="c1">.</span></li>
        <li class="c7 li-bullet-0"><span>Represent a vector by another approximate vector, draw from a </span><span
                class="c5">pool of vectors</span><span class="c1">. Each input vector assigned to &ldquo;closest&rdquo;
                vector from pool.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_re7fjyjjlcnj-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Bag of Visual Words (BoVW) </span><span class="c1">- apply text
                techniques to computer vision</span></li>
        <li class="c7 li-bullet-0"><span>A </span><span class="c5">visual word</span><span class="c1">&nbsp;is a local
                descriptor vector (e.g. SIFT vector) that has been vector quantised.</span></li>
    </ul>
    <ul class="c10 lst-kix_re7fjyjjlcnj-1 start">
        <li class="c9 c16 li-bullet-0"><span>Set of representative vectors is the </span><span class="c5">visual
                equivalent of the lexicon</span><span class="c1">&nbsp;(codebook)</span></li>
        <li class="c9 c16 li-bullet-0"><span>SIFT - each visual word represents a </span><span class="c5">prototypical
                pattern</span><span>&nbsp;of </span><span class="c15 c5">local image gradients</span></li>
    </ul>
    <ul class="c10 lst-kix_re7fjyjjlcnj-0">
        <li class="c7 li-bullet-0"><span>Set of local descriptors can be transformed to </span><span class="c5">fixed
                dimensionality histogram</span><span>&nbsp;by counting the number of </span><span
                class="c5">occurrences</span><span class="c1">&nbsp;of each representative vector.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ibsj8ff72v3p-0 start">
        <li class="c7 li-bullet-0"><span class="c5">BoVW Retrieval</span><span class="c1">&nbsp;- use same techniques
                for text retrieval.</span></li>
    </ul>
    <ul class="c10 lst-kix_ibsj8ff72v3p-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Visual words indexed directly, searched by cosine</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Important parameter: size of codebook.</span></li>
    </ul>
    <ul class="c10 lst-kix_ibsj8ff72v3p-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c1">Only works well efficiently if vectors sparse</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Ensure visual words distinctive to minimize mismatching</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_ibsj8ff72v3p-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">Implies you need large codebook&hellip; ~1 million
                typically</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">This is long.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">And expensive.</span></li>
    </ul>
    <ul class="c10 lst-kix_ibsj8ff72v3p-0">
        <li class="c7 li-bullet-0"><span class="c1">Overall process:</span></li>
    </ul>
    <ul class="c10 lst-kix_ibsj8ff72v3p-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Find interest points + extract local features from all
                images</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Learn codebook from sample of features</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Perform vector quantisation to assign each feature to a
                representative visual word</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Construct an inverted index</span></li>
    </ul>
    <h3 class="c22" id="h.w4m6ow72tili"><span class="c26 c21">Lec 10</span></h3>
    <p class="c9"><span>We&rsquo;ve looked at how </span><span class="c5">features </span><span>can be </span><span
            class="c5">extracted </span><span>from images, and how </span><span class="c5">supervised machine learning
            techniques</span><span>&nbsp;like </span><span class="c5">linear
            classifiers</span><span>&nbsp;and</span><span class="c5">&nbsp;k-nearest neighbours</span><span>&nbsp;can be
            used to train a computer vision system to predict a class for a particular feature input. Current research
            is looking at how we might make computers able to </span><span class="c5">see in the human
            sense</span><span>, fully understanding the content of a visual scene. The choice of feature for image
            classification is very important. We saw how a </span><span class="c5">Bag of Visual
            Words</span><span>&nbsp;(</span><span class="c5">BoVW</span><span>) representation was a </span><span
            class="c5">powerful technique </span><span>for image search. It turns out that </span><span class="c5">BoVWs
        </span><span>are very </span><span class="c5">useful </span><span>for use in </span><span class="c5">high
            performance image classification</span><span class="c1">.</span></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_ikm8mdm5rb23-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Object recognition</span><span>, </span><span class="c5">scene
                classification</span><span>&nbsp;and </span><span class="c5">automatic annotation</span><span
                class="c1">&nbsp;are all important tasks in computer vision.</span></li>
    </ul>
    <ul class="c10 lst-kix_ikm8mdm5rb23-1 start">
        <li class="c9 c16 li-bullet-0"><span>Researchers are striving to </span><span class="c5">narrow </span><span>the
                &ldquo;</span><span class="c5">semantic gap</span><span class="c1">&rdquo; between what computers can
                perceive, compared to humans,</span></li>
    </ul>
    <ul class="c10 lst-kix_ikm8mdm5rb23-0">
        <li class="c7 li-bullet-0"><span>The </span><span class="c5">BoVW </span><span class="c1">approach lends itself
                to high-performance image classification</span></li>
    </ul>
    <ul class="c10 lst-kix_ikm8mdm5rb23-1 start">
        <li class="c9 c16 li-bullet-0"><span>Performance is increased if the local features are </span><span
                class="c15 c5">sampled densely</span></li>
    </ul>
    <p class="c3"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_971tqtgulcdo-0 start">
        <li class="c7 li-bullet-0"><span>Typical system takes in image, passes through </span><span class="c5">feature
                extractor</span><span class="c1">&nbsp;and eventually feeds features to machine learning system to make
                decisions.</span></li>
        <li class="c7 li-bullet-0"><span>Supervised ML algorithm uses </span><span class="c5">pre-labelled training
                data</span><span class="c1">&nbsp;for assigning class labels to vectors</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Binary classifier </span><span class="c1">- 2 classes</span></li>
        <li class="c7 li-bullet-0"><span class="c5">Multiclass classifier </span><span class="c1">- multiple
                classes</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_971tqtgulcdo-0">
        <li class="c7 li-bullet-0"><span class="c5">Multilabel </span><span class="c1">classifier can predict multiple
                labels or classes.</span></li>
    </ul>
    <ul class="c10 lst-kix_971tqtgulcdo-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">With probabilities/confidences.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Often called </span><span class="c5">automatic image annotation
            </span><span>or </span><span class="c5">auto-annotation</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Doesn&rsquo;t </span><span>determine </span><span
                class="c5">where </span><span>in an image a thing is, just looks for </span><span class="c5">presence
            </span><span class="c1">of the thing.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Object recognition</span><span>&nbsp;attempts to localise an
            </span><span class="c5">object</span><span>&nbsp;and determine </span><span class="c5">class</span><span
                class="c1">.</span></li>
    </ul>
    <p class="c3 c33"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_o8zs7t77wkwq-0 start">
        <li class="c7 li-bullet-0"><span class="c15 c5">Current research challenges</span></li>
    </ul>
    <ul class="c10 lst-kix_o8zs7t77wkwq-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Unconstrained object recognition in natural scenes</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Global classification of images into scene
                categories/events/topics.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Automatic annotation of large sets of imagery.</span></li>
    </ul>
    <ul class="c10 lst-kix_o8zs7t77wkwq-0">
        <li class="c7 li-bullet-0"><span>Fundamental problem to solve: make </span><span class="c5">computers
            </span><span>see images like </span><span class="c15 c5">humans.</span></li>
    </ul>
    <ul class="c10 lst-kix_o8zs7t77wkwq-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">&ldquo;Semantic understanding&rdquo; - overall meaning of
                image</span></li>
    </ul>
    <ul class="c10 lst-kix_o8zs7t77wkwq-0">
        <li class="c7 li-bullet-0"><span class="c15 c5">Semantic Gap</span></li>
    </ul>
    <p class="c3"><span class="c5 c15"></span></p>
    <ul class="c10 lst-kix_5df3hp1hvtv7-0 start">
        <li class="c7 li-bullet-0"><span class="c5">History of approaches</span></li>
    </ul>
    <ul class="c10 lst-kix_5df3hp1hvtv7-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Historically BoVW has been important.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">The histograms created also powerful global descriptors and
                object detectors</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Auto Annotation </span><span>treated like </span><span
                class="c5">language translation </span><span>with </span><span class="c15 c5">semantic space.</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span>Raw features from SIFT, and quantised descriptors of </span><span
                class="c5">segments</span><span>&nbsp;even </span><span class="c5">colour </span><span class="c1">of
                pixels.</span></li>
    </ul>
    <p class="c3 c50"><span class="c1"></span></p>
    <ul class="c10 lst-kix_5df3hp1hvtv7-1">
        <li class="c9 c16 li-bullet-0"><span>Codebook needs to be much </span><span class="c5">smaller </span><span
                class="c1">for ML, for performance and effectiveness</span></li>
        <li class="c9 c16 li-bullet-0"><span>Visual words can be </span><span class="c5">less distinctive</span><span
                class="c1">, little more variation</span></li>
        <li class="c9 c16 li-bullet-0"><span>Number of visual words </span><span class="c15 c5">few hundred, up to a few
                thousand.</span></li>
    </ul>
    <p class="c3"><span class="c15 c5"></span></p>
    <ul class="c10 lst-kix_5df3hp1hvtv7-1">
        <li class="c9 c16 li-bullet-0"><span>Classification improved by </span><span class="c5">sampling image at
                greater rate</span></li>
    </ul>
    <ul class="c10 lst-kix_5df3hp1hvtv7-2 start">
        <li class="c9 c12 li-bullet-0"><span class="c5">Dense SIFT</span><span class="c1">, densely sampled grid, rather
                at interest points</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Pyramid Dense SIFT,</span><span class="c1">&nbsp;Gaussian Scale
                Space</span></li>
    </ul>
    <ul class="c10 lst-kix_5df3hp1hvtv7-1">
        <li class="c9 c16 li-bullet-0"><span>BoVW representations augmented with </span><span class="c5">spatial
                pyramid</span><span class="c1">; sub-histograms of visual word occurrences for overlapping windows in
                image</span></li>
    </ul>
    <ul class="c10 lst-kix_5df3hp1hvtv7-2 start">
        <li class="c9 c12 li-bullet-0"><span>Improves performance, as learns </span><span class="c5">where</span><span
                class="c1">&nbsp;in image objects likely appear.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Pyramid Histogram of Words</span><span>&nbsp;(</span><span
                class="c5">PHOW</span><span class="c1">)</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_qbofo8y3aafq-0 start">
        <li class="c7 li-bullet-0"><span class="c5">Developing / Benchmarking BoVW scene classifier</span></li>
        <li class="c7 li-bullet-0"><span>Use </span><span class="c5">standardised datasets </span><span class="c1">when
                developing/comparing results of classifiers.</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Training </span><span>and </span><span class="c5">test
            </span><span class="c1">data sets</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Only training set used to train classifier</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Test set </span><span class="c1">withheld.</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-0">
        <li class="c7 li-bullet-0"><span class="c1">Raw features extracted from training images.</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-1 start">
        <li class="c9 c16 li-bullet-0"><span>Codebook of features, use k-means. </span><span class="c5">Uniform random
                sample </span><span class="c1">of all features rather than all of them for speed.</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-0">
        <li class="c7 li-bullet-0"><span>Apply </span><span class="c5">vector quantisation</span><span>&nbsp;to raw
                features, count the number of occurrences to build </span><span class="c5">histograms </span><span
                class="c1">of visual words for each image.</span></li>
        <li class="c7 li-bullet-0"><span class="c1">Classifiers trained using histograms</span></li>
        <li class="c7 li-bullet-0"><span>Might train on subset of training data to &ldquo;</span><span
                class="c5">validate&rdquo; </span><span>and </span><span class="c5">&ldquo;optimise</span><span
                class="c1">&rdquo; parameters.</span></li>
        <li class="c7 li-bullet-0"><span>Re-train with </span><span class="c15 c5">all training data.</span></li>
        <li class="c7 li-bullet-0"><span>Can now </span><span class="c5">apply classifiers to test data</span><span
                class="c1">:</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Extract features.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Quantise the features (using codebook)</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Compute occurrence histograms</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Use classifiers to find most likely class</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-0">
        <li class="c7 li-bullet-0"><span>Lots of ways to </span><span class="c5">evaluate the performance </span><span
                class="c1">of classification on test set.</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-1 start">
        <li class="c9 c16 li-bullet-0"><span>Simplest is </span><span class="c5">average precision</span></li>
    </ul>
    <ul class="c10 lst-kix_qbofo8y3aafq-2 start">
        <li class="c9 c12 li-bullet-0"><span>Proportion of </span><span class="c5">number of correct
                classifications</span><span>&nbsp;to </span><span class="c5">total number of predictions</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.q25m2fdp23vb"><span>TL;DR By Mark Towers</span></h2>
    <h3 class="c22" id="h.gr71k62go3oc"><span class="c26 c21">Mark (edited by Joshua Gregory)</span></h3>
    <p class="c9"><span>&ldquo;</span><span class="c1">These notes may miss something, please say if I have.
            Thanks&rdquo; - Mark</span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0 start">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 1: Eye and Human vision</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>The </span><span class="c5">human eye</span><span>&nbsp;is a complex
                machine, with cameras borrowing several similar ideas like </span><span class="c5">retina</span><span>,
            </span><span class="c5">lens</span><span>. The image coming into the eye is </span><span class="c5">flipped
            </span><span class="c1">upside down by the lens with the brain automatically flipping the image without
                thinking. </span></li>
        <li class="c9 c16 li-bullet-0"><span>The </span><span class="c5">retina </span><span>(the light sensitive part
                of the eye) with rods for low-light and black-white vision while the </span><span class="c5">cones
            </span><span>provide </span><span class="c5">colour </span><span>vision. However cones are most </span><span
                class="c5">sensitive </span><span class="c1">to green then red then blue. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Mach bands</span><span>&nbsp;are an optical
            </span><span>illusion</span><span class="c1">&nbsp;whereby the contrast between edges of slightly differing
                shades of grey is exaggerated when they are touching. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Neural networks</span><span class="c1">&nbsp;are an attempt to
                replicate the way that the brain works for vision</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 2: Image formation</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>When </span><span class="c5">decomposing </span><span>an image into bits,
                the </span><span class="c5">most significant
                bits</span><span>&nbsp;</span><span>have</span><span>&nbsp;the largest </span><span class="c5">influence
            </span><span>on the image. As the bit position </span><span>increases</span><span class="c1">, the more
                information is represented.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Resolution </span><span>is the number of pixels for the
            </span><span class="c5">width </span><span>and the </span><span class="c5">height </span><span class="c1">of
                the image</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Fourier transformation</span><span>: Any periodic function can
                be converted to the </span><span class="c5">sine </span><span>and </span><span class="c5">cosine waves
            </span><span>of different frequencies. It is also possible to </span><span class="c5">reconstruct
            </span><span>signals from its fourier transform. The </span><span class="c5">magnitude </span><span>and the
            </span><span class="c5">phase</span><span>, is calculated </span><span class="c1">by Pythagoras&#39; theorem
                and the angle of the hypotenuse in the complex plane.</span></li>
    </ul>
    <p class="c9 c33"><img src="assets/computer-vision/image22.png"></p>
    <p class="c9 c33"><img src="assets/computer-vision/image23.png"></p>
    <p class="c9 c33"><img src="assets/computer-vision/image24.png"></p>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 3: Image sampling</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Aliasing </span><span>is an effect that causes different signals
                to become </span><span class="c5">indistinguishable </span><span>when sampled. It also refers to the
                distortion or artifacts that results when a signal </span><span class="c5">reconstructed </span><span
                class="c1">from samples is different from the original continuous signal. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Sampling signals</span><span>: if an original signal is a
                continuous function, then digitally sampling it requires a </span><span class="c5">good sampling
                frequency</span><span>. So the </span><span class="c5">higher </span><span>the sample rate, the
            </span><span class="c5">better representation </span><span class="c1">of the signal can be captured. </span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Wheel motion</span><span>&nbsp;is an example of where sampling
                rate matters in vision as if the sample rate and the wheel rotations per second are
            </span><span>synchronous</span><span class="c1">&nbsp;then it can make it seem like the wheel is moving in
                reverse.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Sampling theory known as </span><span class="c5">Nyquist&rsquo;s sampling
                theorem</span><span>&nbsp;for one-dimension says that for each point of interest (pixel or musical
                sample), </span><span class="c5">twice </span><span class="c1">the frequency should be gathered.</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span>It is possible to </span><span class="c5">reconstruct </span><span>a signal
                from transformed components using the fourier transformation. This means the fourier transforms have a
            </span><span class="c5">forward </span><span>(to transform from a time space to frequency space) and a
            </span><span class="c5">backward </span><span>transformation called the inverse. Where the variables x and y
                are for space, u and v are for frequency and </span><img src="assets/computer-vision/image25.png"><span
                class="c1">&nbsp;is pixel x and y in the image. </span></li>
    </ul><a id="t.f727949b760321cc972232d42b2d9fa1f8785d82"></a><a id="t.2"></a>
    <table class="c65">
        <tbody>
            <tr class="c51">
                <td class="c64" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 65.33px;"><img
                                alt="" src="assets/computer-vision/image73.png"
                                style="width: 286.00px; height: 65.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
                <td class="c64" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 74.67px;"><img
                                alt="" src="assets/computer-vision/image236.png"
                                style="width: 286.00px; height: 74.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Shifting </span><span>an image doesn&rsquo;t affect the
            </span><span class="c5">magnitude </span><span>of the fourier transform of the image, but it does affect the
            </span><span class="c5">phase</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Rotating </span><span class="c1">the image does affect the
                fourier transform and rotates it in the same way.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Filtering</span><span>: by finding the phase of an image by the
                fourier transform, this gives access to the </span><span class="c5">frequency
                components</span><span>&nbsp;of the image. This can be used to find the high detail parts of the images
                by a </span><span class="c5">high-pass</span><span>&nbsp;filter or all of the low level details with a
            </span><span class="c5">low-pass</span><span class="c1">&nbsp;filter. </span></li>
        <li class="c9 c16 li-bullet-0"><span>Additional transformation types: </span><span
                class="c5">fourier</span><span>, </span><span class="c5">discrete cosine </span><span>and </span><span
                class="c5">hartley</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Applications </span><span>of the 2D fourier transformation:
            </span><span class="c5">understanding </span><span>and </span><span class="c5">analysis </span><span>of
                images, </span><span class="c5">speeding </span><span>up algorithms through the use of the function,
                representation </span><span class="c5">invariant properties </span><span>(rotation and shift), coding of
                images by </span><span class="c5">magnitude </span><span>and </span><span class="c5">phase
            </span><span>and recognition and </span><span class="c5">understanding </span><span>of </span><span
                class="c5">textures</span><span class="c1">.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 4: Point operators</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>Image </span><span class="c5">histograms </span><span>are a graph of the
            </span><span class="c5">frequency </span><span>of </span><span class="c5">brightness </span><span
                class="c1">for an image (global feature)</span></li>
        <li class="c9 c16 li-bullet-0"><span>An image can be </span><span class="c5">brightened </span><span
                class="c1">using the formula below where N is the new image, O is the old image, k is the gain, l is the
                level and x, y is the coordinates.</span></li>
    </ul>
    <p class="c9 c47 c98"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 212.00px; height: 48.00px;"><img
                alt="" src="assets/computer-vision/image76.png"
                style="width: 212.00px; height: 48.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Intensity mapping</span><span>&nbsp;allows for the changing of
                the </span><span class="c5">output brightness </span><span class="c1">(intensity) following this
                function where it is limited to the min and max values according to the second function. Where Nmax is
                the maximum limit, Nmin is the minimum limit, Omax is the maximum output and Omin is the minimum output
                and Ox,y being the old image coordinates and Nx, y being the new image coordinates. </span></li>
    </ul>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 529.50px; height: 71.25px;"><img
                alt="" src="assets/computer-vision/image165.png"
                style="width: 529.50px; height: 71.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Histogram equalisation </span><span class="c1">improves contrast
                in images.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">Equations:</span></li>
    </ul>
    <p class="c9 c33"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 216.00px; height: 82.00px;"><img
                alt="" src="assets/computer-vision/image285.png"
                style="width: 216.00px; height: 82.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 205.00px; height: 79.00px;"><img
                alt="" src="assets/computer-vision/image280.png"
                style="width: 205.00px; height: 79.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9 c33"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 241.50px; height: 73.46px;"><img
                alt="" src="assets/computer-vision/image93.png"
                style="width: 241.50px; height: 73.46px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 247.50px; height: 57.52px;"><img
                alt="" src="assets/computer-vision/image134.png"
                style="width: 247.50px; height: 57.52px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <p class="c9 c33"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 314.00px; height: 83.00px;"><img
                alt="" src="assets/computer-vision/image148.png"
                style="width: 314.00px; height: 83.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Thresholding </span><span>is a way of turning a
            </span><span>greyscale</span><span>&nbsp;image into a black-white image by checking if a pixel value is
                greater than a </span><span class="c5">threshold value</span><span class="c1">. If true then the pixel
                is set to 255 otherwise set to 0. </span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 5: Group operators</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Template convolution</span><span>&nbsp;applies a </span><span
                class="c5">kernel </span><span>matrix turning a group of pixels to a </span><span class="c5">single
                value</span><span>. Template convolution includes </span><span class="c5">coordinate inversion
            </span><span>in the x axis and y axis, however this is not needed if the template is </span><span
                class="c5">symmetric</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span>It is possible to apply template convolution </span><span class="c5">via
            </span><span>the </span><span class="c5">fourier transform</span><span>&nbsp;such that </span><img
                src="assets/computer-vision/image26.png"><span>is the fourier transform of the picture and </span><img
                src="assets/computer-vision/image27.png"><span>&nbsp;is the fourier transform of the template and </span><img
                src="assets/computer-vision/image28.png"><span class="c1">&nbsp;is the point by point multiplication. </span></li>
    </ul><a id="t.f727949b760321cc972232d42b2d9fa1f8785d82"></a><a id="t.3"></a>
    <table class="c77 c95">
        <tbody>
            <tr class="c51">
                <td class="c93" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 54.67px;"><img
                                alt="" src="assets/computer-vision/image111.png"
                                style="width: 286.00px; height: 54.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
                <td class="c80" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 400.91px; height: 52.50px;"><img
                                alt="" src="assets/computer-vision/image68.png"
                                style="width: 400.91px; height: 52.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>The </span><span class="c5">gaussian </span><span>function is used to
                calculate the template values and a compromise between the </span><span class="c5">variance </span><img
                src="assets/computer-vision/image29.png"><span>and </span><span class="c5">window size</span><span>. This allows for
            </span><span class="c5">gaussian averaging </span><span class="c1">by using the gaussian function for each
                element in a matrix.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c1">There are more advanced ways of doing gaussian function like
                non-local means and image ray transform.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 6: Edge detection</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>It is very useful to find the </span><span class="c5">edge </span><span
                class="c1">of an image.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">First order edge detection</span><span>: There are three
                equations, one for </span><span class="c5">vertical </span><span>edges, one for </span><span
                class="c5">horizontal </span><span>edges and vertical </span><span
                class="c5">+</span><span>&nbsp;horizontal edges. Where </span><img src="assets/computer-vision/image25.png"><span>is a
                point at x and y. It is possible to rearrange the </span><img src="assets/computer-vision/image30.png"><span>to the
                taylor expansion for </span><img src="assets/computer-vision/image31.png"><span>to the first derivatives </span><img
                src="assets/computer-vision/image32.png"><span class="c1">.</span></li>
    </ul><a id="t.4ddb8f843d82ffd23098bf8aea89b4b1c103b929"></a><a id="t.4"></a>
    <table class="c77 c94">
        <tbody>
            <tr class="c51">
                <td class="c107" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 231.00px; height: 51.00px;"><img
                                alt="" src="assets/computer-vision/image207.png"
                                style="width: 231.00px; height: 51.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
                <td class="c109" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 205.50px; height: 44.19px;"><img
                                alt="" src="assets/computer-vision/image141.png"
                                style="width: 205.50px; height: 44.19px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
                <td class="c40" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 259.00px; height: 48.00px;"><img
                                alt="" src="assets/computer-vision/image123.png"
                                style="width: 259.00px; height: 48.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <p class="c9 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 116.00px;"><img
                alt="" src="assets/computer-vision/image310.png"
                style="width: 602.00px; height: 116.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>Edge detection in vector format where the magnitude is </span><img
                src="assets/computer-vision/image33.png"><span>&nbsp;and the direction is </span><img src="assets/computer-vision/image34.png"><span>.
                Examples are the </span><span class="c5">Prewitt </span><span>operator or </span><span class="c5">Sobel
            </span><span class="c1">operator. </span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 7: Further edge detection</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>The </span><span class="c5">canny </span><span class="c1">edge detection
                algorithm can be broken down to 5 different steps</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c32">Apply </span><span class="c32 c5">Gaussian </span><span
                class="c32">filter to </span><span class="c32 c5">smooth </span><span class="c32">the image in order to
            </span><span class="c32 c5">remove </span><span class="c32">the </span><span class="c27 c5">noise</span>
        </li>
        <li class="c9 c12 li-bullet-0"><span class="c32">Find the </span><span class="c32 c5">intensity gradients
            </span><span class="c27 c21">of the image</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c32">Apply </span><span class="c32 c5">non-maximum
                suppression</span><span class="c32">&nbsp;to get rid of </span><span class="c32 c5">spurious
            </span><span class="c21 c27">response to edge detection</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c32">Apply </span><span class="c32 c5">double threshold </span><span
                class="c27 c21">to determine potential edges</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c32">Track edge by </span><span
                class="c32 c5">hysteresis</span><span class="c32">: Finalize the detection of edges by </span><span
                class="c32 c5">suppressing </span><span class="c27 c21">all the other edges that are weak and not
                connected to strong edges.</span></li>
    </ol>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 494.50px; height: 331.04px;"><img
                alt="" src="assets/computer-vision/image150.png"
                style="width: 494.50px; height: 331.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">&nbsp;It is formulated with three main objectives. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Optimal detection </span><span class="c1">with no spurious
                responses</span></li>
        <li class="c9 c12 li-bullet-0"><span>Good </span><span class="c5">localisation </span><span class="c1">with
                minimal distance between detected and true edge position</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Single response </span><span class="c1">to eliminate multiple
                responses to a single edge.</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Interpolation </span><span class="c1">in non-maximum
                suppression. Interpolate the gradient along the gradients (plus and minus a certain distance) and check
                if center is larger than neighbours.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Hysteresis </span><span>thresholding transfer function. There
                are</span><span class="c5">&nbsp;2 threshold values</span><span>. As a continuous process, when the
                brightness goes below the </span><span class="c5">lower threshold</span><span>, it is set to black, but
                it will only be set to white if the brightness goes above the </span><span class="c5">upper
                threshold</span><span class="c1">.</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 226.67px;"><img
                alt="" src="assets/computer-vision/image170.png"
                style="width: 602.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">The Laplacian operator</span><span>&nbsp;is a different operator
                that creates a new complex gaussian like operator with an extremely complex math function. </span><span
                class="c36 c81 c21">(I really hope you don&#39;t have to remember this function - Mark)</span></li>
    </ul>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.07px; height: 366.50px;"><img
                alt="" src="assets/computer-vision/image261.png"
                style="width: 576.07px; height: 366.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Zero-crossing detection </span><span>- average and sum the 4
                corners around a pixel. If the signs change between summations, you have a detection.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Marr-Hildreth edge detection </span><span>- application of
            </span><span>Laplacian of Gaussian </span><span class="c1">(or Difference of Gaussian) and zero-crossing
                detection.</span></li>
    </ul>
    <p class="c9"><span class="c1">&nbsp;</span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 8: Finding shapes</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>It is important to be able to </span><span class="c5">extract
                features</span><span>&nbsp;from an image. This can be done by finding the difference between
            </span><span class="c5">low </span><span>and </span><span class="c5">high threshold</span><span class="c1">.
                While this can identify high contrast parts of the image however this doesn&rsquo;t help identify shapes
                in the image. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Template matching</span><span>: This is a technique for
                finding</span><span class="c5">&nbsp;small parts</span><span>&nbsp;of an image that match a </span><span
                class="c5">template image</span><span>. It uses </span><span class="c5">correlation </span><span>and
            </span><span class="c5">convolution </span><span>and implementation via </span><span
                class="c5">Fourier</span><span class="c1">. </span></li>
        <li class="c9 c16 li-bullet-0"><span>Template matching doesn&rsquo;t work with </span><span class="c5">noisy
            </span><span>images or for </span><span class="c5">occluded </span><span>images (obstructions</span><span
                class="c76 c86">).</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Hough transform</span><span>&nbsp;is a feature extraction
                technique that can find </span><span class="c5">imperfect instances </span><span>of </span><span
                class="c5">objects </span><span>within a certain class of </span><span class="c5">shapes </span><span>by
                a </span><span class="c5">voting procedure</span><span>. The voting procedure is carried out in a
            </span><span class="c5">parameter space </span><span>from which </span><span class="c5">object
                candidates</span><span>&nbsp;are obtained as a </span><span class="c5">local maxima</span><span>&nbsp;in
                a so-called </span><span class="c5">accumulator space</span><span>. Hough transform has the same
                performance equivalent to </span><span class="c5">template matching</span><span class="c1">&nbsp;but is
                faster to compute. Basically, straight lines in the image are represented as points in the m,c plane and
                vice versa.</span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 9: Finding more shapes</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Hough transform</span><span>&nbsp;can be used for not only lines
                but for </span><span class="c5">circles </span><span>or </span><span class="c5">arbitrary
                shapes</span><span>. To do so uses a </span><span class="c5">generalised hough transformation
            </span><span>where it forms a </span><span class="c5">discrete </span><span>look-up tables called the
            </span><span class="c5">R-table</span><span>. It </span><span class="c5">votes </span><span>via a
                look-up-table. The </span><span class="c5">orientation </span><span>is turned by </span><span
                class="c5">rotating </span><span>the R-table voting and </span><span>scaling </span><span>by
            </span><span class="c5">scaling </span><span>the R-table. This has inherent problems with </span><span
                class="c5">discretisation </span><span class="c1">(the process of transferring the continuous functions
                to the discrete voting table). </span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c7 li-bullet-0"><span class="c1">Lecture 10: Applications/Deep learning</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>Computer vision is used in </span><span class="c5">industry
            </span><span>for </span><span class="c5">quality control </span><span>or in </span><span class="c5">academia
            </span><span>for </span><span class="c5">face recognition</span><span>. Nowadays, computer vision uses
            </span><span class="c5">modern hardware </span><span>and </span><span class="c5">modern cameras
            </span><span>to achieve what we understand by &ldquo;</span><span class="c5">sight</span><span>&rdquo;.
                Currently there is </span><span class="c5">no technique </span><span>for </span><span class="c5">all
                problems </span><span>and is an </span><span class="c5">active </span><span>area of </span><span
                class="c5">research </span><span class="c1">in both industry and academia. </span></li>
    </ul>
    <p class="c3"><span class="c1"></span></p>
    <h2 class="c19" id="h.x8zi2cpk1e2d"><span class="c23 c21">Jon</span></h2>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.bu2xo0olc611" style="display:inline"><span class="c26 c21">Lecture 1: Building machines that
                    see</span></h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>Key terms in designing computer vision systems as you want
                you</span><span>r</span><span class="c5">&nbsp;system to be robust and repeatable</span><span>, the
                system </span><span class="c5">design to be invariant and the constraints to work</span><span
                class="c1">. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Robust </span><span>- Changes to the </span><span
                class="c5">environment </span><span>will not affect the </span><span class="c5">accuracy </span><span
                class="c1">of the system</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Repeatable </span><span class="c1">- A measure of robustness,
                such that the system must work the same over and over regardless of the environmental changes</span>
        </li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Invariant </span><span class="c1">- An environmental factor that
                helps achieve robustness and repeatability. Hardware and software can be designed to be invariant to
                certain environmental changes such as invariant to illumination changes. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Constraints </span><span class="c1">- Are applied to the
                hardware, software and wetware (humans in the system) to make sure the vision system works in a
                repeatable and robust fashion. An example is putting the system in a box so there can&rsquo;t be any
                illumination changes. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>For</span><span class="c15 c5">&nbsp;industry vision, there are constraints
                applied</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Software constraints</span><span class="c1">: Simple and fast
                algorithm are the most popular as it means that there is a smaller chance of failure compared to deep
                learning approaches. Therefore Hough transform is a popular algorithm however this requires physical
                constraints to make it robust. So the use of colour is an important software feature as some
                colour-spaces don&#39;t encode the whole human vision or does not encode the luminance of a colour.
            </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Physical constraints</span><span class="c1">&nbsp;- In industry
                environments, it is possible to constrain the physical environment e.g. lighting, enclosure, mounting,
                camera specs, optics and filters. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>However in the</span><span class="c5">&nbsp;wild, many of these constraints
                are not able to be guaranteed </span><span>therefore as many </span><span class="c5">hardware and
                wetware constraints</span><span class="c1">&nbsp;are applied with the software taking up the slack. E.g.
                the colour information is often less important than lumination. </span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.30gq3ipc56cr" style="display:inline"><span class="c26 c21">Lecture 2: Machine learning for pattern
                    recognition</span></h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>For computer vision application, they normally take the</span><span
                class="c5">&nbsp;form of image &rarr; feature extractor &rarr; machine learning &rarr;
                results</span><span class="c1">. This is as the feature extractor converts the raw image into a feature
                vector which can then be learnt much easier for a machine learning algorithm (instead of learning the
                raw image). </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Feature vector are just a mathematical vector with a fixed
                number of elements </span><span>in it where the number of elements is the dimensionality of the vector.
            </span><span class="c5">Each element represents a point in a featurespace</span><span class="c1">&nbsp;or
                equally a &nbsp;direction in the featurespace. Therefore the dimensionality of a featurespace is equal
                to the dimensionality of every feature vector in it. </span></li>
        <li class="c9 c16 li-bullet-0"><span>An aim of feature extractor is that they produce vectors that are similar
                to each other for similar images. This </span><span class="c5">similarity is measured by finding the
                distance between the two feature vectors</span><span class="c1">. There are different measures of
                distance</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Euclidean distance (L2 distance)</span><span>&nbsp;- The
                straight line distance between two points that is computed via an extension of Pythagoras theorem to n
                dimensions. </span><img src="assets/computer-vision/image35.png"></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Manhattan/Taxicab distance (L1 distance) </span><span>- The
                distance along paths parallel to the axes of the space </span><img src="assets/computer-vision/image36.png"></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Cosine similarity</span><span class="c1">&nbsp;- This
                isn&rsquo;t a distance but rather the angle between the two angles. This is useful if the relative
                length of the vectors don&rsquo;t matter.</span></li>
    </ol>
    <p class="c9 c47 c33"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 358.00px; height: 139.00px;"><img
                alt="" src="assets/computer-vision/image110.png"
                style="width: 358.00px; height: 139.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>Choosing a good feature vector representations for machine learning as
            </span><span class="c5">better feature vectors allows easier distinguishing of objects or classes of
                interest</span><span class="c1">. Machine learning also becomes more difficult, the more features
                (dimensionally) therefore the smaller the number of features the better. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Classification is a supervised machine learning that allows a
                computer to &ldquo;learn&rdquo; the assigning of class labels to an object</span><span>&nbsp;(normally a
                feature vector of an image). To do this requires a pre-labelled dataset of an input and the correct
                output for the process. </span><span class="c5">Binary classifiers only have two classes while
                multiclass classifier has many classes</span><span class="c1">. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Linear classifiers are type of binary classifier where to tries
                to learn a hyperplane that separates two classes in a featurespace with minimum error. </span><span>(Do
                foundations of machine learning if you want to learn the specifies and </span><span class="c5">cry a
                lot</span><span class="c1">). In order to classify a new image, the image is placed in the hyperspace
                then check which side of the hyperplane the image is determining the class of the image.</span></li>
        <li class="c9 c16 li-bullet-0"><span>Some </span><span class="c5">data can&rsquo;t be linearly separable
                therefore non-linear binary classifiers such as Kernel support vector machines</span><span>. These
                machines can learn non-linear decision boundaries through the use of the kernel trick (foundations of
                machine learning has the mathematically details). However this has the </span><span class="c5">problem
                that the algorithm must lose generality by overfitting as the decision boundaries is not limited to a
                straight line</span><span class="c1">. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">KNN is a multiclass classifier that assigns the class of unknown
                points based on the majority class of the closest K neighbours in the featurespace</span><span>. So for
                a new point then within a set radius, all of the points within the radius are found. With the new point
                class being determined by the majority class of the points. However this has </span><span
                class="c15 c5">problems as it is computationally expensive if there are lots of training examples or
                many dimensions. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">K-mean clustering is an unsupervised machine learning algorithm
                that aims to group data together into classes without any prior knowledge</span><span>&nbsp;(or labelled
                data). In terms of feature vectors, items are similar vectors should be grouped together by a cluster
                operation. Some </span><span class="c5">clustering operations can be done using a probabilistic model
                instead of making a discrete choice</span><span class="c1">. It follows the algorithm below</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c1">The value of K (number of clusters) is chosen</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">The initial cluster centres are chosens (called the
                centroids)</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Till the centroids dont move after an iteration</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c1">Each point is assigned to its closest centroids</span></li>
        <li class="c9 c55 li-bullet-0"><span class="c1">The centroids are recomputed as the mean of all of the points
                assigned to it. If the centroid has no points assigned it to, it is randomly re-initialised to a new
                point. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2" start="4">
        <li class="c9 c12 li-bullet-0"><span class="c1">The final clusters are created by assigning all of the points to
                their nearest centroids. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.wn3t7k2phgn7" style="display:inline"><span class="c26 c21">Lecture 3: Covariance and Principal
                    components</span></h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Variance is the mean squared difference from the
                mean</span><span>. It is a measure of how spread-out the data is. It can be written as </span><img
                src="assets/computer-vision/image37.png"><span>&nbsp;where </span><img src="assets/computer-vision/image38.png"><span
                class="c1">&nbsp;is the exception (basically the mean if the probability is equal). </span></li>
    </ul>
    <p class="c9 c47 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 391.50px; height: 131.93px;"><img
                alt="" src="assets/computer-vision/image80.png"
                style="width: 391.50px; height: 131.93px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Covariance measures how two variables change
                together</span><span>&nbsp;and the variance is the covariance when the two variables are the same so
            </span><img src="assets/computer-vision/image39.png"><span>&nbsp;It can be written as </span><img
                src="assets/computer-vision/image40.png"><span class="c1">. </span></li>
    </ul>
    <p class="c9 c47 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 458.50px; height: 116.53px;"><img
                alt="" src="assets/computer-vision/image108.png"
                style="width: 458.50px; height: 116.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Covariance matrix encodes how all possible pairs of dimensions
                in an n-dimensional dataset</span><span class="c1">&nbsp;carry together square symmetric matrix. </span>
        </li>
    </ul>
    <p class="c9 c47 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 322.50px; height: 87.32px;"><img
                alt="" src="assets/computer-vision/image125.png"
                style="width: 322.50px; height: 87.32px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Mean centring is a process of computing the mean
            </span><span>(across a number of independent dimensions) </span><span class="c5">as a set of vectors which
                is then subtracted from the mean vector from every vector in the set</span><span class="c1">. For each
                of the dimensions then all of the vector are translated (by subtracting each point by the mean) so their
                mean position is the origin position. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Principal axes of variation</span><span class="c1">&nbsp;- This
                can be computed using this algorithm: </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Basis is a set of n linearly independent vectors</span><span
                class="c1">&nbsp;in an n-dimensional space. This means that all of the vectors are orthogonal forming a
                coordinate system. </span></li>
        <li class="c9 c12 li-bullet-0"><span>The </span><span class="c5">first principal axis is the vector that
                describes the direction of greatest variance</span><span class="c1">&nbsp;for a given set of
                n-dimensional data. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">All of the following principal axis are orthogonal
                (perpendicular) to all of the previous axis</span><span class="c1">. E.g. second principal axis is
                orthogonal to the first axe while the third principal axis is orthogonal to the first and second
                principal axes. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Eigenvectors and eigenvalues are found by solving the equation
            </span><img src="assets/computer-vision/image41.png"><span class="c5">&nbsp;where A is a n-square matrix, v is a
                n-dimensional vector (eigenvector) and </span><img src="assets/computer-vision/image42.png"><span class="c5">&nbsp;is
                the scalar value (eigenvalue)</span><span class="c1">. Eigenvectors and values have the following
                properties: </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">At most n eigenvector-value pairs</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">If A is symmetric, the set of eigenvectors is
                orthogonal</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">If A is a covariance matrix, the eigenvector are the
                principal axes</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">The eigenvalues are proportional to the variance of the data
                along each eigenvector</span><span class="c1">. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">If all of the eigenvectors are independent then the sorted list
                of eigenvectors is equal to PCA axes</span><span class="c1">.</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Eigendecomposition </span><span>(</span><img
                src="assets/computer-vision/image43.png"><span>) </span><span class="c5">factorizes a matrix into eigenvectors and a
                matrix where the diagonal are eigenvalues</span><span>. If A is a real symmetric (i.e.covariance matrix)
                then </span><img src="assets/computer-vision/image44.png"><span class="c1">&nbsp;(i.e. eigenvectors are orthogonal).
                This allows finding of the principal components. </span></li>
        <li class="c9 c16 li-bullet-0"><span>A linear transform projects data from one space into another space that can
                reduce the dimensions than the original. (e.g. </span><img src="assets/computer-vision/image45.png"><span class="c1">).
                This process can be reversed if W is invertible (invertible) so this is not possible if the dimensional
                is changed. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Principal component analysis (PCA) is an orthogonal linear
                transform that maps data from its original space to a space defined by the principal axes of the
                data</span><span class="c1">. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span>The </span><span class="c5">transform matrix W is just the eigenvector
                matrix Q from the eigendecomposition of the covariance matrix of the data.</span><span
                class="c1">&nbsp;</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Dimensionality reduction can be achieved by removing the
                eigenvectors with low eigenvalues from Q (i.e. keeping the first L columns of Q assuming the
                eigenvectors are sorted by decreasing eigenvalue. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">PCA algorithm that allows for the reduction of dimensions of
                feature space making it easier to learn by machine learning algorithms</span><span>. It also means there
                are a </span><span class="c5">smaller number of dimensions allowing for greater robustness to noise,
                mis-alignment and the dominant features are captured</span><span class="c1">.</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c1">Mean-centre the data vector</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c1">Form the vectors into a matrix Z, such that each row corresponds
                to a vector</span></li>
        <li class="c9 c12 li-bullet-0"><span>Perform the eigendecomposition of the matrix </span><img
                src="assets/computer-vision/image46.png"><span>&nbsp;to recover the eigen matrix Q and diagonal matrix </span><img
                src="assets/computer-vision/image47.png"></li>
        <li class="c9 c12 li-bullet-0"><span>Sort the columns of Q and corresponding diagonal values of </span><img
                src="assets/computer-vision/image48.png"><span class="c1">&nbsp;so that the eigenvalues are decreasing.</span></li>
        <li class="c9 c12 li-bullet-0"><span>Select the L largest eigenvectors of Q (the first L columns) to create the
                transform matrix </span><img src="assets/computer-vision/image49.png"></li>
        <li class="c9 c12 li-bullet-0"><span>Project the original vectors into a lower dimensional space, </span><img
                src="assets/computer-vision/image50.png"><span class="c1">.</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.7t7wul3zorx" style="display:inline"><span class="c26 c21">Lecture 4: Types of image feature and
                    segmentation</span></h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>There are</span><span class="c15 c5">&nbsp;four main ways of extracting
                features from an image</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Global </span><span>- features are extracted from the contents
                of an entire image through </span><span class="c5">image histograms and joint-colour
                histogram</span><span class="c1">.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Grid/block-based</span><span>&nbsp;- The </span><span
                class="c5">entire image split into blocks with a feature extracted from each block</span><span
                class="c1">. This allows for multiple feature vectors to be extracted.</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Region-based</span><span>&nbsp;- The </span><span
                class="c5">entire image is split into a number of regions and a feature is extracted from
                each</span><span class="c1">&nbsp;allowing for multiple feature vectors to be extracted. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Local </span><span>- The </span><span class="c5">interest points
                of the image are detected with a feature vector extracted from the surrounding pixels of each interest
                points</span><span class="c1">. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Image histograms</span><span class="c1">&nbsp;- A simple global
                feature that finds the image histograms of the intensity (by averaging the colour band values). However
                this isn&rsquo;t particularly robust and can&rsquo;t deal well with multiple colours in the
                image.</span></li>
    </ul>
    <p class="c9 c47 c33"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 424.50px; height: 214.87px;"><img
                alt="" src="assets/computer-vision/image156.png"
                style="width: 424.50px; height: 214.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Joint-colour histogram</span><span>&nbsp;- The</span><span
                class="c5">&nbsp;colour space is quantised into bins</span><span class="c1">&nbsp;and we accumulate the
                number of pixels in each bin. This is technically a multidimensional histogram (due to each colour) that
                if flatten (unwrap) it can be used to make it a feature vector. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Image segmentation</span><span>&nbsp;- The</span><span
                class="c5">&nbsp;process of creating region-based descriptions</span><span class="c1">, basically
                creating groups (segments) of pixels that are &ldquo;similar&rdquo;. This is normally pixels that share
                certain visual characteristics (colour, lighting, etc). </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Global binary thresholding</span><span>&nbsp;- Takes a
            </span><span class="c5">greyscale</span><span class="c5">&nbsp;image and assigns all pixel with a value
                lower than a predetermined threshold to one segment with all other pixels to the other
                segment</span><span>. This is really </span><span class="c5">fast </span><span>but </span><span
                class="c5">requires a manually set static threshold</span><span class="c1">&nbsp;making it not robust to
                lightning changes. Works well in applications with lots of physical constraints</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Otsu&rsquo;s thresholding method</span><span>&nbsp;- Provides a
                way to </span><span class="c5">automatically find the threshold assuming that there are only two
                classes</span><span>&nbsp;(i.e. foreground and background) so the histogram must have two peaks. So
            </span><span class="c5">an exhaustive search for the threshold that maximises the interclass
                variance</span><span class="c1">&nbsp;</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Adaptive/local thresholding</span><span>&nbsp;- </span><span
                class="c5">computes a different threshold value for every pixel in an image based on the surrounding
                pixels</span><span class="c1">. This is usually a square or rectangular window around the current pixel
                to define the neighbours. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Mean adaptive thresholding</span><span>&nbsp;- </span><span
                class="c5">Set the current pixel to zero if its value is less than the mean of its neighbours plus a
                constant values otherwise set to 1</span><span class="c1">. This relies on the parameters: size of the
                window and the constant offset value. This means that it deals well with uneven lighting/contrast but it
                is computationally expensive (compared to other global methods) and can be difficult to choose the
                window size. As the scale of an object can break it. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Segmentation with K-means</span><span>&nbsp;- </span><span
                class="c5">Cluster the colour vectors [</span><span class="c89 c5">r</span><span class="c5">,
            </span><span class="c5 c105">g</span><span class="c5">, </span><span class="c67 c5">b</span><span
                class="c5">] of all the pixels where each pixel is assigned to a segment based on the closest
                centroid</span><span>. This works best if the colour-space and sitane function are compatible (e.g. lab
                colour-space is designed so that Euclidean distances are proportional to perceptual colour differences.
            </span><span class="c5">This doesn&rsquo;t preserve continuity of segments so single pixel might end up
                alone</span><span>. Therefore also </span><span class="c5">encoding the position is helpful</span><span
                class="c1">&nbsp;but this should be normalised by the width and height of the image to remove the effect
                of different image sizes and scale x and y so they have more or less effect than the colour components.
            </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Pixel connectivity</span><span>&nbsp;- A </span><span
                class="c5">pixel is connected to another if they are spatially adjacent to each other</span><span>.
                There are two standard ways of defining this: </span><span class="c15 c5">4-connectivity and
                8-connectivity representation the cardinal directions. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Connected component labelling</span><span>&nbsp;- The process of
            </span><span class="c5">detecting connected regions within a binary (segmented) image</span><span
                class="c1">. There are a lot of different algorithms that have a variety of performance tradeoffs
                (memory vs time). An example algorithm is the two-pass algorithm:</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c1">One the first pass, iterate through each element of the data by
                column then by row (raster scanning)</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c1">If the element is not the background</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-4 start">
        <li class="c9 c91 c62 li-bullet-0"><span class="c1">Get the neighbouring elements of the current element</span>
        </li>
        <li class="c9 c91 c62 li-bullet-0"><span class="c1">If there are no neighbours, uniquely label the current
                element and continue</span></li>
        <li class="c9 c91 c62 li-bullet-0"><span class="c1">Otherwise, find the neighbour with the smallest label and
                assign it to the current element</span></li>
        <li class="c9 c91 c62 li-bullet-0"><span class="c1">Store the equivalence between neighbouring labels</span>
        </li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2" start="2">
        <li class="c9 c12 li-bullet-0"><span class="c1">On the second pass, iterate over the data in the same way</span>
        </li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c1">If the element is not the background</span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-4 start">
        <li class="c9 c62 c91 li-bullet-0"><span class="c1">Relabel the element with the lowest equivalent label</span>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c19 c50 c62 li-bullet-0">
            <h2 id="h.rmn2ck5oh94e" style="display:inline"><span class="c23 c21">Lecture 5: Shape description and
                    modelling</span></h2>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>It is possible to</span><span class="c5">&nbsp;extract features from shapes
                by connected pixels</span><span>. There are two types of </span><span class="c5">pixel borders: inner
                and outer</span><span class="c1">.</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span>The </span><span class="c15 c5">inner border is the set of pixels that are
                outermost pixels within the shape</span></li>
        <li class="c9 c12 li-bullet-0"><span>The </span><span class="c15 c5">outer border is the set of pixels that the
                outline of pixels outside the shape.</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">There are two ways of describing a shape: Region description and
                boundary description. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">Region description: A simple scalar shape features</span>
        </li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c5">Perimeter </span><span class="c1">= Length around the outside of
                the component</span></li>
        <li class="c9 c55 li-bullet-0"><span class="c5">Area </span><span class="c1">= Number of pixels in
                component</span></li>
        <li class="c9 c55 li-bullet-0"><span class="c5">Compactness </span><span>= How tightly packed the pixels are,
                often computed as the weighted ratio of area to perimeter squared. </span><img
                src="assets/computer-vision/image51.png"><span class="c1">.</span></li>
        <li class="c9 c55 li-bullet-0"><span class="c5">Centre of mass</span><span class="c1">&nbsp;= The mean of x and
                y positions of all the pixels in the component</span></li>
        <li class="c9 c55 li-bullet-0"><span class="c5">Irregularity/Dispersion</span><span class="c1">&nbsp;= How
                &ldquo;spread-out&rdquo; the shape is. This is computed is two different ways: the ratio between the
                furthest point from the centre of mass and the area of the shape. The other is the ratio between the
                furthest boundary point and the closest boundary point. </span></li>
    </ul>
    <p class="c9 c47 c33"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 431.83px; height: 266.50px;"><img
                alt="" src="assets/computer-vision/image214.png"
                style="width: 431.83px; height: 266.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-3">
        <li class="c9 c55 li-bullet-0"><span class="c5">Moment </span><span>= The distribution of pixels of shapes in a
            </span><span>greyscale</span><span>&nbsp;image with the order p and q and I(s) is the pixel intensity. For
                the case of connected components, this is simplified to the second equation. These equations can be used
                to calculate the centre of mass: </span><img src="assets/computer-vision/image52.png"><span class="c1">. But it is not
                invariant to translation, rotation or scaling however other moments exist. </span></li>
    </ul><a id="t.f727949b760321cc972232d42b2d9fa1f8785d82"></a><a id="t.5"></a>
    <table class="c65">
        <tbody>
            <tr class="c51">
                <td class="c83" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 371.25px; height: 67.50px;"><img
                                alt="" src="assets/computer-vision/image144.png"
                                style="width: 371.25px; height: 67.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
                <td class="c90" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 189.50px; height: 65.31px;"><img
                                alt="" src="assets/computer-vision/image157.png"
                                style="width: 189.50px; height: 65.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <p class="c3"><span class="c1"></span></p><a id="t.df65473154dd77de019d1a3eebc2b41f9b810271"></a><a id="t.6"></a>
    <table class="c50 c77">
        <tbody>
            <tr class="c51">
                <td class="c28" colspan="1" rowspan="1">
                    <p class="c9"><span class="c5">Central moments</span><span class="c1">&nbsp;= Translation invariant
                            as it uses the centre of mass</span></p>
                </td>
                <td class="c28" colspan="1" rowspan="1">
                    <p class="c9"><span class="c5">Normalised central moments</span><span class="c1">&nbsp;= Both scale
                            and translation invariant</span></p>
                </td>
            </tr>
            <tr class="c51">
                <td class="c28" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 262.00px; height: 53.33px;"><img
                                alt="" src="assets/computer-vision/image216.png"
                                style="width: 262.00px; height: 53.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
                <td class="c28" colspan="1" rowspan="1">
                    <p class="c9"><span
                            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 262.00px; height: 50.67px;"><img
                                alt="" src="assets/computer-vision/image191.png"
                                style="width: 262.00px; height: 50.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                                title=""></span></p>
                </td>
            </tr>
        </tbody>
    </table>
    <p class="c3"><span class="c1"></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>It is important to </span><span class="c5">encode the boundary of a
                component</span><span class="c1">, this is done in two ways: chain codes and chain code invariance.
            </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Chain codes</span><span class="c1">: By walking around the
                boundary and encode the direction you take on each step as a number. They cyclically shift the code so
                it forms the smallest possible integer value (making it invariant to the starting point). </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Chain code invariance</span><span class="c1">: This can be made
                rotation invariant by encoding the differences in direction rather than absolute values. It can also be
                made scale invariant by resampling the components to a fixed size (however this doesn&rsquo;t work well
                in practice). </span></li>
    </ol>
    <p class="c9"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 174.80px; height: 370.50px;"><img
                alt="" src="assets/computer-vision/image247.png"
                style="width: 174.80px; height: 370.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 384.00px; height: 371.00px;"><img
                alt="" src="assets/computer-vision/image87.gif"
                style="width: 384.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Region adjacency graph</span><span>&nbsp;- It </span><span
                class="c5">builds a graph from a set of connected components where each node corresponds to a component
                and a vertex (connection) between nodes exist if they share a border</span><span class="c1">. This can
                be used to easily detect patterns in the graph making it invariant to non-linear distortions but not to
                occlusions. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Active shape models and constrained local models
                (ASM/CLM)</span><span class="c1">&nbsp;extends Point Distribution Model (PDM) by learning the local
                appearance around each point which is typically just an image template. Using a constrained optimisation
                algorithm, the shape can be optimally fitted to an image by using constraints. </span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c19 c50 c62 li-bullet-0">
            <h2 id="h.6yguqrroim2j" style="display:inline"><span class="c23 c21">Lecture 6: Local interest points</span>
            </h2>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Interest points</span><span class="c1">&nbsp;- Points within an
                image that are &ldquo;important&rdquo;. Good interest points have:</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">Invariance to brightness changes</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">Sufficient texture variation in the local neighbourhood
            </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c15 c5">Invariance to changes between the angle / position of the
                scene to the camera. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c1">There are lots of different types of interest point types to
                choose from.</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Corner detection</span><span>&nbsp;- By using &nbsp;a small
                window, the idea is that at a corner, there will be a significant change in all directions. Whereas if
                the window is at the edge then there is no change along the edge direction. And in a flat region there
                will be no change in all directions. This is dependant on measuring the change in intensity between a
                window and the shifted version. </span><span>TODO </span><span class="c1">maths</span></li>
        <li class="c9 c12 li-bullet-0"><span>Blob detection (also called Difference-of-Gaussian Extrema) - TODO </span>
        </li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.jziq0rxhhwv0" style="display:inline"><span class="c26 c21">Lecture 7: Local features and
                    matching</span></h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c1">Local features are used for: image alignment, object
                recognition, index and database retrieval, motion tracking, 3D reconstruction. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Local features are found by identifying all of the interest
                points in an image with a feature vector being extracted from interest points from the surrounding
                pixels</span><span class="c1">. </span></li>
        <li class="c9 c16 li-bullet-0"><span>There are two distinct </span><span class="c5">types of matching
                problem</span><span class="c1">: narrow-baseline stereo and wide-baseline stereo. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Narrow-baseline stereo</span><span class="c1">&nbsp;- When the
                local features in two images have only moved by a few pixels. Because of this the interest matcher, it
                doesn&rsquo;t need robustness to rotation and light. The search can be optimised for within the window
                area, so the detector doesn&rsquo;t need to identify a large number of points (low descriptiveness).
            </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Wide-baseline stereo</span><span class="c1">&nbsp;- When the
                local features in two images have moved by large amounts (the feature has moved, rotated, etc in the
                image). Because of this the interest matcher, it needs to be robust to intensity change and invariant to
                rotation. The matcher also needs to be highly descriptive so that it identifies a large number of
                interest points in the image to avoid mismatches (but not so distinctive that you can&rsquo;t find any
                matches). Also robust to small localisation errors of the interest points, the descriptor should not
                change too much if it moves by a few pixels but to change more rapidly once it moves further way.</span>
        </li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-3 start">
        <li class="c9 c55 li-bullet-0"><span class="c15 c5">There are a number of problems with wider baselines: not
                robust to rotation, sensitive to localisation of interest points (small search window helps), wider
                baseline can&#39;t assume a search area (therefore requires considering all of the interest points
                between the two images). </span></li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Instead of using pixel patches to identify interest points,
                local histograms can be used instead.</span><span>&nbsp;To match each interest point in the first image
                to the most similar point in the second image (i.e. in terms of euclidean distance between the
                histograms). But this has the </span><span class="c5">following problems</span><span class="c1">:</span>
        </li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Not necessarily very distinctive as many interest points likely
                to have similar distribution of </span><span class="c5">greyscale</span><span
                class="c15 c5">&nbsp;image. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">It is not rotation invariant if the sampling window is square or
                rectangular but can be overcome by using a circular window</span><span class="c1">. </span></li>
        <li class="c9 c12 li-bullet-0"><span>It is </span><span class="c15 c5">not invariant to illumination
                changes</span></li>
        <li class="c9 c12 li-bullet-0"><span>It is </span><span class="c5">sensitive to interest point
                localisation</span><span class="c1">, the point where the interest point is identified. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>It order to </span><span class="c15 c5">overcome localisation sensitivity
                to </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Allow the window to move a few pixels in any direction without
                changing the descriptor</span><span class="c1">. </span></li>
        <li class="c9 c12 li-bullet-0"><span>By </span><span class="c5">applying a weighting so that the pixels near the
                edge of the window have a smaller effect than the points in the centre</span><span class="c1">. Commonly
                this is done using the gaussian weighting centred on the interest point for this. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>It order to </span><span class="c5">overcome the lack of illumination
                invariance</span><span>, this is potentially achievable by </span><span class="c5">normalising or
                equalising the pixel patches before constructing the histogram.</span><span class="c1">&nbsp;</span>
        </li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Local gradient histograms is an alternative to pixel histograms
                by finding the partial derivatives of an image</span><span>&nbsp;(e.g. applying convolution with Sobel).
                So instead of building histograms of the raw pixel values we could instead build histograms that encode
                the gradient magnitude and direction for each pixel in the sampling patch. As </span><span
                class="c5">gradient magnitudes (and directions) are invariant to brightness change plus gradient
                magnitude and direction histograms are more distinctive than local pixel histograms</span><span>. This
                is built by quantising the direction (0 to 2</span><img src="assets/computer-vision/image53.png"><span
                class="c1">&nbsp;radians) into a number of bins (usually 8). For each pixel in the sample patch,
                accumulate the gradient magnitude of that pixel in the respective orientation bin. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span>Gradient histograms are not naturally rotation invariant however they can
                be made </span><span class="c5">invariant by finding the dominant (bin with the greatest value)
                orientation and cyclically shifting the histogram so the dominant orientation is the first
                bin</span><span class="c1">. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>SIFT (Scale Invariant Feature Transformer) feature is widely used that
                builds on the idea of local gradient histogram by incorporating spatial binning which create multiple
                gradient histograms about the interest point and appends them all together into a longer feature.
                Standard SIFT geometry appends a spatial 4x4 grid of histograms with 8 orientations. This leads to a
                128-dimensional feature that is highly discriminative and robust. In order to </span><span
                class="c5">match SIFT features</span><span class="c1">:</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span>Find the </span><span class="c5">SIFT feature vector of the interest point
                of interest and then find all of the feature vectors of the image</span><span>. Using the </span><span
                class="c5">Euclidean distance between the interest points </span><span>is an easy way of finding the
                feature vectors that are closest to the interest point. </span><span class="c5">Thresholds can be used
                to reject poor matches however that doesn&rsquo;t work well and results in lots of
                mismatches</span><span class="c1">. </span></li>
        <li class="c9 c12 li-bullet-0"><span>An improved matching method is to take </span><span class="c5">each feature
                from the first image and find the two closest feature in the second image</span><span>. Only
            </span><span class="c5">form a match if the ratio of distances between the closest and second closest
                matches is less than a threshold </span><span class="c1">(usually set at 0.8 meaning that the distance
                to the closest feature must be at most 80% of the second closest. This leads to a more robust matching
                strategy. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.pntbmv1yvvn" style="display:inline"><span class="c26 c21">Lecture 8: Consistent matching</span>
            </h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span>Even the most advanced local features can be prone to being mismatched as
                there are always </span><span class="c5">tradeoffs in feature distinctiveness</span><span>. As if its
            </span><span class="c5">too distinctive it will not match subtle variations</span><span>&nbsp;</span><span
                class="c5">due to noise</span><span>&nbsp;of imaging conditions but if it&rsquo;s </span><span
                class="c5">not distinctive enough it will match everything</span><span class="c1">. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Geometric mapping </span><span>can be thought of as a
            </span><span class="c5">transform function that maps the x, y coordinates of points in one image to
                another</span><span class="c1">. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Point transforms -</span><span>&nbsp;take the form of
            </span><img src="assets/computer-vision/image54.png"><span>&nbsp;where </span><img src="assets/computer-vision/image55.png"><span>&nbsp;is
                the transformed coordinate, </span><img src="assets/computer-vision/image56.png"><span>&nbsp;is the transform matrix and
            </span><img src="assets/computer-vision/image57.png"><span class="c1">&nbsp;is the original coordinate. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Affine transform</span><span>&nbsp;- take the form of
            </span><img src="assets/computer-vision/image58.png"><span class="c1">&nbsp;that allows for translation, rotation, scaling,
                changing of the aspect ratio and shearing. This means it has 6 degrees of freedom due to the number of
                operations </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Projective transformation (planar homography)</span><span
                class="c1">&nbsp;- Uses a 3x3 matrix as the transformation with the coordinator vector being [x, y, 1].
            </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>It is possible to </span><span class="c5">recover the transform matrix from
                a transformed image and the original image by finding a set of point matches</span><span class="c1">.
                For a homography is needs at least 4 points and 3 for affine transform. To solve uses the least squares
                difference between the proposed matrix image and the actual image. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">RANdom SAmple Consensus (RANSAC)</span><span>&nbsp;is an
            </span><span class="c5">iterative method to estimate parameters of a mathematical model for a set of
                observed data that contains outliers</span><span>. The algorithm works in two stages where the first
                stage is to generate a mathematical model representing the dataset with the second stage to find
            </span><span class="c5">how far each data point is from the line of best fit</span><span>. </span><span
                class="c5">If a data point is greater than a threshold value, the point is an outlier otherwise it is an
                inlier</span><span class="c1">. This is repeated a set number of times keeping the inliners. </span>
        </li>
        <li class="c9 c16 li-bullet-0"><span>However there are problems with</span><span class="c5">&nbsp;direct local
                feature matching as the algorithm is slow</span><span>. The typical image (800x600) has ~2000 difference
                of gaussian interest points / SIFT descriptors as it has 128 dimensions. For matching a query feature to
                an image requires </span><img src="assets/computer-vision/image59.png"><span class="c1">&nbsp;operations. </span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">K-D Trees</span><span>&nbsp;- </span><span class="c5">A binary
                tree structure that partitions the space along axis-aligned hyperplanes</span><span>. This typically
                takes each dimension in turn and splits on the median of the points in the enclosing partitions but
                stops after a certain depth or when the number of points in a leaf is less than a threshold. To search,
                just walk down the tree until a leaf is hit and brute-force search to find the best in the leaf. However
                this </span><span class="c5">doesn&rsquo;t scale well to high dimensions</span><span class="c1">&nbsp;as
                you tend to end up needing to search most of the tree. And there are approximate versions that
                won&rsquo;t necessarily return the exact answer that do scale. </span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Locality Sensitive Hashing (LSH)</span><span class="c1">&nbsp;-
                Creates hash codes for vectors such that similar vectors have similar hash codes</span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-0">
        <li class="c22 c50 c62 li-bullet-0">
            <h3 id="h.jtvokeqnfdyh" style="display:inline"><span class="c26 c21">Lecture 9: Image search and Bags of
                    Visual words</span></h3>
        </li>
    </ul>
    <ul class="c10 lst-kix_m2vm2hzdem04-1 start">
        <li class="c9 c16 li-bullet-0"><span class="c5">Bag data structure</span><span class="c1">&nbsp;- An unordered
                data set but allows elements to be inserted multiple times (sometimes called a multiset or counted set).
            </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Text processing is a way of doing feature extraction of
                text</span><span>&nbsp;by </span><span class="c5">splitting a sentence into words (tokenization)
            </span><span>with </span><span class="c5">optional stop-words removal</span><span>&nbsp;and </span><span
                class="c5">stemming/lemmatization</span><span>. The tokenized words are packaged into a bag called a
            </span><span class="c5">bag of words with a count of each word</span><span class="c1">. This conceptually
                makes language able to be solved with vector-space models. This allows for documents to be modelled with
                a vector and queried and for evaluating how &ldquo;similar&rdquo; two documents are. </span></li>
    </ul>
    <p class="c9 c47 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 482.50px; height: 304.57px;"><img
                alt="" src="assets/computer-vision/image337.png"
                style="width: 482.50px; height: 304.57px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Bag of words vectors</span><span>&nbsp;uses a </span><span
                class="c5">lexicon or vocabulary as the set of all (processed) words across all documents</span><span>.
                A vector is created for each document with as many dimensions as words in the lexicon. </span><span
                class="c5">Each word vector is a histogram of the word occurrences in the document however will have a
                very high number of dimensions but it is very sparse</span><span class="c1">.</span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">Inverted indexes are a way of mapping words to
                documents</span><span>. A posting is a pair formed by a </span><span class="c5">document
                ID</span><span>&nbsp;and the </span><span class="c5">number of times the specific
                word</span><span>&nbsp;</span><span class="c5">appeared in that document</span><span class="c1">.
            </span></li>
        <li class="c9 c16 li-bullet-0"><span>A more efficient way of</span><span class="c5">&nbsp;computing the
                similarity of two documents is to compute the cosine similarity using the inverted indexes</span><span>.
                Where</span><span class="c5">&nbsp;the smaller the angle the better</span><span class="c1">. </span>
        </li>
    </ul>
    <p class="c9 c47 c50"><span
            style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 498.50px; height: 284.72px;"><img
                alt="" src="assets/computer-vision/image82.png"
                style="width: 498.50px; height: 284.72px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                title=""></span><span class="c1">&nbsp;</span></p>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span>However doing this </span><span class="c5">assumes that every word in the
                document has equal importance which is normally not true as if a term is frequent in a document but rare
                across other documents</span><span>, it is probably more important for that document. There are
            </span><span class="c15 c5">multiple weighting schemes</span></li>
    </ul>
    <ol class="c10 lst-kix_m2vm2hzdem04-2 start" start="1">
        <li class="c9 c12 li-bullet-0"><span class="c5">Binary weights </span><span class="c1">- Only presence (1) or
                absence (0) of a term recorded in vector</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">Raw frequency</span><span class="c1">&nbsp;- The frequency of
                occurrence of term in document included in vector</span></li>
        <li class="c9 c12 li-bullet-0"><span class="c5">TF/IDF (Term frequency / Inverse document frequency)</span><span
                class="c1">&nbsp;- Provides high values for rare words and low values for common words by the term
                frequency being the frequency count of a term in the document and the inverse document frequency being
                the amount of information the word provides. </span></li>
    </ol>
    <ul class="c10 lst-kix_m2vm2hzdem04-1">
        <li class="c9 c16 li-bullet-0"><span class="c5">Vector quantisation is a lossy data compression
                technique</span><span>. Given a set of vectors, a technique like K-Means clustering can be used to learn
                a fixed size set of representative vectors where the set of representation vectors is called a codebook.
                Vector quantisation achieves this by </span><span class="c5">representing a vector by another
                approximate vector that is drawn from a pool of representative vectors</span><span class="c1">. Each
                input vector is assigned to the closest vector from a pool. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">SIFT visual words use vector quantisation as a way of replacing
                each descriptor (interest point) by a representative vector known as a visual word</span><span
                class="c1">. This is a way of simplifying a patch of pixels to a feature vector of a cluster. </span>
        </li>
        <li class="c9 c16 li-bullet-0"><span>It is possible to create a </span><span class="c5">histogram of bag of
                visual words </span><span>by generating a codebook of all the visual words in the image. This is a way
                of</span><span class="c5">&nbsp;aggregating a variable number of local descriptors into a fixed length
                vector and allows applying techniques for text retrieval to images</span><span class="c1">. </span></li>
        <li class="c9 c16 li-bullet-0"><span class="c5">An important key parameters in building visual word
                representation is the size of the codebook</span><span>&nbsp;as</span><span class="c5">&nbsp;if it is
                too small, all vectors look the same meaning that it is not distinctive enough</span><span>.
            </span><span class="c5">Too big and the same visual word might never appear across images meaning it is not
                too distinctive</span><span>. </span></li>
    </ul>
</body>

</html>